======================================================== most successful young learners
were those who had been through a range of musical instruments”); and J. A. Sloboda and M. J. A.
Howe, “Biographical Precursors of Musical Excellence,” Psychology of Music 19 (1991): 3–21 (“The
exceptional children practiced much less than the average children on their first chosen instrument
but much more than the average children on their third instrument”).
“a mismatch between the instruments”: S. A. O’Neill, “Developing a Young Musician’s Growth
Mindset,” in Music and the Mind, ed. I. Deliège and J. W. Davidson (Oxford: Oxford University
Press, 2011).
“It seems very clear”: Sloboda and Howe, “Biographical Precursors of Musical Excellence.”
A study that followed up: A. Ivaldi, “Routes to Adolescent Musical Expertise,” in Music and the
Mind, ed. Deliège and Davidson.
“Despite the ever-increasing number”: P. Gorner, “Cecchini’s Guitar Truly Classical,” Chicago
Tribune, July 13, 1968. (Studs Terkel interviewed Cecchini the day before the performance. That
fantastic conversation about music can be found here: http://jackcecchini.com/Interviews.html ).
“There was no connection”: T. Teachout, Duke: A Life of Duke Ellington (New York: Gotham
Books, 2013).
America’s preeminent composer: Kerman and Tomlinson, Listen , 394.

“John played anything”: L. Flanagan, Moonlight in Vermont: The Official Biography of Johnny
Smith (Anaheim Hills, CA: Centerstream, 2015).
“I got a wonderful piano teacher”: F. M. Hall, It’s About Time: The Dave Brubeck Story.
(Fayetteville: University of Arkansas Press, 1996).
“with a drawn knife”; “I wonder if”: M. Dregni, Django: The Life and Music of a Gypsy Legend
(Oxford: Oxford University Press, 2004 [Kindle ebook]). Two other sources provided particularly
important details about Django’s life: C. Delaunay, Django Reinhardt (New York: Da Capo, 1961)
(on the back cover, James Lincoln Collier, author of The Making of Jazz, identifies Django as
“without question, the single most important guitarist”); and a special Django issue of Guitar Player
magazine (November 1976) devoted to legendary musicians recounting their time with him.
creativity erupted: The 5-CD set “Django Reinhardt—Musette to Maestro 1928–1937: The Early
Work of a Guitar Genius” (JSP Records, 2010) includes recordings of a young Reinhardt both before
and after his injury.
Jimi Hendrix, who kept an album of Django’s: Jacob McMurray, senior curator at Seattle’s
Museum of Pop Culture, kindly confirmed this with the museum’s permanent collection.
sepia-toned YouTube clip: “Django Reinhardt Clip Performing Live (1945),” YouTube,
www.youtube.com/watch?v=aZ308aOOX04 . (The date on the You-Tube video is incorrect. The clip
is from the 1938 short film “Jazz ‘Hot.’”)
“one of osmosis” (and other Berliner quotes): P. F. Berliner, Thinking in Jazz (Chicago: University of
Chicago Press, 1994).
“as if the brain turned off”: C. Kalb, “Who Is a Genius?,” National Geographic, May 2017.
“Well, I can’t read either”: Guitar Player, November 1976.
“a concept that went against conservatory training”: Dregni, Django .
“I can’t improvise at all”: A. Midgette, “Concerto on the Fly: Can Classical Musicians Learn to
Improvise,” Washington Post, June 15, 2012, online ed.
“My complete self-taught technique” and detail about hitting siblings with violins: S. Suzuki,
Nurtured by Love, trans. W. Suzuki (Alfred Music, 1993 [Kindle ebook]).
household rules: J. S. Dacey, “Discriminating Characteristics of the Families of Highly Creative
Adolescents,” Journal of Creative Behavior 23, no. 4 (1989): 263–71. (Grant referenced the study in:
“How to Raise a Creative Child. Step One: Back Off,” New York Times , Jan. 30, 2016.)
CHAPTER 4:LEARNING, FAST AND SLOW
“Okay? You’re going to an Eagles game”: The classroom scene is from video, transcript, and
analysis from the Trends in International Mathematics and Science Study (TIMSS). The particular
video is “M-US2 Writing Variable Expressions.”
“three dollars for a hot dog”: The teacher briefly misspoke and said “two.” It is corrected for
clarity.
“using procedures”; “making connections”: J. Hiebert et al., “Teaching Mathematics in Seven
Countries,” National Center for Education Statistics, 2003, chap. 5.
bansho : E.R.A. Kuehnert et al. “Bansho: Visually Sequencing Mathematical Ideas,” Teaching
Children Mathematics 24, no. 6 (2018): 362–69.
“Students do not view mathematics as a system ”: L. E. Richland et al., “Teaching the Conceptual
Structure of Mathematics,” Educational Psychology 47, no. 3 (2012): 189–203.
tested sixth graders in the South Bronx: N. Kornell and J. Metcalfe, “The Effects of Memory
Retrieval, Errors and Feedback on Learning,” in Applying Science of Learning in Education , V.A.

Benassi et al., ed. (Society for the Teaching of Psychology, 2014); J. Metcalfe and N. Kornell,
“Principles of Cognitive Science in Education,” Psychonomic Bulletin and Review 14, no. 2 (2007):
225–29.
“hypercorrection effect”: T. S. Eich et al., “The Hypercorrection Effect in Younger and Older
Adults,” Neuropsychology, Development and Cognition. Section B, Aging, Neuropsychology and
Cognition 20, no. 5 (2013): 511–21; J. Metcalfe et al., “Neural Correlates of People’s
Hypercorrection of Their False Beliefs,” Journal of Cognitive Neuroscience 24, no. 7 (2012): 1571–
83.
Oberon and Macduff: N. Kornell and H. S. Terrace, “The Generation Effect in Monkeys,”
Psychological Science 18, no. 8 (2007): 682–85.
“Like life”: N. Kornell et al., “Retrieval Attempts Enhance Learning, but Retrieval Success (Versus
Failure) Does Not Matter,” Journal of Experimental Psychology: Learning, Memory, and Cognition
41, no. 1 (2015): 283–94.
Spanish vocabulary learners: H. P. Bahrick and E. Phelps, “Retention of Spanish Vocabulary over 8
Years,” Journal of Experimental Psychology: Learning, Memory, and Cognition 13, no. 2 (1987):
344–49.
Iowa State researchers read: L. L. Jacoby and W. H. Bartz, “Rehearsal and Transfer to LTM,”
Journal of Verbal Learning and Verbal Behavior 11 (1972): 561–65.
“produce misleadingly high levels”: N. J. Cepeda et al., “Spacing Effects in Learning,”
Psychological Science 19, no. 11 (2008): 1095–1102.
In 2007, the U.S. Department of Education: H. Pashler et al., “Organizing Instruction and Study to
Improve Student Learning,” National Center for Education Research, 2007.
an extraordinarily unique study: S. E. Carrell and J. E. West, “Does Professor Quality Matter?,”
Journal of Political Economy 118, no. 3 (2010): 409–32.
A similar study was conducted at Italy’s Bocconi University: M. Braga et al., “Evaluating
Students’ Evaluations of Professors,” Economics of Education Review 41 (2014): 71–88.
“desirable difficulties”: R. A. Bjork, “Institutional Impediments to Effective Training,” in Learning,
Remembering, Believing: Enhancing Human Performance, ed. D. Druckman and R. A. Bjork
(Washington, DC: National Academies Press, 1994), 295–306.
“Above all, the most basic message”: C. M. Clark and R. A. Bjork, “When and Why Introducing
Difficulties and Errors Can Enhance Instruction,” in Applying the Science of Learning in Education,
ed. V. A. Benassi et al. (Society for the Teaching of Psychology, 2014 [ebook]).
said in national surveys: C. Rampell, “Actually, Public Education is Getting Better, Not Worse,”
Washington Post , September 18, 2014.
School has not gotten worse; “jobs that pay well”: G. Duncan and R. J. Murnane, Restoring
Opportunity (Cambridge, MA: Harvard Education Press, 2014 [Kindle ebook]).
In a study using college math problems: D. Rohrer and K. Taylor, “The Shuffling of Mathematics
Problems Improves Learning,” Instructional Science 35 (2007): 481–98. See also: D. Rohrer et al.,
“A Randomized Controlled Trial of Interleaved Mathematics Practice,” Journal of Educational
Psychology (May 16, 2019): advance online publication.
butterfly species identification to psychological-disorder diagnosis: M. S. Birnbaum et al., “Why
Interleaving Enhances Inductive Learning,” Memory and Cognition 41 (2013): 392–402.
naval air defense simulations: C. L. Holladay and M.A. Quiñones, “Practice Variability and
Transfer of Training,” Journal of Applied Psychology 88, no. 6 (2003): 1094–1103.
In one of Kornell and Bjork’s interleaving studies, 80 percent of students: N. Kornell and R. A.
Bjork, “Learning Concepts and Categories: Is Spacing the ‘Enemy of Induction’?,” Psychological

Science 19, no. 6 (2008): 585–92.
a particular left-hand jump across fifteen keys: M. Bangert et al., “When Less of the Same Is
More: Benefits of Variability of Practice in Pianists,” Proceedings of the International Symposium on
Performance Science (2013): 117–22.
O’Neal should practice from a foot in front: Bjork makes this suggestion in Daniel Coyle’s The
Talent Code (New York: Bantam, 2009).
hallmark of expert problem solving: See, for example: M.T.H. Chi et al., “Categorization and
Representation of Physics Problems by Experts and Novices,” Cognitive Science 5, no. 2 (1981):
121–52; and J. F. Voss et al., “Individual Differences in the Solving of Social Science Problems,” in
Individual Differences in Cognition, vol. 1, ed. R. F. Dillon and R. R. Schmeck (New York:
Academic Press, 1983).
reviewed sixty-seven early childhood education programs: D. Bailey et al., “Persistence and
Fadeout in Impacts of Child and Adolescent Interventions,” Journal of Research on Educational
Effectiveness 10, no. 1 (2017): 7–39.
The motor-skill equivalent: S. G. Paris, “Reinterpreting the Development of Reading Skills,”
Reading Research Quarterly 40, no. 2 (2005): 184–202.
CHAPTER 5:THINKING OUTSIDE EXPERIENCE
Giordano Bruno: A. A. Martinez, “Giordano Bruno and the Heresy of Many Worlds,” Annals of
Science 73, no. 4 (2016): 345–74.
Johannes Kepler inherited: Sources that give excellent background on the worldviews that Kepler
inherited, and his transformative analogies, are: D. Gentner et al., “Analogical Reasoning and
Conceptual Change: A Case Study of Johannes Kepler,” Journal of the Learning Sciences 6, no. 1
(1997): 3–40; D. Gentner, “Analogy in======================================================== OceanofPDF.com



OceanofPDF.com

For Elizabeth,
this one and any other one
OceanofPDF.com

Contents
INTRODUCTION: Roger vs. Tiger
CHAPTER 1: The Cult of the Head Start
CHAPTER 2: How the Wicked World Was Made
CHAPTER 3: When Less of the Same Is More
CHAPTER 4: Learning, Fast and Slow
CHAPTER 5: Thinking Outside Experience
CHAPTER 6: The Trouble with Too Much Grit
CHAPTER 7: Flirting with Your Possible Selves
CHAPTER 8: The Outsider Advantage
CHAPTER 9: Lateral Thinking with Withered Technology
CHAPTER 10: Fooled by Expertise
CHAPTER 11: Learning to Drop Your Familiar Tools
CHAPTER 12: Deliberate Amateurs
CONCLUSION: Expanding Your Range
AFTERWORD
ACKNOWLEDGMENTS
NOTES
INDEX
OceanofPDF.com

And he refused to specialize in anything, preferring to keep an eye on the
overall estate rather than any of its parts. . . . And Nikolay’s management
produced the most brilliant results.
—Leo Tolstoy, War and Peace
No tool is omnicompetent. There is no such thing as a master-key that will unlock all doors.
—Arnold Toynbee, A Study of History
OceanofPDF.com

INTRODUCTION
Roger vs. Tiger
LET’S START WITH a couple of stories from the world of sports. This first one,
you probably know.
The boy’s father could tell something was different. At six months old, the
boy could balance on his father’s palm as he walked through their home. At
seven months, his father gave him a putter to fool around with, and the boy
dragged it everywhere he went in his little circular baby walker. At ten
months, he climbed down from his high chair, trundled over to a golf club
that had been cut down to size for him, and imitated the swing he’d been
watching in the garage. Because the father couldn’t yet talk with his son, he
drew pictures to show the boy how to place his hands on the club. “It is very
difficult to communicate how to putt when the child is too young to talk,” he
would later note.
At two—an age when the Centers for Disease Control and Prevention list
physical developmental milestones like “kicks a ball” and “stands on
tiptoe”—he went on national television and used a club tall enough to reach
his shoulder to drive a ball past an admiring Bob Hope. That same year, he
entered his first tournament, and won the ten-and-under division.
There was no time to waste. By three, the boy was learning how to play
out of a “sand twap,” and his father was mapping out his destiny. He knew
his son had been chosen for this, and that it was his duty to guide him. Think
about it: if you felt that certain about the path ahead, maybe you too would
start prepping your three-year-old to handle the inevitable and insatiable
media that would come. He quizzed the boy, playing reporter, teaching him
how to give curt answers, never to offer more than precisely what was asked.

That year, the boy shot 48, eleven over par, for nine holes at a course in
California.
When the boy was four, his father could drop him off at a golf course at
nine in the morning and pick him up eight hours later, sometimes with the
money he’d won from those foolish enough to doubt.
At eight, the son beat his father for the first time. The father didn’t mind,
because he was convinced that his boy was singularly talented, and that he
was uniquely equipped to help him. He had been an outstanding athlete
himself, and against enormous odds. He played baseball in college when he
was the only black player in the entire conference. He understood people,
and discipline; a sociology major, he served in Vietnam as a member of the
Army’s elite Green Berets, and later taught psychological warfare to future
officers. He knew he hadn’t done his best with three kids from a previous
marriage, but now he could see that he’d been given a second chance to do
the right thing with number four. And it was all going according to plan.
The boy was already famous by the time he reached Stanford, and soon
his father opened up about his importance. His son would have a larger
impact than Nelson Mandela, than Gandhi, than Buddha, he insisted. “He
has a larger forum than any of them,” he said. “He’s the bridge between the
East and the West. There is no limit because he has the guidance. I don’t
know yet exactly what form this will take. But he is the Chosen One.”
This second story, you also probably know. You might not recognize it at
first .
His mom was a coach, but she never coached him. He would kick a ball
around with her when he learned to walk. As a boy, he played squash with
his father on Sundays. He dabbled in skiing, wrestling, swimming, and
skateboarding. He played basketball, handball, tennis, table tennis,
badminton over his neighbor’s fence, and soccer at school. He would later
give credit to the wide range of sports he played for helping him develop his
athleticism and hand-eye coordination.
He found that the sport really didn’t matter much, so long as it included a
ball. “I was always very much more interested if a ball was involved,” he
would remember. He was a kid who loved to play. His parents had no
particular athletic aspirations for him. “We had no plan A, no plan B,” his
mother would later say. She and the boy’s father encouraged him to sample a

wide array of sports. In fact, it was essential. The boy “became unbearable,”
his mother said, if he had to stay still for too long.
Though his mother taught tennis, she decided against working with him.
“He would have just upset me anyway,” she said. “He tried out every strange
stroke and certainly never returned a ball normally. That is simply no fun for
a mother.” Rather than pushy, a Sports Illustrated writer would observe that
his parents were, if anything, “pully.” Nearing his teens, the boy began to
gravitate more toward tennis, and “if they nudged him at all, it was to stop
taking tennis so seriously.” When he played matches, his mother often
wandered away to chat with friends. His father had only one rule: “Just don’t
cheat.” He didn’t, and he started getting really good.
As a teenager, he was good enough to warrant an interview with the local
newspaper. His mother was appalled to read that, when asked what he would
buy with a hypothetical first paycheck from playing tennis, her son
answered, “a Mercedes.” She was relieved when the reporter let her listen to
a recording of the interview and they realized there’d been a mistake: the
boy had said “Mehr CDs ,” in Swiss German. He simply wanted “more CDs.
”
The boy was competitive, no doubt. But when his tennis instructors
decided to move him up to a group with older players, he asked to move
back so he could stay with his friends. After all, part of the fun was hanging
around after his lessons to gab about music, or pro wrestling, or soccer.
By the time he finally gave up other sports—soccer, most notably—to
focus on tennis, other kids had long since been working with strength
coaches, sports psychologists, and nutritionists. But it didn’t seem to hamper
his development in the long run. In his midthirties, an age by which even
legendary tennis players are typically retired, he would still be ranked
number one in the world.
In 2006, Tiger Woods and Roger Federer met for the first time, when both
were at the apex of their powers. Tiger flew in on his private jet to watch the
final of the U.S. Open. It made Federer especially nervous, but he still won,
for the third year in a row. Woods joined him in the locker room for a
champagne celebration. They connected as only they could. “I’ve never
spoken with anybody who was so familiar with the feeling of being
invincible,” Federer would later describe it. They quickly became friends, as

well as focal points of a debate over who was the most dominant athlete in
the world.
Still, the contrast was not lost on Federer. “His story is completely
different from mine,” he told a biographer in 2006. “Even as a kid his goal
was to break the record for winning the most majors. I was just dreaming of
just once meeting Boris Becker or being able to play at Wimbledon some
time.”
It seems pretty unusual for a child with “pully” parents, and who first took
his sport lightly, to grow into a man who dominates it like no one before
him. Unlike Tiger, thousands of kids, at least, had a head start on Roger.
Tiger’s incredible upbringing has been at the heart of a batch of bestselling
books on the development of expertise, one of which was a parenting
manual written by Tiger’s father, Earl. Tiger was not merely playing golf. He
was engaging in “deliberate practice,” the only kind that counts in the now-
ubiquitous ten-thousand-hours rule to expertise. The “rule” represents the
idea that the number of accumulated hours of highly specialized training is
the sole factor in skill development, no matter the domain. Deliberate
practice, according to the study of thirty violinists that spawned the rule,
occurs when learners are “given explicit instructions about the best method,”
individually supervised by an instructor, supplied with “immediate
informative feedback and knowledge of the results of their performance,”
and “repeatedly perform the same or similar tasks.” Reams of work on
expertise development shows that elite athletes spend more time in highly
technical, deliberate practice each week than those who plateau at lower
levels:

Tiger has come to symbolize the idea that the quantity of deliberate
practice determines success—and its corollary, that the practice must start as
early as possible.
The push to focus early and narrowly extends well beyond sports. We are
often taught that the more competitive and complicated the world gets, the
more specialized we all must become (and the earlier we must start) to
navigate it. Our best-known icons of success are elevated for their precocity
and their head starts—Mozart at the keyboard, Facebook CEO Mark
Zuckerberg at the other kind of keyboard. The response, in every field, to a
ballooning library of human knowledge and an interconnected world has
been to exalt increasingly narrow focus. Oncologists no longer specialize======================================================== point into primary sources for anyone
interested in some Friday night (or Saturday morning) exploration. The vast
majority of spoken quotes in the book are from interviews I conducted.
When that is not the case, the source is identified in the text or here. In the
interest of packing as many citations in the available space as I could, I
removed subtitles of books and papers in some of the references below.
INTRODUCTION: ROGER VS. TIGER
the boy could balance on his father’s palm: G. Smith, “The Chosen One,” Sports Illustrated ,
December 23, 1996. (Additionally, Earl Woods included a photograph of this in the source cited
below.)
“It is very difficult to communicate how to putt”: The primary source on Tiger’s childhood in this
section is: E. Woods (with P. McDaniel, foreword by Tiger Woods), Training a Tiger: Raising a
Winner in Golf and Life (New York: Harper Paperbacks, 1997).
taught psychological warfare: J. Benedict and A. Keteyian, Tiger Woods (New York: Simon &
Schuster, 2018).
“He has a larger forum than any of them”: Smith, “The Chosen One.”
“I was always very much more interested”; “We had no plan A”: R. Jacob, “Ace of Grace,”
Financial Times , January 13, 2006, online ed.
“became unbearable”; “he would have just upset me anyway”: R. Stauffer, The Roger Federer
Story: Quest for Perfection (Chicago: New Chapter Press, 2007 [Kindle ebook]).
“pully”; “if they nudged him”; “just don’t cheat”; “Mehr CDs ”: J. L. Wertheim, Strokes of
Genius (New York: Houghton Mifflin Harcourt, 2009 [Kindle ebook]).
“being invincible”; “His story is completely different”: Stauffer, The Roger Federer Story.
study of thirty violinists: K. A. Ericsson, R. T. Krampe, and C. Tesch-Römer, “The Role of
Deliberate Practice in the Acquisition of Expert Performance,” Psychological Review 100, no. 3
(1993): 363–406.
“we have to check”: A. Gawande, The Checklist Manifesto (New York: Metropolitan Books, 2010).
“slow bakers”: For an excellent look at how Great Britain altered its talent pipelines, see: O. Slot,
The Talent Lab (London: Ebury Press, 2017).

ramp up technical practice in one area: Examples of studies—including those cited in the
introduction—from a range of sports and countries documenting the trend of sampling and delayed
specialization include (the first paper here is the source for data in the charts showing practice hours):
K. Moesch et al., “Late Specialization: The Key to Success in Centimeters, Grams, or Seconds (CGS)
Sports,” Scandinavian Journal of Medicine and Science in Sports 21, no. 6 (2011): e282–90; K.
Moesch et al., “Making It to the Top in Team Sports: Start Later, Intensify, and Be Determined!,”
Talent Development and Excellence 5, no. 2 (2013): 85–100; M. Hornig et al., “Practice and Play in
the Development of German Top-Level Professional Football Players,” European Journal of Sport
Science 16, no. 1 (2016): 96–105 (epub ahead of print, 2014); A. Güllich et al., “Sport Activities
Differentiating Match-Play Improvement in Elite Youth Footballers—A 2-Year Longitudinal Study,”
Journal of Sports Sciences 35, no. 3 (2017): 207–15 (epub ahead of print, 2016); A. Güllich,
“International Medallists’ and Non-medallists’ Developmental Sport Activities—A Matched-Pairs
Analysis,” Journal of Sports Sciences 35, no. 23 (2017): 2281–88; J. Gulbin et al., “Patterns of
Performance Development in Elite Athletes,” European Journal of Sport Science 13, no. 6 (2013):
605–14; J. Gulbin et al., “A Look Through the Rear View Mirror: Developmental Experiences and
Insights of High Performance Athletes,” Talent Development and Excellence 2, no. 2 (2010): 149–64;
M. W. Bridge and M. R. Toms, “The Specialising or Sampling Debate,” Journal of Sports Sciences
31, no. 1 (2013): 87–96; P. S. Buckley et al., “Early Single-Sport Specialization,” Orthopaedic
Journal of Sports Medicine 5, no. 7 (2017): 2325967117703944; J. P. Difiori et al., “Debunking Early
Single Sports Specialization and Reshaping the Youth Sport Experience: An NBA Perspective,”
British Journal of Sports Medicine 51, no. 3(2017): 142–43; J. Baker et al., “ Sport-Specific Practice
and the Development of Expert Decision-Making in Team Ball Sports,” Journal of Applied Sport
Psychology 15, no. 1 (2003): 12–25; R. Carlson, “The Socialization of Elite Tennis Players in
Sweden: An Analysis of the Players’ Backgrounds and Development,” Sociology of Sport Journal 5
(1988): 241–56; G. M. Hill, “Youth Sport Participation of Professional Baseball Players,” Sociology
of Sport Journal 10 (1993): 107–14.; F. G. Mendes et al., “Retrospective Analysis of Accumulated
Structured Practice: A Bayesian Multilevel Analysis of Elite Brazilian Volleyball Players,” High
Ability Studies (advance online publication, 2018); S. Black et al., “Pediatric Sports Specialization in
Elite Ice Hockey Players,” Sports Health: A Multidisciplinary Approach (advance online publication,
2018); T. Staff et al., "Investigating the Period of Practice Needed to Acquire Expertise in Great
Britain 2012 Track and Field Olympic Athletes," Journal of Expertise 2, no. 3 (2019): 148–63.
(France, which won the 2018 World Cup, overhauled its youth development decades ago to
emphasize unstructured play at the expense of formal competitions, and to make room for late
bloomers. A top youth footballer in France might play half as many formal games as an American
peer. When French kids in the national development system do have formal games, coaches are
barred from talking for most of the competition so that they cannot micromanage young players.
“There is no remote [control] for the players. . . . Let them play,” as Ludovic Debru, who helped
design the youth system, put it at the 2018 edition of the Aspen Institute’s Project Play Summit.)
“In an era of sports specialization”: J. Brewer, “Ester Ledecka Is the Greatest Olympian at the
Games, Even If She Doesn’t Know It,” Washington Post, February 24, 2018, online ed.
“I was doing so many different sports”: J. Drenna, “Vasyl Lomachenko: ‘All Fighters Think About
Their Legacy. I’m No Different,’” Guardian , April 16, 2018, online ed.
“young people are just smarter”: M. Coker, “Startup Advice for Entrepreneurs from Y
Combinator,” VentureBeat, March 26, 2007.
a tech founder who is fifty: P. Azoulay et al., “Age and High-Growth Entrepreneurship,” NBER
Working Paper No. 24489 (2018).
“No one imagined silos like that”: G. Tett, The Silo Effect: The Peril of Expertise and the Promise
of Breaking Down Barriers (New York: Simon & Schuster, 2015 [Kindle ebook]).

if they were admitted during a national cardiology meeting: A. B. Jena et al., “Mortality and
Treatment Patterns Among Patients Hospitalized with Acute Cardiovascular Conditions During Dates
of National Cardiology Meetings,” JAMA Internal Medicine 175, no. 2 (2015): 237–44. See also:
R.F. Redberg, “Cardiac Patient Outcomes during National Cardiology Meetings,” JAMA Internal
Medicine 175, no.2 (2015): 245.
CHAPTER1: THE CULT OF THE HEAD START
go along with the plan: The lives of the Polgar sisters have been chronicled in a number of books
and articles. For the details in this chapter, in addition to an interview with Susan Polgar, the most
useful sources were: Y. Aviram (director), The Polgar Variant (Israel: Lama Films, 2014); S. Polgar
with P. Truong, Breaking Through: How the Polgar Sisters Changed the Game of Chess (London:
Everyman Chess, 2005); C. Flora, “The Grandmaster Experiment,” Psychology Today, July 2005,
online ed.; P. Voosen, “Bringing Up Genius: Is Every Healthy Child a Potential Prodigy?,” Chronicle
of Higher Education, November 8, 2015, online ed.; C. Forbes, The Polgar Sisters (New York: Henry
Holt, 1992).
“met a very interesting person”: Polgar with Truong, Breaking Through .
“gray average mass”: People staff, “Nurtured to Be Geniuses, Hungary’s Polgar Sisters Put
Winning Moves on Chess Masters,” People , May 4, 1987.
“Chess is very objective”: L. Myers, “Trained to Be a Genius, Girl, 16, Wallops Chess Champ
Spassky for $110,000,” Chicago Tribune, February 18, 1993.
“absolute category” : Aviram, The Polgar Variant .
problems like cancer and AIDS: W. Hartston, “A Man with a Talent for Creating Genius,”
Independent, January 12, 1993.
“complete lack of connection” : “Daniel Kahneman—Biographical,” Nobelprize.org , Nobel Media
AB 2014. I had the pleasure of discussing Kahneman’s life and work with him over lunch in
December 2015. Additional detail can be found in his book Thinking, Fast and Slow (New York:
Farrar, Straus & Giroux, 2011).
impressed him “enormously”: The still relevant book that impressed Kahneman is: Paul E. Meehl,
Clinical Versus Statistical Prediction (Minneapolis: University of Minnesota Press, 1954). Meehl
sparked an enormous amount of research showing that experts often gain confidence but not skill
with experience. An excellent review of some of that work is: C. F. Camerer and E. J. Johnson, “The
Process-Performance Paradox in Expert Judgment: How Can Experts Know So Much and Predict So
Badly?,” in Toward a General Theory of Expertise, ed. K. A. Ericsson and Jacqui Smith (Cambridge:
Cambridge University Press, 1991).
In 2009, Kahneman and Klein: D. Kahneman and G. Klein, “Conditions for Intuitive Expertise: A
Failure to Disagree,” American Psychologist 64, no. 6 (2009): 515–26.
“kind” learning environments: Robin Hogarth’s fantastic book on learning environments is
Educating Intuition (Chicago: University of Chicago Press, 2001).
“a more productive carrier”: L. Thomas, The Youngest Science (New York: Penguin, 1995), 22.
In a 1997 showdown: Kasparov was on the cover of the May 5, 1997, Newsweek, with the headline,
“The Brain’s Last Stand.”
“Today the free chess app”: Kasparov and his aide-de-camp Mig Greengard were kind enough to
answer my questions. Additional information came from a lecture Kasparov gave at Georgetown
University on June 5, 2017, and Kasparov and Greengard’s book Deep Thinking (New York:
PublicAffairs, 2017).

“you can get a lot further”: S. Polgar and P. Truong, Chess Tactics======================================================== and anyone in one circle had numerous entry points to
communicate with the next circle, rather than just a single superior who
acted as a gate. When she explained it to me, it seemed a lot like the kind of
incongruence Geveden worked to engender, and the kind that Captain
Lesmes wielded: a differentiated chain of command and chain of
communication that produced incongruence, and thus a healthy tension. An
occasionally confusing but effective mix of strong formal and informal
culture. A trio of psychology and management professors who analyzed a
century of Himalayan mountain climbers—5,104 expedition groups in all—
found that teams from countries that strongly valued hierarchical culture got
more climbers to the summit, but also had more climbers die along the way.
The trend did not hold for solo climbers, only teams, and the researchers
argued that hierarchical teams benefitted from a clear chain of command,
but suffered from a one-way chain of communication that obscured
problems. The teams needed elements of both hierarchy and individualism
to both excel and survive.
It is a difficult balancing act, cultivating aspects of a culture that seem on
their face to push against one another. There are no rules for the qualitative
hunches of space shuttle engineers or pararescue jumpers lacking intel.
Incongruence, as the experimental research testified, helps people to
discover useful cues, and to drop the traditional tools when it makes sense.

Karl Weick’s tools insight reminded me of an experience I had as a
graduate student, working aboard the Research Vessel Maurice Ewing in the
Pacific Ocean. The ship was bouncing sound waves off the ocean floor to
image underwater volcanoes. I got to know a few volcano experts who truly
saw the world through volcano-colored glasses. Despite ample evidence
that an asteroid impact was either the primary cause of the dinosaur
extinction, or at least very important, they insisted that volcanic eruptions
were clearly the real culprit. If anything, one told me, the asteroid was
really just a lucky knockout punch; volcanoes had already delivered the
body blows. He seemed to attribute a whole slew of mass extinctions to
volcanoes, some with compelling evidence, others with pretty much none.
When all you have is a volcanologist, I learned, every extinction looks like
a volcano. That is not necessarily bad for the world. They should challenge
accepted wisdom, and it drives those narrowly focused experts to find
volcano knowledge where no one else is looking. But when entire
specialties grow up around devotion to a particular tool, the result can be
disastrous myopia .
Interventional cardiologists, for example, specialize in treating chest pain
by placing stents—a metal tube that pries open blood vessels. It makes a ton
of sense: a patient comes in with chest pain, imaging shows a narrowed
artery, a stent is placed to open it and preclude a heart attack. The logic is so
compelling that a prominent cardiologist coined the term “oculostenotic
reflex,” from the Latin for “eye,” and stenotic, from the Greek for “narrow,”
meaning: if you see a blockage, you’ll reflexively fix a blockage. Except,
repeatedly, randomized clinical trials that compared stents with more
conservative forms of treatment show that stents for patients with stable
chest pain prevent zero heart attacks and extend the lives of patients a grand
total of not at all.
The interventional cardiologists are seeing and treating one tiny part of a
complicated system; the cardiovascular system isn’t a kitchen sink, and it
turns out that treating one blocked pipe often doesn’t help. Plus, about one
in fifty patients who get a stent will suffer a serious complication or die as a
result of the implantation procedure. Despite the bird’s-eye evidence,
cardiologists who specialize in using that tool reported that they simply
cannot believe that stenting doesn’t work, even when their compensation
was not tied to performing the procedure. Being told to stop using stents
was like being told to forget you are an interventional cardiologist. The

instinct, often well-meaning, to use interventions that seem logical but that
have not been shown to help may explain the finding of a 2015 study:
patients with heart failure or cardiac arrest were less likely to die if they
were admitted during a national cardiology conference, when thousands of
top cardiologists were away. “At large cardiology conventions, my
colleagues and I have often joked that the convention center would be the
safest place in the world to have a heart attack,” cardiologist Rita F.
Redberg wrote. “[The conference study] turned that analysis around.”
Similarly harrowing findings are now appearing all over medicine,
wherever specialties have arisen for the use of a particular tool. One of the
most common orthopedic surgeries in the world involves shaving a torn
meniscus—a piece of cartilage in the knee—back to its original crescent
shape. A patient reports knee pain; an MRI shows a torn meniscus;
naturally, a surgeon wants to fix it. When five orthopedic clinics in Finland
compared the surgery with “sham surgery”—that is, surgeons took patients
with knee pain and a torn meniscus to operating rooms, made incisions,
faked surgeries, and sewed them back up and sent them to physical therapy
—they found that sham surgery worked just as well. Most people with a
torn meniscus, it turns out, don’t have any symptoms at all and will never
even know. And for those who do have a torn meniscus and knee pain, the
tear may have nothing to do with the pain.
Seeing small pieces of a larger jigsaw puzzle in isolation, no matter how
hi-def the picture, is insufficient to grapple with humanity’s greatest
challenges. We have long known the laws of thermodynamics, but struggle
to predict the spread of a forest fire. We know how cells work, but can’t
predict the poetry that will be written by a human made up of them. The
frog’s-eye view of individual parts is not enough. A healthy ecosystem
needs biodiversity.
Even now, even in endeavors that engender specialization unprecedented
in history, there are beacons of breadth. Individuals who live by historian
Arnold Toynbee’s words that “no tool is omnicompetent. There is no such
thing as a master-key that will unlock all doors.” Rather than wielding a
single tool, they have managed to collect and protect an entire toolshed, and
they show the power of range in a hyperspecialized world.
OceanofPDF.com

CHAPTER 12
Deliberate Amateurs
JANUARY 23, 1954 , was a Saturday, and Oliver Smithies was in the lab in
Toronto, as usual. “Saturday morning experiments,” he called them.
Nobody was around, and he felt free from the strictures of normal work. On
Saturday, he didn’t have to weigh things carefully. He could take a pinch of
this, a dash of that for an experiment that during the week would be
considered a waste of time and equipment. He could try something that
intrigued him, but that had little to do with his primary project. One needs
to let the brain think about something different from its daily work, he
would say. “On Saturday,” as Smithies put it, “you don’t have to be
completely rational.”
Smithies worked in a lab studying insulin, and his job was to find an
insulin precursor. The work was stuck, literally. The method of separating
molecules so they could be studied involved running an electric current
through a special type of moist paper. The molecules moved apart as they
crossed the paper. But insulin just stuck to it. Smithies had heard that the
local children’s hospital had tried moist starch grains instead of paper.
Starch solved the stickiness problem, but would require him to cut the
grains into fifty slices and analyze each one individually to find out where
the molecules ended up. That would take forever, so it was a nonstarter.
Then he remembered something, from when he was twelve.
Smithies grew up in the town of Halifax in England, and would watch his
mother starch his father’s work shirts to make the collars firm. She dipped
each shirt in gooey hot starch, and then ironed it. To help her tidy up,

Smithies disposed of the starch. He noticed that when it cooled, the starch
congealed into a jelly.
Smithies had a skeleton key for the building, and went around raiding
supply closets for starch grains. He cooked the grains, let them cool into a
gel, and tried it in place of the paper. When he applied electrical current, the
insulin molecules separated according to size in the gel. “Very promising!”
his notebook page from that day reads. In subsequent years, “gel
electrophoresis” was refined, and revolutionized biology and chemistry.
Individual fragments of DNA and components of human blood serum could
be separated and studied.
When I spoke with Smithies in 2016, he was ninety years old and in his
lab. He was thinking about how the kidney separates large and small
molecules. “At the moment, it’s a Saturday morning theoretical
experiment,” he said.
What struck me as Smithies spoke was his joy in experimentation. Not
just in his lab, but in his life. He embodied a number of tenets I set out to
explore in this book. From the outside, he looked like the consummate
hyperspecialist. He was a molecular biochemist, after all. Except, molecular
biochemist wasn’t really a thing when Smithies was in training. First he
studied medicine, until he attended a talk by a professor who was
combining chemistry and biology. “He lectured about this new subject
which hadn’t yet been invented, in a sense,” Smithies told me. “It was
marvelous, and I thought, ‘I’d like to do that. I’d better learn some
chemistry.’” He turned on a dime and switched to studying chemistry. He
never even thought to feel behind. On the contrary, “that was really very
valuable, because at the end I had a good background in biology and wasn’t
frightened of biology, and then I wasn’t frightened of chemistry. That gave
me a great deal of power in the early days of molecular biology.” What
sounds======================================================== “necessary nor healthy” for children to
be directed toward one career before they can make that decision
themselves—a decision that, again, took her years of adulthood. “So what
does grit look like early in life?” she wrote. “A young child who decides
today that she wants to become a doctor but thinks tomorrow that she’d
rather build houses. A teenager who decides, no, she won’t go out for track
this year and instead will see what it’s like to write for the school
newspaper.” Specialization has benefits, she added, “but before
specialization comes sampling, the exploration of possibilities that, really,
you cannot know anything about until you try them . . . Don’t confuse the
healthy development of a work ethic with the premature commitment to a
singular passion.”
As one researcher suggested to me: “When you get fit, it will look like
grit.” That is, if you help someone find a good fit, they are more likely to
display the characteristics of grit—like sticking with something—even if
they didn’t before.
Needless to say, most people aren’t going to be Tillman Scholars,
executives, or William Shakespeare. And while many of the stories in
Range portray uncommon achievements, I hoped those would serve as
memorable portals of engagement into research that applies to a much
broader swath of humanity.
In fact, international research that studied thousands of workers—more
than three-quarters of whom did not have tertiary education—
produced findings that resonate with a major theme of the book: that
sometimes the actions that provide a head start will undermine long-term
development , whether that is choosing a career or a course of study, or
simply developing a skill or learning new material.
A 2017 study published by four economists in the U.S., Germany, and
China, analyzed education and employment data in eleven countries with

large vocational education or apprenticeship programs, comparing people
within each country who had similar backgrounds—including test scores,
family background, and years of education—but differed in whether they
received career-focused or broader, general education. Naturally, there was
considerable variation between countries and certainly between individuals,
but the general pattern was: people who got narrow, career-focused
education were more likely to be employed right out of school and earned
more right away, but over time both advantages evaporated; decades later,
they had spent less overall time in the labor market and had lower lifetime
earnings. The early specializers often won in the short term, and lost in the
long run. Workers who received general education, the economists
concluded, were better positioned to adapt to change in a wicked world
where work next year might not look like work last year.
The pattern was particularly pronounced in two countries with famously
extensive apprenticeship programs—Denmark and Germany—an important
finding given that, over the last decade, U.S. politicians on both sides of the
aisle have advocated for a move toward the German apprenticeship model.
In 2017, President Trump issued an executive order to expand
apprenticeship programs to prepare workers for “today’s rapidly changing
economy”. The economists, on the other hand, concluded that the more
rapidly a nation’s economy is changing, the greater the long-term advantage
of general education. Of the three countries with widespread apprenticeship
programs—Denmark, Germany, Switzerland—early specialization only
resulted in a lifetime earnings advantage in Switzerland, which has had
easily the slowest growing economy of those three nations in recent
decades. “This comparison is consistent with the idea that those with
general education are more adaptable to changed economic demands,” two
of the economists wrote. “Vocational education has been promoted largely
as a way of improving the transition from schooling to work, but it also
appears to reduce the adaptability of workers to technological and structural
change in the economy.”
Does that mean we should have no early vocational training or
apprenticeships at all? I certainly don’t think so, and one of the economists
who did this work pointed out that apprenticeships still work well in
specific areas, like the building trades, but also that those trades are a small
portion of unfilled jobs. In my opinion, we should preserve a variety of
pathways, to fit a variety of life circumstances. But I also think we need to

be aware of how easy it is to be fooled by head starts, assuming that they
represent terminally stable trajectories, whether the head start be for child
athletes, college students learning math, or workers entering the labor force.
“The advantages of vocational training in smoothing entry into the labor
market,” the economists wrote, “have to be set against disadvantages later
in life, disadvantages that are likely to be more severe as we move more
into being a knowledge economy.”
The question of how broad or specialized to be is important to just about
everyone at some point or another, but usually only discussed with
intuition. Like any complex question that involves human beings, there is
no one-size-fits-all answer. My hope was to make discussions about that
crucial topic more interesting and productive.
I’m a science writer, so in doing that, I wanted to rely heavily on
scientific research that bears on the question from various angles. In talking
with readers after the hardcover publication, though, I’ve increasingly felt
that the stories of late starts or zig-zagging career paths have a specific
importance. The “availability heuristic” is a well-known cognitive bias in
which we tend to rely on the first example that comes to mind when making
a decision or judging an idea. Tiger stories have supplied millions of brains
with availability-heuristic ammo when they think of specialization. I hope
some of the stories in this book—from Federer and Van Gogh to Frances
Hesselbein (now 104, still working)—might stick in readers’ minds and
surface when the Tiger stories do, adding much needed balance to how we
consider the topic.
When I was allotted this space for an afterword to the paperback edition,
I first thought I should stuff it with research that I had to cut from the
hardcover due to space constraints. (My editor talked me off that cliff.)
Instead, I’d like to share one more memorable story.
When asked, Titus Kaphar reflexively says that nobody in his family went
to college. His mother didn’t go to college. His father went to prison, but
not to college. Neither his grandmother nor his grandfather went to college.
Nobody went to college. Except—he corrects himself—a distant cousin
went to college. Kaphar himself certainly wasn’t going to college. He often
didn’t even go to high school, hence the 0.65 GPA.

And yet, in his twenties, he decided to enroll in a few junior college
classes. Allow him to explain: he wanted to date a soon-to-be teacher; she
was four years older, contemplating grad school, and not impressed that he
had no plans for his future.
“So I just went over to the junior college,” Kaphar told me, “kind of as a
joke, not really taking it seriously, because, you know, I’m not an academic.
I’m not a person who does really well in school.” He picked a few classes
more or less at random. He came back and told the object of his affection.
They had a quick laugh about it.
One class was art history. Why? “I probably read the word ‘art’ and
thought, ‘art should be easy,’” Kaphar told me. In an unexpected way, it
was. Kaphar realized that he could remember details of paintings—not just
remember what he had seen, but associate the painting with the style of a
particular artist or artistic movement. “I remember one day we were talking
about Van Gogh,” he recalled, “and I remember seeing the image and being
very aware of where the painting sat in the history of art, where it sat in the
timeline the professor was trying to lay out for us.” He began to contribute
to class discussions. His confidence grew, and he got a B in the class.
“That was a new experience for me,” he told me, “a B overall in the class
at something that was academic. It made me go, ‘Hold up, wait a minute.’ I
realized this was, in fact, something that I was enjoying, and I could feel
myself wanting to push harder. When it became difficult, that grit became
more apparent.” He took more classes, and tested strategies until he found
something that worked, like dictating essays into a recorder for his first
draft, and studying for history tests by focusing on connecting the images in
a book to the surrounding material. Suddenly, college didn’t seem like such
a crazy idea.
Kaphar proceeded to San José State University to study fine arts. In an
art history survey course, to his dismay, the professor skipped over the
section on black painters. So Kaphar decided to compile his own syllabus
on the topic. “I think to some degree, it was like being a reporter doing an
investigation,” he said. A friend’s grandmother was a sculptor, and gave him
books. The first was on the Harlem Renaissance. “That sort of opened the
floodgates,” he recalled. He realized that the traditional artistic canon used
in class was not some magical pantheon, but just another syllabus
assembled by humans. He collected more books, and introduced new names
into class discussion.

Eventually, he took an actual painting class, but the teacher told the class
that he didn’t believe in painting anymore, so he gave no instruction
whatsoever on technique. Instead, Kaphar started looking over other
students’ shoulders and self-teaching. “It was like, last semester I painted an
apple, and it looked like a cannonball,” he told me. “This semester that
actually looks like an apple. Now, it’s loose, a child could do the same
thing, but it looks like an apple. Awesome, let’s keep going.” He began to
study paintings and then try to reverse-engineer them. When he noticed that
shadows in Velázquez paintings didn’t======================================================== those
features was associated with differences in student achievement across
countries. There were similarities too. In every classroom in every country,
teachers relied on two main types of questions.
The more common were “using procedures” questions: basically, practice
at something that was just learned. For instance, take the formula for the
sum of the interior angles of a polygon (180 × (number of polygon sides −

2)), and apply it to polygons on a worksheet. The other common variety
was “making connections” questions, which connected students to a
broader concept, rather than just a procedure. That was more like when the
teacher asked students why the formula works, or made them try to figure
out if it works for absolutely any polygon from a triangle to an octagon.
Both types of questions are useful and both were posed by teachers in every
classroom in every country studied. But an important difference emerged in
what teachers did after they asked a making-connections problem.
Rather than letting students grapple with some confusion, teachers often
responded to their solicitations with hint-giving that morphed a making-
connections problem into a using-procedures one. That is exactly what the
charismatic teacher in the American classroom was doing. Lindsey
Richland, a University of Chicago professor who studies learning, watched
that video with me, and told me that when the students were playing
multiple choice with the teacher, “what they’re actually doing is seeking
rules.” They were trying to turn a conceptual problem they didn’t
understand into a procedural one they could just execute. “We’re very good,
humans are, at trying to do the least amount of work that we have to in
order to accomplish a task,” Richland told me. Soliciting hints toward a
solution is both clever and expedient. The problem is that when it comes to
learning concepts that can be broadly wielded, expedience can backfire.
In the United States, about one-fifth of questions posed to students began
as making-connections problems. But by the time the students were done
soliciting hints from the teacher and solving the problems, a grand total of
zero percent remained making-connections problems. Making-connections
problems did not survive the teacher-student interactions.
Teachers in every country fell into the same trap at times, but in the
higher-performing countries plenty of making-connections problems
remained that way as the class struggled to figure them out. In Japan, a little
more than half of all problems were making-connections problems, and half
of those stayed that way through the solving. An entire class period could
be just one problem with many parts. When a student offered an idea for
how to approach a problem, rather than engaging in multiple choice, the
teacher had them come to the board and put a magnet with their name on it
next to the idea. By the end of class, one problem on a blackboard the size
of an entire wall served as a captain’s log of the class’s collective
intellectual voyage, dead ends and all. Richland originally tried to label the

videotaped lessons with a single topic of the day, “but we couldn’t do it
with Japan,” she said, “because you could engage with these problems
using so much different content.” (There is a specific Japanese word to
describe chalkboard writing that tracks conceptual connections over the
course of collective problem solving: bansho .)
Just as it is in golf, procedure practice is important in math. But when it
comprises the entire math training strategy, it’s a problem. “Students do not
view mathematics as a system ,” Richland and her colleagues wrote. They
view it as just a set of procedures. Like when Patrick was asked how
variable expressions connected to the world, and answered that they were
good for answering questions in math class.
In their research, Richland and her collaborators highlighted the stunning
degree of reliance community college students—41 percent of all
undergraduate students in the United States—have on memorized
algorithms. Asked whether a / 5 or a / 8 is greater, 53 percent of students
answered correctly, barely better than guessing. Asked to explain their
answers, students frequently pointed to some algorithm. Students
remembered that they should focus on the bottom number, but a lot of them
recalled that a larger denominator meant a / 8 was bigger than a / 5. Others
remembered that they should try to get a common denominator, but weren’t
sure why. There were students who reflexively cross-multiplied, because
they knew that’s what you do when you see fractions, even though it had no
relevance to the problem at hand. Only 15 percent of the students began
with broad, conceptual reasoning that if you divide something into five
parts, each piece will be larger than if you divide the same thing into eight
parts. Every single one of those students got the correct answer.
Some of the college students seemed to have unlearned number sense
that most children have, like that adding two numbers gives you a third
comprised of the first two. A student who was asked to verify that 462 +
253 = 715, subtracted 253 from 715, and got 462. When he was asked for
another strategy, he could not come up with subtracting 462 from 715 to see
that it equals 253, because the rule he learned was to subtract the number to
the right of the plus sign to check the answer.
When younger students bring home problems that force them to make
connections, Richland told me, “parents are like, ‘Lemme show you, there’s
a faster, easier way.’” If the teacher didn’t already turn the work into using-
procedures practice, well-meaning parents will. They aren’t comfortable

with bewildered kids, and they want understanding to come quickly and
easily. But for learning that is both durable (it sticks) and flexible (it can be
applied broadly), fast and easy is precisely the problem.
“Some people argue that part of the reason U.S. students don’t do as well on
international measures of high school knowledge is that they’re doing too
well in class,” Nate Kornell, a cognitive psychologist at Williams College,
told me. “What you want is to make it easy to make it hard.”
Kornell was explaining the concept of “desirable difficulties,” obstacles
that make learning more challenging, slower, and more frustrating in the
short term, but better in the long term. Excessive hint-giving, like in the
eighth-grade math classroom, does the opposite; it bolsters immediate
performance, but undermines progress in the long run. Several desirable
difficulties that can be used in the classroom are among the most rigorously
supported methods of enhancing learning, and the engaging eighth-grade
math teacher accidentally subverted all of them in the well-intended interest
of before-your-eyes progress.
One of those desirable difficulties is known as the “generation effect.”
Struggling to generate an answer on your own, even a wrong one, enhances
subsequent learning. Socrates was apparently on to something when he
forced pupils to generate answers rather than bestowing them. It requires
the learner to intentionally sacrifice current performance for future benefit.
Kornell and psychologist Janet Metcalfe tested sixth graders in the South
Bronx on vocabulary learning, and varied how they studied in order to
explore the generation effect. Students were given some of the words and
definitions together. For example, To discuss something in order to come to
an agreement: Negotiate . For others, they were shown only the definition
and given a little time to think of the right word, even if they had no clue,
before it was revealed. When they were tested later, students did way better
on the definition-first words. The experiment was repeated on students at
Columbia University, with more obscure words (Characterized by haughty
scorn: Supercilious ). The results were the same. Being forced to generate
answers improves subsequent learning even if the generated answer is
wrong. It can even help to be wildly wrong. Metcalfe and colleagues have
repeatedly demonstrated a “hypercorrection effect.” The more confident a
learner is of their wrong answer, the better the information sticks when they

subsequently learn the right answer. Tolerating big mistakes can create the
best learning opportunities. 
*
Kornell helped show that the long-run benefits of facilitated screw-ups
extend to primates only slightly less studious than Columbia students.
Specifically, to Oberon and Macduff, two rhesus macaques trained to learn
lists by trial and error. In a fascinating experiment, Kornell worked with an
animal cognition expert to give Oberon and Macduff lists of random
pictures to memorize, in a particular order. (Example: a tulip, a school of
fish, a cardinal, Halle Berry, and a raven.) The pictures were all displayed
simultaneously on a screen. By pressing them in trial-and-error fashion, the
monkeys had to learn the desired order and then practice it repeatedly. But
all practice was not designed equal.
In some practice sessions, Oberon (who was generally brighter) and
Macduff were automatically given hints on every trial, showing them the
next picture in the list. For other lists, they could voluntarily touch a hint
box on the screen whenever they were stuck and wanted to be shown the
next item. For still other lists, they could ask for a hint on half of their
practice attempts. And for a final group of lists, no hints at all.
In the practice sessions with hints upon request, the monkeys behaved a
lot like humans. They almost always requested hints when they were
available, and thus got a lot of the lists right. Overall, they had about 250
trials to learn each list.
After three days of practice, the scientists took off the training wheels.
Starting on day four, the memorizing monkeys had to repeat all the lists
from every training condition without any hints whatsoever. It was a
performance disaster. Oberon only got about one-third of the lists======================================================== “they’ll more likely work hard and it
will look like grit from the outside.”
Because personality changes more than we expect with time, experience,
and different contexts, we are ill-equipped to make ironclad long-term goals
when our past consists of little time, few experiences, and a narrow range of
contexts. Each “story of me” continues to evolve. We should all heed the
wisdom of Alice, who, when asked by the Gryphon in Wonderland to share
her story, decided she had to start with the beginning of her adventure that
very morning. “It’s no use going back to yesterday,” she said, “because I
was a different person then.” Alice captured a grain of truth, one that has
profound consequences for the best way to maximize match quality.

Herminia Ibarra, a professor of organizational behavior at London Business
School, studied how young consultants and bankers advance (or don’t) in
firms she described as up-or-out hierarchies. When she followed up a few
years later, after her project, she found that some of the budding stars either
weren’t there anymore, having embarked on new careers, or were hatching
escape plans.
Ibarra began another study, this time adding web entrepreneurs, lawyers,
doctors, professors, and IT professionals. The focus would be on career
switching. Ibarra tracked ambitious professionals, most in their thirties and
forties, in the United States, United Kingdom, and France who had traveled
a linear career path for a minimum of eight years. Over the course of her
work, she watched midcareer professionals move from a flicker of desire
for change, to an unsettling period of transition, to the actual jump to a new
career. Occasionally she saw the entire process occur twice for the same
individual. When she compiled her findings, the central premise was at
once simple and profound: we learn who we are only by living, and not
before.
Ibarra concluded that we maximize match quality throughout life by
sampling activities, social groups, contexts, jobs, careers, and then
reflecting and adjusting our personal narratives. And repeat. If that sounds
facile, consider that it is precisely the opposite of a vast marketing crusade
that assures customers they can alight on their perfect matches via
introspection alone. A lucrative career and personality quiz and counseling
industry survives on that notion. “All of the strengths-finder stuff, it gives
people license to pigeonhole themselves or others in ways that just don’t
take into account how much we grow and evolve and blossom and discover
new things,” Ibarra told me. “But people want answers, so these
frameworks sell. It’s a lot harder to say, ‘Well, come up with some
experiments and see what happens.’”
If only you fill out this quiz, the promise goes, it will light the way to the
ideal career, never mind what psychologists have documented about
personal change across time and context. Ibarra criticized conventional-
wisdom articles like one in the Wall Street Journal on “the painless path to a
new career,” which decreed that the secret is simply forming “a clear
picture of what you want” before acting.
Instead, she told me, in a clever inversion of a hallowed axiom, “First act
and then think.” Ibarra marshaled social psychology to argue persuasively

that we are each made up of numerous possibilities. As she put it, “We
discover the possibilities by doing, by trying new activities, building new
networks, finding new role models.” We learn who we are in practice, not in
theory.
Think of Frances Hesselbein, who assumed over and over she was just
dipping her toe into something new, until she was near the age when her
peers were retiring and finally realized she had short-term-planned her way
to a vocation. Or Van Gogh, who was certain he found the perfect calling
again and again, only to learn in practice that he was mistaken, until he
wasn’t.
Ibarra documented extreme transitions: Pierre, a thirty-eight-year-old
psychiatrist and bestselling author, became a Buddhist monk after a
winding road that started with meeting a Tibetan lama at a dinner party. And
more quotidian conversions: Lucy, a forty-six-year-old tech manager at a
brokerage firm, was floored by the critical personal feedback she got from
an organizational development consultant, so she hired the woman as a
personal coach. Lucy soon realized she was more inspired to manage
people (an area of weakness, the consultant convinced her) than technology.
Gradually, she attended classes and conferences and tapped the far-flung
fringes of her personal network to get a sense of what was possible. One gig
at a time, a weakness became a strength, and she transitioned into an
organizational development coach herself.
Themes emerged in the transitions. The protagonists had begun to feel
unfulfilled by their work, and then a chance encounter with some world
previously invisible to them led to a series of short-term explorations. At
first, all career changers fell prey to the cult of the head start and figured it
couldn’t possibly make sense to dispense with their long-term plans in favor
of rapidly evolving short-term experiments. Sometimes they tried to talk
themselves out of it. Their confidants advised them not to do anything rash;
don’t change now, they said, just keep the new interest or talent as a hobby.
But the more they dabbled, the more certain they were that it was time for a
change. A new work identity did not manifest overnight, but began with
trying something temporary, Hesselbein style, or finding a new role model,
then reflecting on the experience and moving to the next short-term plan.
Some career changers got richer, others poorer; all felt temporarily behind,
but as in the Freakonomics coin-flip study, they were happier with a
change.

Ibarra’s advice is nearly identical to the short-term planning the Dark
Horse researchers documented. Rather than expecting an ironclad a priori
answer to “Who do I really want to become?,” their work indicated that it is
better to be a scientist of yourself, asking smaller questions that can actually
be tested—“Which among my various possible selves should I start to
explore now? How can I do that?” Be a flirt with your possible selves. 
*
Rather than a grand plan, find experiments that can be undertaken quickly. “
Test-and-learn,” Ibarra told me, “not plan-and-implement.”
Paul Graham, computer scientist and cofounder of Y Combinator—the
start-up funder of Airbnb, Dropbox, Stripe, and Twitch—encapsulated
Ibarra’s tenets in a high school graduation speech he wrote, but never
delivered:
It might seem that nothing would be easier than deciding what you like, but it turns out to be
hard, partly because it’s hard to get an accurate picture of most jobs. . . . Most of the work I’ve
done in the last ten years didn’t exist when I was in high school. . . . In such a world it’s not a
good idea to have fixed plans.
And yet every May, speakers all over the country fire up the Standard Graduation Speech,
the theme of which is: don’t give up on your dreams. I know what they mean, but this is a bad
way to put it, because it implies you’re supposed to be bound by some plan you made early on.
The computer world has a name for this: premature optimization. . . .
. . . Instead of working back from a goal, work forward from promising situations. This is
what most successful people actually do anyway.
In the graduation-speech approach, you decide where you want to be in twenty years, and
then ask: what should I do now to get there? I propose instead that you don’t commit to
anything in the future, but just look at the options available now, and choose those that will
give you the most promising range of options afterward.
What Ibarra calls the “ plan-and-implement” model—the idea that we
should first make a long-term plan and execute without deviation, as
opposed to the “ test-and-learn” model—is entrenched in depictions of
geniuses. Popular lore holds that the sculptor Michelangelo would see a full
figure in a block of marble before he ever touched it, and simply chip away
the excess stone to free the figure inside. It is an exquisitely beautiful
image. It just isn’t true. Art historian William Wallace showed that
Michelangelo was actually a test-and-learn all-star. He constantly changed
his mind and altered his sculptural plans as he worked. He left three-fifths
of his sculptures unfinished, each time moving on to something more
promising. The first line of Wallace’s analysis: “Michelangelo did not
expound a theory of art.” He tried, then went from there. He was a sculptor,
painter, master architect, and made engineering designs for fortifications in

Florence. In his late twenties he even pushed visual art aside to spend time
writing poems (including one about how much he grew to dislike painting),
half of which he left unfinished.
Like anyone eager to raise their match quality prospects, Michelangelo
learned who he was—and whom he was carving—in practice, not in theory.
He started with an idea, tested it, changed it, and readily abandoned it for a
better project fit. Michelangelo might have fit well in Silicon Valley; he was
a relentless iterator. He worked according to Ibarra’s new aphorism: “I
know who I am when I see what I do.”
Full disclosure: after researching the Dark Horse Project, I got recruited
into it, by virtue of a winding career path of short-term plans. The work
resonated with me, partly because of my own experiences, but even more so
because it describes a roster of people I admire.
The nonfiction writer and filmmaker Sebastian Junger was twenty-nine
and working as an arborist, harnessed in the upper canopy of a pine tree,
when he tore open his leg with a chainsaw and got the idea to write about
dangerous jobs. He was still limping two months later when a fishing vessel
out of Gloucester, Massachusetts, where he lived, was lost at sea.
Commercial fishing provided his topic; the result was The Perfect Storm.
Junger stuck with the theme of dangerous jobs, and made======================================================== retention
bonuses—just cash payments to junior officers if they agreed to serve a few
more years. It cost taxpayers $500 million, and was a massive waste.
Officers who had planned to stay anyway took it, and those who already
planned to leave did not. The Army learned a hard lesson: the problem was
not a financial one; it was a matching one.
In the industrial era, or the “company man” era, as the monograph
authors called it, “firms were highly specialized,” with employees generally
tackling the same suite of challenges repeatedly. Both the culture of the
time—pensions were pervasive and job switching might be viewed as
disloyal—and specialization were barriers to worker mobility outside of the

company. Plus, there was little incentive for companies to recruit from
outside when employees regularly faced kind learning environments, the
type where repetitive experience alone leads to improvement. By the 1980s,
corporate culture was changing. The knowledge economy created
“overwhelming demand for . . . employees with talents for
conceptualization and knowledge creation.” Broad conceptual skills now
helped in an array of jobs, and suddenly control over career trajectory
shifted from the employer, who looked inward at a ladder of opportunity, to
the employee, who peered out at a vast web of possibility. In the private
sector, an efficient talent market rapidly emerged as workers shuffled
around in pursuit of match quality. While the world changed, the Army
stuck with the industrial-era ladder.
The West Point professors explained that the Army, like many
bureaucratic organizations, missed out on match quality markets. “There is
no talent matching market mechanism,” they wrote. When a junior officer
changed direction and left the Army, it did not signal a loss of drive. It
signaled that a strong drive for personal development had changed the
officer’s goals entirely. “I’ve yet to meet a classmate who left the Army and
regretted it,” said Ashley Nicolas, the former intelligence officer. She went
on to become a math teacher and then a lawyer. She added that all were
grateful for the experience, even though it didn’t become a lifelong career.
While the private sector adjusted to the burgeoning need for high match
quality, the Army just threw money at people. It has, though, begun to
subtly change. That most hierarchical of entities has found success
embracing match flexibility. The Officer Career Satisfaction Program was
designed so that scholarship-ROTC and West Point graduates can take more
control of their own career progression. In return for three additional years
of active service, the program increased the number of officers who can
choose a branch (infantry, intelligence, engineering, dental, finance,
veterinary, communication technology, and many more), or a geographic
post. Where dangling money for junior officers failed miserably, facilitating
match quality succeeded. In the first four years of the program, four
thousand cadets agreed to extend their service commitments in exchange
for choice. 
*
It is just a small step. When Defense Secretary Ash Carter visited West
Point in 2016 for student meetings, he was flooded with concerns from very
gritty cadets about rigid career paths that did not allow them to adjust to

their own development. Carter had pledged to drastically reshape the
Army’s “industrial era” personnel management from the strict “up-or-out”
model to one that allows officers a shot to improve their own match quality
as they grow.
When they were high school graduates, with few skills and little
exposure to a world of career options, West Point cadets might easily have
answered “Not like me at all” to the Grit Scale statement “I often set a goal
but later choose to pursue a different one.” A few years later, with more
knowledge of their skills and preferences, choosing to pursue a different
goal was no longer the gritless route; it was the smart one .
Intuitively, grit research appeals to me. In the nonscientific, colloquial use
of the word, I tend to think I have a lot of it. After running track and playing
football, basketball, and baseball at a large public high school—and I’m
only five foot six—I walked on to a Division I track team in college as an
800-meter runner.
I was not close to the worst 800 runner on my college team freshman
year; I was the worst, by a landslide. I was allowed to keep practicing with
the team because as long as you are not chosen for travel, it doesn’t cost
anybody anything, not even the pair of shoes the recruits got. When the
traveling team went to South Carolina to train over spring break, I stayed on
the eerily quiet campus rather than going home, to train without distraction.
I stuck with it for two miserable years of vomit-inducing workouts and ego-
bruising races, while blue-chip recruits quit and were replaced by others.
There were plenty of days (and weeks, and an entire month or three) when I
felt like I should probably quit. But I was learning about the kind of training
that worked for me, and I was improving. In my senior season, I cracked the
university’s all-time top ten list indoors, was twice All-East, and part of a
relay that set the university record. The only other guy in my class who held
a university record was my gritty roommate, the other walk-on. Nearly the
entire recruited class from our year quit. Hilariously, I was awarded the
Gustave A. Jaeger Memorial Prize for the athlete who “achieved significant
athletic success in the face of unusual challenge and difficulty”—my
“unusual challenge and difficulty” just being that I epically stunk at first.
After the presentation, the head coach, with whom I’d had little direct

conversation as a walk-on, shared that he had felt sorry for me watching
workouts my freshman year.
There’s nothing particularly special about that story—it exists on every
team. But I think it is indicative of my approach to work. Nonetheless, I
scored at the 50th percentile on the Grit Scale compared to American adults
at large. I racked up points for assessing myself as a very hard worker who
is not discouraged by setbacks, but I missed a lot of points for confessing
that “my interests change from year to year,” and, like so many West Point
graduates, I sometimes “set a goal but later choose to pursue a different
one.” When I was seventeen and positive that I was going to go to the U.S.
Air Force Academy to become a pilot and then an astronaut, I probably
would have self-assessed at the very top of the Grit Scale. I got all the way
to Chicago-area congressman Sidney Yates agreeing to provide a
nomination.
But I never did any of that. Instead, at the last minute I changed my mind
and went elsewhere to study political science. I took a single poli-sci class,
and ended up majoring in Earth and environmental sciences and minoring
in astronomy, certain I would become a scientist. I worked in labs during
and after college and realized that I was not the type of person who wanted
to spend my entire life learning one or two things new to the world, but
rather the type who wanted constantly to learn things new to me and share
them. I transitioned from science to journalism; my first job was as a
midnight-shift street reporter in New York City. (Nothing happy that’s
going in the New York Daily News happens between midnight and 10 a.m.)
Growing self-knowledge kept changing my goals and interests until I
landed in a career the very lifeblood of which is investigating broad
interests. When I later worked at Sports Illustrated , determined students
would ask me whether it was better to study journalism or English to work
at SI . I told them I had no clue, but that a statistics or biology course never
hurt anyone.
I don’t think I have become less passionate or resilient over time, nor do I
think that all those former West Point cadets who left the Army lost the
drive that got them there in the first place. It makes sense to me that grit
would be powerfully predictive for cadets trying to get through their
rigorous orientation, or for a sample of schoolchildren or spelling bee
contestants. Very young people often have their goals set for them, or at
least have a limited menu to choose from, and pursuing them with passion

and resilience is the main challenge. The same goes for 800 runners. One of
the compelling aspects of sports goals is how straightforward and easily
measurable they are. On the final weekend of the 2018 Winter Olympics,
Sasha Cohen, a 2006 silver medalist figure skater, wrote an advice column
to retiring athletes. “Olympic athletes need to understand that the rules for
life are different from the rules for sports,” she wrote. “Yes, striving to
accomplish a single overarching goal every day means you have grit,
determination and resilience. But the ability to pull yourself together
mentally and physically in competition is different from the new challenges
that await you. So after you retire, travel, write a poem, try to start your
own business, stay out a little too late, devote time to something that
doesn’t have a clear end goal.” In the wider world of work, finding a goal
with high match quality in the first place is the greater challenge, and
persistence for the sake of persistence can get in the way.
A recent international Gallup survey of more than two hundred thousand
workers in 150 countries reported that 85 percent were either “not engaged”
with their work or “actively disengaged.” In that condition, according to
Seth Godin, quitting takes a lot more guts than continuing to be carried
along like debris on an ocean wave. The trouble, Godin noted, is that
humans are bedeviled by the “sunk cost fallacy.” Having invested time or
money in something, we are loath to leave it, because that would mean we
had wasted our time or money, even though it is already gone. Writer,
psychology PhD, and professional poker player Maria Konnikova explained
in her book The Confidence Game how the sunk cost mindset is so======================================================== “they’ll more likely work hard and it
will look like grit from the outside.”
Because personality changes more than we expect with time, experience,
and different contexts, we are ill-equipped to make ironclad long-term goals
when our past consists of little time, few experiences, and a narrow range of
contexts. Each “story of me” continues to evolve. We should all heed the
wisdom of Alice, who, when asked by the Gryphon in Wonderland to share
her story, decided she had to start with the beginning of her adventure that
very morning. “It’s no use going back to yesterday,” she said, “because I
was a different person then.” Alice captured a grain of truth, one that has
profound consequences for the best way to maximize match quality.

Herminia Ibarra, a professor of organizational behavior at London Business
School, studied how young consultants and bankers advance (or don’t) in
firms she described as up-or-out hierarchies. When she followed up a few
years later, after her project, she found that some of the budding stars either
weren’t there anymore, having embarked on new careers, or were hatching
escape plans.
Ibarra began another study, this time adding web entrepreneurs, lawyers,
doctors, professors, and IT professionals. The focus would be on career
switching. Ibarra tracked ambitious professionals, most in their thirties and
forties, in the United States, United Kingdom, and France who had traveled
a linear career path for a minimum of eight years. Over the course of her
work, she watched midcareer professionals move from a flicker of desire
for change, to an unsettling period of transition, to the actual jump to a new
career. Occasionally she saw the entire process occur twice for the same
individual. When she compiled her findings, the central premise was at
once simple and profound: we learn who we are only by living, and not
before.
Ibarra concluded that we maximize match quality throughout life by
sampling activities, social groups, contexts, jobs, careers, and then
reflecting and adjusting our personal narratives. And repeat. If that sounds
facile, consider that it is precisely the opposite of a vast marketing crusade
that assures customers they can alight on their perfect matches via
introspection alone. A lucrative career and personality quiz and counseling
industry survives on that notion. “All of the strengths-finder stuff, it gives
people license to pigeonhole themselves or others in ways that just don’t
take into account how much we grow and evolve and blossom and discover
new things,” Ibarra told me. “But people want answers, so these
frameworks sell. It’s a lot harder to say, ‘Well, come up with some
experiments and see what happens.’”
If only you fill out this quiz, the promise goes, it will light the way to the
ideal career, never mind what psychologists have documented about
personal change across time and context. Ibarra criticized conventional-
wisdom articles like one in the Wall Street Journal on “the painless path to a
new career,” which decreed that the secret is simply forming “a clear
picture of what you want” before acting.
Instead, she told me, in a clever inversion of a hallowed axiom, “First act
and then think.” Ibarra marshaled social psychology to argue persuasively

that we are each made up of numerous possibilities. As she put it, “We
discover the possibilities by doing, by trying new activities, building new
networks, finding new role models.” We learn who we are in practice, not in
theory.
Think of Frances Hesselbein, who assumed over and over she was just
dipping her toe into something new, until she was near the age when her
peers were retiring and finally realized she had short-term-planned her way
to a vocation. Or Van Gogh, who was certain he found the perfect calling
again and again, only to learn in practice that he was mistaken, until he
wasn’t.
Ibarra documented extreme transitions: Pierre, a thirty-eight-year-old
psychiatrist and bestselling author, became a Buddhist monk after a
winding road that started with meeting a Tibetan lama at a dinner party. And
more quotidian conversions: Lucy, a forty-six-year-old tech manager at a
brokerage firm, was floored by the critical personal feedback she got from
an organizational development consultant, so she hired the woman as a
personal coach. Lucy soon realized she was more inspired to manage
people (an area of weakness, the consultant convinced her) than technology.
Gradually, she attended classes and conferences and tapped the far-flung
fringes of her personal network to get a sense of what was possible. One gig
at a time, a weakness became a strength, and she transitioned into an
organizational development coach herself.
Themes emerged in the transitions. The protagonists had begun to feel
unfulfilled by their work, and then a chance encounter with some world
previously invisible to them led to a series of short-term explorations. At
first, all career changers fell prey to the cult of the head start and figured it
couldn’t possibly make sense to dispense with their long-term plans in favor
of rapidly evolving short-term experiments. Sometimes they tried to talk
themselves out of it. Their confidants advised them not to do anything rash;
don’t change now, they said, just keep the new interest or talent as a hobby.
But the more they dabbled, the more certain they were that it was time for a
change. A new work identity did not manifest overnight, but began with
trying something temporary, Hesselbein style, or finding a new role model,
then reflecting on the experience and moving to the next short-term plan.
Some career changers got richer, others poorer; all felt temporarily behind,
but as in the Freakonomics coin-flip study, they were happier with a
change.

Ibarra’s advice is nearly identical to the short-term planning the Dark
Horse researchers documented. Rather than expecting an ironclad a priori
answer to “Who do I really want to become?,” their work indicated that it is
better to be a scientist of yourself, asking smaller questions that can actually
be tested—“Which among my various possible selves should I start to
explore now? How can I do that?” Be a flirt with your possible selves. 
*
Rather than a grand plan, find experiments that can be undertaken quickly. “
Test-and-learn,” Ibarra told me, “not plan-and-implement.”
Paul Graham, computer scientist and cofounder of Y Combinator—the
start-up funder of Airbnb, Dropbox, Stripe, and Twitch—encapsulated
Ibarra’s tenets in a high school graduation speech he wrote, but never
delivered:
It might seem that nothing would be easier than deciding what you like, but it turns out to be
hard, partly because it’s hard to get an accurate picture of most jobs. . . . Most of the work I’ve
done in the last ten years didn’t exist when I was in high school. . . . In such a world it’s not a
good idea to have fixed plans.
And yet every May, speakers all over the country fire up the Standard Graduation Speech,
the theme of which is: don’t give up on your dreams. I know what they mean, but this is a bad
way to put it, because it implies you’re supposed to be bound by some plan you made early on.
The computer world has a name for this: premature optimization. . . .
. . . Instead of working back from a goal, work forward from promising situations. This is
what most successful people actually do anyway.
In the graduation-speech approach, you decide where you want to be in twenty years, and
then ask: what should I do now to get there? I propose instead that you don’t commit to
anything in the future, but just look at the options available now, and choose those that will
give you the most promising range of options afterward.
What Ibarra calls the “ plan-and-implement” model—the idea that we
should first make a long-term plan and execute without deviation, as
opposed to the “ test-and-learn” model—is entrenched in depictions of
geniuses. Popular lore holds that the sculptor Michelangelo would see a full
figure in a block of marble before he ever touched it, and simply chip away
the excess stone to free the figure inside. It is an exquisitely beautiful
image. It just isn’t true. Art historian William Wallace showed that
Michelangelo was actually a test-and-learn all-star. He constantly changed
his mind and altered his sculptural plans as he worked. He left three-fifths
of his sculptures unfinished, each time moving on to something more
promising. The first line of Wallace’s analysis: “Michelangelo did not
expound a theory of art.” He tried, then went from there. He was a sculptor,
painter, master architect, and made engineering designs for fortifications in

Florence. In his late twenties he even pushed visual art aside to spend time
writing poems (including one about how much he grew to dislike painting),
half of which he left unfinished.
Like anyone eager to raise their match quality prospects, Michelangelo
learned who he was—and whom he was carving—in practice, not in theory.
He started with an idea, tested it, changed it, and readily abandoned it for a
better project fit. Michelangelo might have fit well in Silicon Valley; he was
a relentless iterator. He worked according to Ibarra’s new aphorism: “I
know who I am when I see what I do.”
Full disclosure: after researching the Dark Horse Project, I got recruited
into it, by virtue of a winding career path of short-term plans. The work
resonated with me, partly because of my own experiences, but even more so
because it describes a roster of people I admire.
The nonfiction writer and filmmaker Sebastian Junger was twenty-nine
and working as an arborist, harnessed in the upper canopy of a pine tree,
when he tore open his leg with a chainsaw and got the idea to write about
dangerous jobs. He was still limping two months later when a fishing vessel
out of Gloucester, Massachusetts, where he lived, was lost at sea.
Commercial fishing provided his topic; the result was The Perfect Storm.
Junger stuck with the theme of dangerous jobs, and made======================================================== History of Nintendo, vol. 2,
1980–1991 ( Triel-sur-Seine: Pix’N Love, 2012); E. Voskuil, Before Mario: The Fantastic Toys from
the Video Game Giant’s Early Days (Châtillon: Omaké Books, 2014); J. Parish, Game Boy World
1989 (Norfolk, VA: CreateSpace, 2016); D. Sheff, Game Over: How Nintendo Conquered the World
(New York: Vintage, 2011).
“I didn’t want to leave Kyoto”: For source note on Yokoi’s quotes, see footnote on p. 192 .
“snow melts in sunlight”: Gorges with Yamazaki, The History of Nintendo, vol. 2 , 1980–1991.
“lateral thinking”: E. de Bono, Lateral Thinking: Creativity Step by Step (New York: HarperCollins,
2010).
delicately embossed the screen: Yokoi’s often simple patents are a treasure trove of invention
history. This patent (U.S. no. 4398804) and others can be found using Google Patents.
118.7 million units: B. Edwards, “Happy 20th b-day, Game Boy,” Ars Technica, April 21, 2009.
“It was difficult”; “ ‘snowman ’ ”; “grim expression”: shmuplations.com (translation), “Console
Gaming Then and Now: A Fascinating 1997 Interview with Nintendo’s Legendary Gunpei Yokoi,”
techspot.com , July 10, 2015.
the “candle problem”: For an excellent description, see D. Pink, Drive (New York: Riverhead,
2011).
“Electronics was not Yokoi’s strong point”: Satoru Okada’s foreword in Before Mario .
“design and interface”: IGN staff, “Okada on the Game Boy Advance,” IGN.com , Sep. 13, 2000.
“If I can speak”: M. Kodama, Knowledge Integration Dynamics (Singapore: World Scientific): 211.
“simply innovated in a different way”: C. Christensen and S. C. Anthony, “What Should Sony Do
Next?,” Forbes, August 1, 2007, online ed.
focused frogs and visionary birds: F. Dyson, “Bird and Frogs,” Notices of the American
Mathematical Society 56, no. 2 (2009): 212–23. (Dyson may be a math frog, but he is also an
excellent writer.)
multilayer optical film: M. F. Weber et al., “Giant Birefringent Optics in Multilayer Polymer
Mirrors,” Science 287 (2000): 2451–56; and R. F. Service, “Mirror Film Is the Fairest of Them All,”
Science 287 (2000): 2387–89.
blue morpho: R. Ahmed et al., “Morpho Butterfly-Inspired Optical Diffraction, Diffusion, and Bio-
chemical Sensing,” RSC Advances 8 (2018): 27111–18.
“It’s in front of you literally every day”: Ouderkirk’s talk at TEDxHHL, October 14, 2016.

set out to study inventors at 3M: W. F. Boh, R. Evaristo, and A. Ouderkirk, “Balancing Breadth and
Depth of Expertise for Innovation: A 3M Story,” Research Policy 43 (2013): 349–66.
“nobody ever told me”: Ouderkirk’s talk at TEDxHHL, October 14, 2016.
the state of Iowa alone: G. D. Glenn and R. L. Poole, The Opera Houses of Iowa (Ames: Iowa State
University Press, 1993). For a broader discussion of this phenomenon, see R. H. Frank, Luxury Fever
(New York: The Free Press, 1999), ch. 3.
relationship between R& D spending and performance: B. Jaruzelski et al., “Proven Paths to
Innovation Success,” Strategy+ Business, winter 2014, issue 77 preprint.
They analyzed fifteen years of tech patents: E. Melero and N. Palomeras, “The Renaissance Man
Is Not Dead! The Role of Generalists in Teams of Inventors,” Research Policy 44 (2015): 154–67.
comic books: A. Taylor and H. R. Greve, “Superman or the Fantastic Four? Knowledge Combination
and Experience in Innovative Teams,” Academy of Management Journal 49, no. 4 (2006): 723–40.
Wertham manipulated: C. L. Tilley, “Seducing the Innocent: Fredric Wertham and the
Falsifications That Helped Condemn Comics,” Information and Culture 47, no. 4 (2012): 383-413.
specialized surgeons get better outcomes: M. Maruthappu et al., “The Influence of Volume and
Experience on Individual Surgical Performance: A Systematic Review,” Annals of Surgery 261, no. 4
(2015): 642–47; N. R. Sahni et al., “Surgeon Specialization and Operative Mortality in the United
States: Retrospective Analysis,” BMJ 354 (2016): i3571; A. Kurmann et al., “Impact of Team
Familiarity in the Operating Room on Surgical Complications,” World Journal of Surgery 38, no. 12
(2014): 3047–52; M. Maruthappu, “The Impact of Team Familiarity and Surgical Experience on
Operative Efficiency,” Journal of the Royal Society of Medicine 109, no. 4 (2016): 147–53.
analyzed its database of major flight accidents: “A Review of Flightcrew-Involved Major
Accidents of U.S. Air Carriers, 1978 Through 1990,” National Transportation Safety Board, Safety
Study NTSB/ SS-94/ 01, 1994.
University of Utah professor Abbie Griffin: A. Griffin, R. L. Price, and B. Vojak, Serial
Innovators: How Individuals Create and Deliver Breakthrough Innovations in Mature Firms
(Stanford, CA: Stanford Business Books, 2012 [Kindle ebook]).
“could be considered a professional outsider”: D. K. Simonton, Origins of Genius (Oxford:
Oxford University Press, 1999).
“unwilling to spend more time on the subject”; Howard Gruber: H. E. Gruber, Darwin on Man:
A Psychological Study of Scientific Creativity (Chicago: University of Chicago Press, 1981).
at least 231 scientific pen pals; experiments with seeds: T. Veak, “Exploring Darwin’s
Correspondence,” Archives of Natural History 30, no. 1 (2003): 118–38.
“bewildering miscellany”: H. E. Gruber, “The Evolving Systems Approach to Creative Work,”
Creativity Research Journal 1, no.1 (1988): 27–51.
“a lot of apps open in my brain”: R. Mead, “All About the Hamiltons,” The New Yorker , February.
9, 2015.
CHAPTER 10:FOOLED BY EXPERTISE
The bet was on: Yale history professor Paul Sabin’s book The Bet (New Haven, CT: Yale University
Press, 2013) gives fascinating background and analysis. A shorter sample of that analysis is C. R.
Sunstein, “The Battle of Two Hedgehogs,” New York Review of Books, December 5, 2013.
“population growth curve”: P. Ehrlich, Eco-Catastrophe! (San Francisco: City Lights Books,
1969).

“green revolution”: G. S. Morson and M. Schapiro, Cents and Sensibility (Princeton, NJ: Princeton
University Press, 2017 [Kindle ebook]).
the food supply per person increased: This and other statistics in the paragraph (share of
undernourished citizens; death rate from famine; birth rates; population growth trajectory) come from
the incredible online publication Our World in Data, founded by University of Oxford economist
Max Roser. The supply of calories per person per day, for example, can be found here:
https://slides.our world-indata.org/hunger-and-food-provision/#/kcalcapitaday-by-world-regions-
mg.png .
United Nations projects: United Nations, Department of Economic and Social Affairs, Population
Division, “World Population Prospects: The 2017 Revision, Key Findings and Advance Tables,”
Working Paper No. ESA/ P/ WP/ 248.
“now the population bomb has detonated”: P. R. Ehrlich and A. H. Ehrlich, The Population
Explosion (New York: Simon & Schuster, 1990).
When economists later examined: K. Kiel et al., “Luck or Skill? An Examination of the Ehrlich-
Simon Bet,” Ecological Economics 69, no. 7 (2010): 1365–67.
Tetlock decided to put: Tetlock gives the results of his work in great (and witty) detail in Expert
Political Judgment: How Good Is It? How Can We Know? (Princeton, NJ: Princeton University
Press, 2005).
“curiously inverse relationship”: Tetlock, Expert Political Judgment .
Superforecasters’ online interactions: P. E. Tetlock et al., “Bringing Probability Judgments into
Policy Debates via Forecasting Tournaments,” Science 355 (2017): 481–83.
“ Forecasts of dollar-euro exchange rates”: G. Gigerenzer, Risk Savvy (New York: Penguin, 2014).
“active open-mindedness”; “myside” ideas: J. Baron et al., “Reflective Thought and Actively
Open-Minded Thinking,” in Individual Differences in Judgment and Decision Making, ed. M. E.
Toplak and J. A. Weller (New York: Routledge, 2017 [Kindle ebook]).
never mind seriously entertain them: J. A. Frimer et al., “Liberals and Conservatives Are Similarly
Motivated to Avoid Exposure to One Another’s Opinions,” Journal of Experimental Social
Psychology 72 (2017): 1–12.
study during the run-up to the Brexit vote: Online Privacy Foundation, “Irrational Thinking and
the EU Referendum Result” (2016).
skin cream and gun control: D. Kahan et al., “Motivated Numeracy and Enlightened Self-
Government,” Behavioural Public Policy 1, no. 1 (2017): 54–86.
Not science knowledge, science curiosity : D. M. Kahan et al., “Science Curiosity and Political
Information Processing,” Advances in Political Psychology 38, no. 51 (2017): 179–99.
“Depth can be inadequate”: Baron et al., “Reflective Thought and Actively Open-Minded
Thinking.”
first four models: H. E. Gruber, Darwin on Man: A Psychological Study of Scientific Creativity ,
127.
“views therein advocated”: The Autobiography of Charles Darwin .
“In one of the most remarkable interchanges”: J. Browne, Charles Darwin: A Biography, vol. 1,
Voyaging (New York: Alfred A. Knopf, 1995), 186.
Einstein was a hedgehog: For one of many references to Einstein’s hedgehoginess, see Morson and
Schapiro, Cents and Sensibility .
“A consensus seems to exist”: G. Mackie, “Einstein’s Folly,” The Conversation, November 29,
2015.

Niels Bohr . . . replied: C. P. Snow, The Physicists , (London: Little, Brown and Co., 1981). Einstein
also expresses this idea in: H. Dukas and B. Hoffmann eds., Albert Einstein, The Human Side:
Glimpses from His Archive s (Princeton, NJ: Princeton University Press, 1979), 68.
In four straight years: W. Chang et al., “Developing Expert Political Judgment: The Impact of
Training and Practice on Judgmental Accuracy in Geopolitical Forecasting Tournaments,” Judgment
and Decision Making 11, no. 5 (2016): 509–26.
CHAPTER 11: LEARNING TO DROP YOUR FAMILIAR TOOLS
It was early afternoon in fall: Professor Max Bazerman kindly allowed me to observe the Carter
Racing case study at the Harvard Business School over the course of two days in October 2016. (The
case study was created in 1986 by Jack W. Brittain and Sim B. Sitkin.)
“professional weakness shared by all”: F. Lighthall, “Launching the Space Shuttle Challenger:
Disciplinary Deficiencies in the Analysis of Engineering Data,” IEEE Transactions on======================================================== of a naval clash
claiming more than ten lives in the East China Sea? Forecasters could
update predictions as often as they wanted, but the scoring system rewarded
accuracy over time, so a great prediction at the last minute before a
question’s end date was of limited value.
The team run by Tetlock and Mellers was called the Good Judgment
Project. Rather than recruit decorated experts, in the first year of the
tournament they made an open call for volunteers. After a simple screening,
they invited thirty-two hundred to start forecasting. From those, they
identified a small group of the foxiest forecasters—just bright people with
wide-ranging interests and reading habits but no particular relevant
background—and weighted team forecasts toward them. They destroyed the
competition.
In year two, the Good Judgment Project randomly arranged the top
“superforecasters” into online teams of twelve, so that they could share
information and ideas. They beat the other university-run teams so badly
that IARPA dropped those lesser competitors from the tournament. The
volunteers drawn from the general public beat experienced intelligence
analysts with access to classified data “by margins that remain classified,”

according to Tetlock. (He has, though, referenced a Washington Post report
indicating that the Good Judgment Project performed about 30 percent
better than a collection of intelligence community analysts.)
Not only were the best forecasters foxy as individuals, they had qualities
that made them particularly effective collaborators—partners in sharing
information and discussing predictions. Every team member still had to
make individual predictions, but the team was scored by collective
performance. On average, forecasters on the small superteams became 50
percent more accurate in their individual predictions. Superteams beat the
wisdom of much larger crowds—in which the predictions of a large group
of people are averaged—and they also beat prediction markets, where
forecasters “trade” the outcomes of future events like stocks, and the market
price represents the crowd prediction.
It might seem like the complexity of predicting geopolitical and
economic events would necessitate a group of narrow specialists, each
bringing to the team extreme depth in one area. But it was actually the
opposite. As with comic book creators and inventors patenting new
technologies, in the face of uncertainty, individual breadth was critical. The
foxiest forecasters were impressive alone, but together they exemplified the
most lofty ideal of teams: they became more than the sum of their parts. A
lot more.
A few of the qualities that make the best Good Judgment Project forecasters
valuable teammates are obvious from talking to them. They are bright, but
so were the hedgehog experts Tetlock started with. They toss around
numbers easily, estimating this country’s poverty rate or that state’s
proportion of farmland. And they have range.
Scott Eastman told me that he “never completely fit in one world.” He
grew up in Oregon and competed in math and science contests, but in
college he studied English literature and fine arts. He has been a bicycle
mechanic, a housepainter, founder of a housepainting company, manager of
a multimillion-dollar trust, a photographer, a photography teacher, a lecturer
at a Romanian university—in subjects ranging from cultural anthropology
to civil rights—and, most unusually, chief adviser to the mayor of Avrig, a
small town in the middle of Romania. In that role, he did everything from

helping integrate new technologies into the local economy to dealing with
the press and participating in negotiations with Chinese business leaders.
Eastman narrates his life like a book of fables; each experience comes
with a lesson. “I think that housepainting was probably one of the greatest
helps,” he told me. It afforded him the chance to interact with a diverse
palette of colleagues and clients, from refugees seeking asylum to Silicon
Valley billionaires whom he would chat with if he had a long project
working on their homes. He described it as fertile ground for collecting
perspectives. But housepainting is probably not a singular education for
geopolitical prediction. Eastman, like his teammates, is constantly
collecting perspectives anywhere he can, always adding to his intellectual
range, so any ground is fertile for him.
Eastman was uncannily accurate at predicting developments in Syria, and
surprised to learn that Russia was his weak spot. He studied Russian and
has a friend who was a former ambassador to Russia. “I should have every
leg up there, but I saw over a large series of questions, it was one of my
weakest areas,” he told me. He learned that specializing in a topic
frequently did not bear fruit in the forecasts. “So if I know somebody [on
the team] is a subject area expert, I am very, very happy to have access to
them, in terms of asking questions and seeing what they dig up. But I’m not
going to just say, ‘Okay, the biochemist said a certain drug is likely to come
to market, so he must be right.’ Often if you’re too much of an insider, it’s
hard to get good perspective.” Eastman described the core trait of the best
forecasters to me as: “genuinely curious about, well, really everything.”
Ellen Cousins researches fraud for trial lawyers. Her research naturally
roams from medicine to business. She has wide-ranging interests on the
side, from collecting historical artifacts to embroidery, laser etching, and
lock picking. She conducts pro bono research on military veterans who
should (and sometimes do) get upgraded to the Medal of Honor. She felt
exactly the same as Eastman. Narrow experts are an invaluable resource,
she told me, “but you have to understand that they may have blinders on. So
what I try to do is take facts from them, not opinions.” Like polymath
inventors, Eastman and Cousins take ravenously from specialists and
integrate.
Superforecasters’ online interactions are exercises in extremely polite
antagonism, disagreeing without being disagreeable. Even on a rare
occasion when someone does say, “ ‘You’re full of beans, that doesn’t make

sense to me, explain this,’” Cousins told me, “they don’t mind that.”
Agreement is not what they are after; they are after aggregating
perspectives, lots of them. In an impressively unsightly image, Tetlock
described the very best forecasters as foxes with dragonfly eyes. Dragonfly
eyes are composed of tens of thousands of lenses, each with a different
perspective, which are then synthesized in the dragonfly’s brain.
One forecast discussion I saw was a team trying to predict the highest
single-day close for the exchange rate between the U.S. dollar and
Ukrainian hryvnia during an extremely volatile stretch in 2014. Would it be
less than 10, between 10 and 13, or more than 13? The discussion started
with a team member offering percentage predictions for each of the three
possibilities, and sharing an Economist article. Another team member
chimed in with a Bloomberg link and online historical data, and offered
three different probability predictions, with “between 10 and 13” favored. A
third teammate was convinced by the second’s argument. A fourth shared
information about the dire state of Ukrainian finances. A fifth addressed the
broader issue of how exchange rates change, or don’t, in relation to world
events. The teammate who started the conversation then posted again; he
was persuaded by the previous arguments and altered his predictions, but
still thought they were overrating the possibility of “more than 13.” They
continued to share information, challenge one another, and update their
forecasts. Two days later, a team member with specific expertise in finance
saw that the hryvnia was strengthening amid events he thought would
surely weaken it. He chimed in to inform his teammates that this was
exactly the opposite of what he expected, and that they should take it as a
sign of something wrong in his understanding. In contrast to politicians, the
most adept predictors flip-flop like crazy. The team finally homed in on
“between 10 and 13” as the heavy favorite, and they were correct.
In separate work, from 2000 to 2010 German psychologist Gerd
Gigerenzer compiled annual dollar-euro exchange rate predictions made by
twenty-two of the most prestigious international banks—Barclays,
Citigroup, JPMorgan Chase, Bank of America Merrill Lynch, and others.
Each year, every bank predicted the end-of-year exchange rate.
Gigerenzer’s simple conclusion about those projections, from some of the
world’s most prominent specialists: “Forecasts of dollar-euro exchange
rates are worthless.” In six of the ten years, the true exchange rate fell
outside the entire range of all twenty-two bank forecasts. Where a

superforecaster quickly highlighted a change in exchange rate direction that
confused him, and adjusted, major bank forecasts missed every single
change of direction in the decade Gigerenzer analyzed.
A hallmark of interactions on the best teams is what psychologist Jonathan
Baron termed “active open-mindedness.” The best forecasters view their
own ideas as hypotheses in need of testing. Their aim is not to convince
their teammates of their own expertise, but to encourage their teammates to
help them falsify their own notions. In the sweep of humanity, that is not
normal. Asked a difficult question—for example, “Would providing more
money for public schools significantly improve the quality of teaching and
learning?”—people naturally come up with a deluge of “myside” ideas.
Armed with a web browser, they don’t start searching for why they are
probably wrong. It is not that we are unable to come up with contrary ideas,
it is just that our strong instinct is not to.
Researchers in Canada and the United States began a 2017 study by
asking a politically diverse and well-educated group of adults to read
arguments confirming their beliefs about controversial issues. When
participants======================================================== for Champions (New York:
Random House Puzzles & Games, 2006), x.
“Human creativity was even more paramount”; “My advantage in calculating”: Kasparov and
Greengard, Deep Thinking .
“freestyle chess”: For an excellent discussion of human-computer chess partnerships, see: T. Cowen,
Average is Over (New York: Dutton, 2013).
His teammate, Nelson Hernandez: Hernandez kindly engaged in an extended back-and-forth,
explaining to me the nuances of freestyle chess and providing me with documentation about
tournaments. He estimated that Williams’s Elo rating in traditional chess would be about 1800.
In 2007, National Geographic TV: The program was “My Brilliant Brain.”
The first took place in the 1940s: A. D. de Groot, Thought and Choice in Chess (Amsterdam:
Amsterdam University Press, 2008).
added a wrinkle: Chase and Simon’s chunking theory: W. G. Chase and H. A. Simon, “Perception in
Chess,” Cognitive Psychology 4 (1973): 55–81.
if rigorous training had not begun by age twelve: F. Gobet and G. Campitelli, “The Role of
Domain-Specific Practice, Handedness, and Starting Age in Chess,” Developmental Psychology 43
(2007): 159–72. For the different rates at which individuals progress, see: G. Campitelli and F.
Gobet, “The Role of Practice in Chess: A Longitudinal Study,” Learning and Individual Differences
18, no. 4 (2007): 446–58.
Treffert studied savants: Treffert shared with me videos from his library of documentation on
savants. His book Islands of Genius (London: Jessica Kingsley Publishers, 2012) is a great account
of his research.
“What I heard seemed so unlikely”: A. Ockelford, “Another Exceptional Musical Memory,” in
Music and the Mind, ed. I. Deliège, and J. W. Davidson (Oxford: Oxford University Press, 2011).
Other sources on savants and atonal music: L. K. Miller, Musical Savants (Hove, East Sussex:
Psychology Press, 1989); B. Hermelin et al., “Intelligence and Musical Improvisation,”
Psychological Medicine 19 (1989): 447–57.
when artistic savants are briefly shown pictures: N. O’Connor and B. Hermelin, “Visual and
Graphic Abilities of the Idiot-Savant Artist,” Psychological Medicine 17 (1987): 79–90. (Treffert has
helped replace the term “ idiot-savant” with “savant syndrome.”) See also: E. Winner, Gifted
Children: Myths and Realities (New York: BasicBooks, 1996), ch. 5.
AlphaZero programmers touted: D. Silver et al., “Mastering Chess and Shogi by Self-Play with a
General Reinforcement Learning Algorithm,” arXiv (2017): 1712.01815.
“In narrow enough worlds”: In addition to an interview with Gary Marcus, I used video of his June
7, 2017, lecture at the AI for Good Global Summit in Geneva, as well as several of his papers and
essays: “Deep Learning: A Critical Appraisal,” arXiv: 1801.00631; “In Defense of Skepticism About
Deep Learning,” Medium, January 14, 2018; “Innateness, AlphaZero, and Artificial Intelligence,”
arXiv: 1801.05667.
IBM ’s Watson: For a balanced take on Watson’s challenges in healthcare—from one critic calling it
“a joke,” to others suggesting it falls far short of the original hype but does indeed have value—see:
D. H. Freedman, “A Reality Check for IBM’s AI Ambitions,” MIT Technology Review , June 27,
2017, online ed.
“The difference between winning at Jeopardy! ”: The oncologist is Dr. Vinay Prasad. He said this
to me in an interview, and also shared it on Twitter.
a report in the esteemed journal Nature : J. Ginsberg et al., “Detecting Influenza Epidemics Using
Search Engine Query Data,” Nature 457 (2009): 1012–14.

double the prevalence: D. Butler, “When Google Got Flu Wrong,” Nature 494 (2013): 155–56; D.
Lazer et al., “The Parable of Google Flu: Traps in Big Data Analysis,” Science 343 (2014): 1203–5.
“the essence of their job”: C. Argyris, “Teaching Smart People How to Learn,” Harvard Business
Review, May– June 1991.
subtitle of Schwartz’s paper: B. Schwartz, “Reinforcement-Induced Behavioral Stereotypy: How
Not to Teach People to Discover Rules,” Journal of Experimental Psychology: General 111, no. 1
(1982):23–59.
“Big-C creator”: E. Winner, “Child Prodigies and Adult Genius: A Weak Link,” in The Wiley
Handbook of Genius, ed. D. K. Simonton (Malden, MA: John Wiley & Sons, 2014).
Accountants and bridge and poker players: A useful source, in addition to Kahneman and Klein’s
“adversarial collaboration” paper, and Hogarth’s Educating Intuition, is: J. Shanteau, “Competence in
Experts: The Role of Task Characteristics,” Organizational Behavior and Human Decision Processes
53 (1992): 252–62.
“robust statistical regularities”: Kahneman, Thinking, Fast and Slow .
research in the game of bridge: P. A. Frensch and R. J. Sternberg, “Expertise and Intelligent
Thinking: When Is It Worse to Know Better?” in Advances in the Psychology of Human Intelligence,
vol. 5, ed. R. J. Sternberg (New York: Psychology Press, 1989).
experienced accountants; “cognitive entrenchment”; “having one foot outside”: E. Dane,
“Reconsidering the Trade-Off Between Expertise and Flexibility,” Academy of Management Review
35, no. 4 (2010): 579–603. For a general discussion of expert flexibility and inflexibility: P. J.
Feltovich et al., “Issues of Expert Flexibility in Contexts Characterized by Complexity and Change,”
in Expertise in Context, ed. P. J. Feltovich et al. (Cambridge, MA: AAAI Press/ MIT Press, 1997);
and F. Gobet, Understanding Expertise (Basingstoke: Palgrave Macmillan, 2016).
Nobel laureates are at least: R. Root-Bernstein et al., “Arts Foster Scientific Success: Avocations of
Nobel, National Academy, Royal Society and Sigma Xi Members,” Journal of Psychology of Science
and Technology 1, no. 2 (2008): 51–63; R. Root-Bernstein et al., “Correlations Between Avocations,
Scientific Style, Work Habits, and Professional Impact of Scientists,” Creativity Research Journal 8,
no. 2 (1995): 115–37.
“To him who observes them from afar”: S. Ramón y Cajal, Precepts and Counsels on Scientific
Investigation (Mountain View, CA: Pacific Press Publishing Association, 1951).
those who did not make a creative contribution: A. Rothenberg, A Flight from Wonder: An
Investigation of Scientific Creativity (Oxford: Oxford University Press, 2015).
“rather than obsessively focus[ing]”: D. K. Simonton, “Creativity and Expertise: Creators Are Not
Equivalent to Domain-Specific Experts!,” in The Science of Expertise, ed. D. Hambrick et al. (New
York: Routledge, 2017 [Kindle ebook]).
“When we were designing”: Steve Jobs’s 2005 commencement address at Stanford:
https://news.stanford.edu/ 2005/ 06/ 14/ jobs-061505.
“no one else was familiar”: J. Horgan, “Claude Shannon: Tinkerer, Prankster, and Father of
Information Theory,” IEEE Spectrum 29, no. 4 (1992): 72–75. For more depth on Shannon, see J.
Soni and R. Goodman, A Mind at Play (New York: Simon & Schuster, 2017).
“career streams”; “traveled on an eight-lane highway”: C. J. Connolly, “Transition Expertise:
Cognitive Factors and Developmental Processes That Contribute to Repeated Successful Career
Transitions Amongst Elite Athletes, Musicians and Business People” (PhD thesis, Brunel University,
2011).
CHAPTER 2 : HOW THE WICKED WORLD WAS MADE

a thirty-year-old paper: R. D. Tuddenham, “Soldier Intelligence in World Wars I and II,” American
Psychologist 3, no. 2 (1948): 54–56.
Should Martians alight on Earth: J. R. Flynn, Does Your Family Make You Smarter? (Cambridge:
Cambridge University Press, 2016), 85.
“cradle to the grave”: J. R. Flynn, What Is Intelligence? (Cambridge: Cambridge University Press,
2009).
When Flynn published his revelation: J. R. Flynn, “The Mean IQ of Americans: Massive Gains
1932 to 1978,” Psychological Bulletin 95, no. 1 (1984): 29–51; J. R. Flynn, “Massive IQ Gains in 14
Nations,” Psychological Bulletin 101, no. 2 (1987): 171–91. For an excellent primer on the Flynn
effect and response, see I. J. Deary, Intelligence: A Very Short Introduction (Oxford: Oxford
University Press, 2001).
tests that gauged material: In addition to interviews with Flynn, his books were helpful—
particularly the hundred pages of appendices in Are We Getting Smarter? (Cambridge: Cambridge
University Press, 2012).
both separate day from night: M. C. Fox and A. L. Mitchum, “A Knowledge-Based Theory of
Rising Scores on ‘Culture-Free’ Tests,” Journal of Experimental Psychology 142, no. 3 (2013): 979–
1000.
When a group of Estonian researchers: O. Must et al., “Predicting the Flynn Effect Through Word
Abstractness: Results from the National Intelligence Tests Support Flynn’s Explanation,” Intelligence
57 (2016): 7–14. I first saw these results in St. Petersburg, Russia, at the 2016 annual conference of
the International Society for Intelligence Research. The ISIR invited me to give the annual Constance
Holden Memorial Address. Four attempts at getting a visa later, I arrived. The event was full of
vigorous but civil debate, including over the Flynn effect, and was an excellent background resource.
“The huge Raven’s gains”: J. R. Flynn, What Is Intelligence?
Even in countries: E. Dutton et al., “The Negative Flynn Effect,” Intelligence 59 (2016): 163–69.
And see Flynn’s Are We Getting Smarter? on, for example, trends in Sudan.
Alexander Luria: Luria’s fascinating book is the major source for this section: Cognitive
Development: Its Cultural and Social Foundations (Cambridge, MA: Harvard University Press,
1976).
He learned the local language: E. D. Homskaya, Alexander Romanovich Luria: A Scientific
Biography (New York: Springer, 2001).
“eduction”: Flynn’s Does Your Family Make You Smarter? and chap. 22 of R. J. Sternberg and S. B.
Kaufman, eds., The Cambridge Handbook of Intelligence (Cambridge: Cambridge University Press,
2011).
forest for the trees: An in-depth description of the “seeing the trees” phenomenon in a different
context can be found in sections about “weak central coherence” in U. Frith, Autism: Explaining the
Enigma (Malden, MA: Wiley-Blackwell, 2003).
The Kpelle people: S. Scribner, “Developmental Aspects of Categorized Recall in a West African
Society,” Cognitive Psychology 6======================================================== In the face
of an unfamiliar challenge, NASA managers failed to drop their familiar
tools.
Psychologist and organizational behavior expert Karl Weick noticed
something unusual in the deaths of smokejumpers and “hotshot” wilderness
firefighters: they held on to their tools, even when ditching equipment
would have allowed them to run away from an advancing fire. For Weick, it
was emblematic of something larger.
In Montana’s 1949 Mann Gulch fire, made famous in Norman Maclean’s
Young Men and Fire, smokejumpers parachuted in expecting to face a “ten
o’clock fire,” meaning they would have it contained by 10 a.m. the next
morning. Until the fire jumped across the gulch from one forested hill slope
to the steep slope where the firefighters were, and chased them uphill
through dry grass at eleven feet per second. Crew foreman Wagner Dodge
yelled at the men to drop their tools. Two did so immediately and sprinted
over the ridge to safety. Others ran with their tools and were caught by the
flames. One firefighter stopped fleeing and sat down, exhausted, never
having removed his heavy pack. Thirteen firefighters died. The Mann Gulch

tragedy led to reforms in safety training, but wildland firefighters continued
to lose races with fires when they did not drop their tools.
In 1994, on Colorado’s Storm King Mountain, hotshots and
smokejumpers faced a Mann Gulch situation when a fire jumped a canyon
and erupted through a stand of gambel oak below them. The sound in the
canyon was “like a jet during take off,” according to a survivor. Fourteen
men and women lost the race with a wall of flame. “[Victim] was still
wearing his backpack,” reads an analysis from the body recovery operation.
“Victim has chainsaw handle still in hand.” He was just 250 feet from a safe
zone. Survivor Quentin Rhoades had already run nine hundred feet uphill,
“then realized I still had my saw over my shoulder! I irrationally started
looking for a place to put it down where it wouldn’t get burned. . . . I
remember thinking I can’t believe I’m putting down my saw.” Two separate
analyses conducted for the U.S. Forest Service and the Bureau of Land
Management concluded that the crew would have made it out intact had
they simply dropped their tools and run from the start.
In four separate fires in the 1990s, twenty-three elite wildland firefighters
refused orders to drop their tools and perished beside them. Even when
Rhoades eventually dropped his chainsaw, he felt like he was doing
something unnatural. Weick found similar phenomena in Navy seamen who
ignored orders to remove steel-toed shoes when abandoning a ship, and
drowned or punched holes in life rafts; fighter pilots in disabled planes
refusing orders to eject; and Karl Wallenda, the world-famous high-wire
performer, who fell 120 feet to his death when he teetered and grabbed first
at his balance pole rather than the wire beneath him. He momentarily lost
the pole while falling, and grabbed it again in the air. “Dropping one’s tools
is a proxy for unlearning, for adaptation, for flexibility,” Weick wrote. “It is
the very unwillingness of people to drop their tools that turns some of these
dramas into tragedies.” For him, firefighters were an example, and a
metaphor for what he learned while studying normally reliable
organizations that clung to trusty methods, even when they led to
bewildering decisions.
Rather than adapting to unfamiliar situations, whether airline accidents or
fire tragedies, Weick saw that experienced groups became rigid under
pressure and “regress to what they know best.” They behaved like a
collective hedgehog, bending an unfamiliar situation to a familiar comfort
zone, as if trying to will it to become something they actually had

experienced before. For wildland firefighters, their tools are what they
know best. “Firefighting tools define the firefighter’s group membership,
they are the firefighter’s reason for being deployed in the first place,” Weick
wrote. “Given the central role of tools in defining the essence of a
firefighter, it is not surprising that dropping one’s tools creates an existential
crisis.” As Maclean succinctly put it, “When a firefighter is told to drop his
firefighting tools, he is told to forget he is a firefighter.”
Weick explained that wildland firefighters have a firm “can do” culture,
and dropping tools was not part of it, because it meant they had lost control.
Quentin Rhoades’s chainsaw was such a part of his firefighting self that he
did not even realize he still had it, any more than he realized he still had his
arms. When it became utterly ludicrous to carry the saw further, Rhoades
still “could not believe” he was parting with it. He felt naked, just as Larry
Mulloy said he would have without a quantitative argument for a last-
second launch reversal. At NASA, accepting a qualitative argument was
like being told to forget you are an engineer.
When sociologist Diane Vaughan interviewed NASA and Thiokol
engineers who had worked on the rocket boosters, she found that NASA’s
own famous can-do culture manifested as a belief that everything would be
fine because “we followed every procedure”; because “the [flight readiness
review] process is aggressive and adversarial”; because “we went by the
book.” NASA’s tools were its familiar procedures. The rules had always
worked before. But with Challenger they were outside their usual bounds,
where “can do” should have been swapped for what Weick calls a “make
do” culture. They needed to improvise rather than throw out information
that did not fit the established rubric.
Roger Boisjoly’s unquantifiable argument that the cold weather was
“away from goodness” was considered an emotional argument in NASA
culture. It was based on interpretation of a photograph. It did not conform to
the usual quantitative standards, so it was deemed inadmissible evidence
and disregarded. The can-do attitude among the rocket-booster group,
Vaughan observed, “was grounded in conformity.” After the tragedy, it
emerged that other engineers on the teleconference agreed with Boisjoly,
but knew they could not muster quantitative arguments, so they remained
silent. Their silence was taken as consent. As one engineer who was on the
Challenger conference call later said, “If I feel like I don’t have data to
back me up, the boss’s opinion is better than mine.”

Dropping familiar tools is particularly difficult for experienced
professionals who rely on what Weick called overlearned behavior. That is,
they have done the same thing in response to the same challenges over and
over until the behavior has become so automatic that they no longer even
recognize it as a situation-specific tool. Research on aviation accidents, for
example, found that “a common pattern was the crew’s decision to continue
with their original plan” even when conditions changed dramatically.
When Weick spoke with hotshot Paul Gleason, one of the best wildland
firefighters in the world, Gleason told him that he preferred to view his
crew leadership not as decision making, but as sensemaking. “If I make a
decision, it is a possession, I take pride in it, I tend to defend it and not
listen to those who question it,” Gleason explained. “If I make sense, then
this is more dynamic and I listen and I can change it.” He employed what
Weick called “hunches held lightly.” Gleason gave decisive directions to his
crew, but with transparent rationale and the addendum that the plan was ripe
for revision as the team collectively made sense of a fire .
On the night of the Challenger conference call, following procedure in
the face of uncertainty was so paramount that NASA’s Mulloy asked
Thiokol to put its final launch recommendation and rationale on paper and
sign it. Last-minute sign-off had always been verbal in the past. Thiokol’s
Allan McDonald was in the room with Mulloy, and refused. One of
McDonald’s bosses in Utah signed and faxed the document instead. Even
Mulloy, who had demanded data, must have felt uneasy with the decision,
while at the same time feeling protected by NASA’s ultimate tool—its
hallowed process. The process culminated with more concern for being able
to defend a decision than with using all available information to make the
right one. Like the firefighters, NASA managers had merged with their
tools. As McDonald said, looking only at the quantitative data actually
supported NASA’s stance that there was no link between temperature and
failure. NASA’s normal quantitative standard was a dearly held tool, but the
wrong one for the job. That night, it should have been dropped.
It is easy to say in retrospect. A group of managers accustomed to
dispositive technical information did not have any; engineers felt like they
should not speak up without it. Decades later, an astronaut who flew on the
space shuttle, both before and after Challenger, and then became NASA’s
chief of safety and mission assurance, recounted what the “In God We
Trust, All Others Bring Data” plaque had meant to him: “Between the lines

it suggested that, ‘We’re not interested in your opinion on things. If you
have data, we’ll listen, but your opinion is not requested here.’”
Physicist and Nobel laureate Richard Feynman was one of the members
of the commission that investigated the Challenger, and in one hearing he
admonished a NASA manager for repeating that Boisjoly’s data did not
prove his point. “When you don’t have any data,” Feynman said, “you have
to use reason.”
These are, by definition, wicked situations. Wildland firefighters and
space shuttle engineers do not have the liberty to train for their most
challenging moments by trial and error. A team or organization that is both
reliable and flexible, according to Weick, is like a jazz group. There are
fundamentals—scales and chords—that every member must overlearn, but
those are just tools for sensemaking in a dynamic environment. There are
no tools that cannot be dropped, reimagined, or repurposed in order to
navigate an unfamiliar======================================================== reverse.
In a separate study of twelve hundred young musicians, those who quit
reported “a mismatch between the instruments [they] wanted to learn to
play and the instruments they actually played.” Amy Chua described her
daughter Lulu as a “natural musician.” Chua’s singer friend called Lulu
“extraordinary,” with a gift “no one can teach.” Lulu made rapid progress
on the violin, but pretty soon told her mother ominously, “You picked it, not
me.” At thirteen, she quit most of her violin activities. Chua, candid and
introspective, wondered in the coda of her book if Lulu would still be
playing if she had been allowed to choose her own instrument.
When Sloboda and a colleague conducted a study with students at a
British boarding school that recruited from around the country—admission
rested entirely on an audition—they were surprised to find that the students
classified as exceptional by the school came from less musically active
families compared to less accomplished students, did not start playing at a
younger age, were less likely to have had an instrument in the home at a
very young age, had taken fewer lessons prior to entering the school, and

had simply practiced less overall before arriving—a lot less. “It seems very
clear,” the psychologists wrote, “that sheer amount of lesson or practice
time is not a good indicator of exceptionality.” As to structured lessons,
every single one of the students who had received a large amount of
structured lesson time early in development fell into the “average” skill
category, and not one was in the exceptional group. “The strong
implication,” the researchers wrote, is “that that too many lessons at a
young age may not be helpful.”
“ However,” they added, “the distribution of effort across different
instruments seems important. Those children identified as exceptional by
[the school] turn out to be those children who distributed their effort more
evenly across three instruments.” The less skilled students tended to spend
their time on the first instrument they picked up, as if they could not give up
a perceived head start. The exceptional students developed more like the
figlie del coro . “The modest investment in a third instrument paid off
handsomely for the exceptional children,” the scientists concluded.
The psychologists highlighted the variety of paths to excellence, but the
most common was a sampling period, often lightly structured with some
lessons and a breadth of instruments and activities, followed only later by a
narrowing of focus, increased structure, and an explosion of practice
volume. Sound familiar? A study that followed up on Sloboda’s work two
decades later compared young musicians admitted to a competitive
conservatory to similarly committed but less skilled music students. Nearly
all of the more accomplished students had played at least three instruments,
proportionally much more than the lower-level students, and more than half
played four or five. Learning to play classical music is a narrative linchpin
for the cult of the head start; as music goes, it is a relatively golflike
endeavor. It comes with a blueprint; errors are immediately apparent; it
requires repetitive practice of the exact same task until execution becomes
automatic and deviation is minimal. How could picking an instrument as
early as possible and starting in technical training not be the standard path
to success? And yet even classical music defies a simple Tiger story.
The Cambridge Handbook of Expertise and Expert Performance,
published in 2006, is a sort of bible for popular writers, speakers, and
researchers in the ten-thousand-hours school. It is a compilation of
essayistic chapters, each written by different researchers who delve into
dance, math, sports, surgery, writing, and chess. The music section focuses

very conspicuously on classical playing. At nine hundred oversized pages, it
is a handbook for large hands. In the chapter on developing music expertise,
there is just one single substantive mention of the beginnings of expert
players in all the genres of music in the world that are not classical. The
Handbook simply notes that, in contrast to classical players, jazz and folk
and modern popular musicians and singers do not follow a simple, narrow
trajectory of technical training, and they “start much later.”
Jack Cecchini can thank two stumbles, one metaphorical and one literal, for
making him one of the rare musicians who is world class in both jazz and
classical.
The first was in 1950 in Chicago, when he was thirteen and stumbled
across a guitar resting on his landlord’s couch. He ran his fingers over the
strings as he walked by. The landlord picked it up, demonstrated two
chords, and immediately asked Cecchini to play accompaniment with them.
Of course, he couldn’t. “He’d shake his head when it was time for me to
change the chord, and if I didn’t he’d start swearing,” Cecchini recalled
with a chuckle. Cecchini’s interest was ignited, and he started trying to
imitate songs he heard on the radio. By sixteen, he was playing jazz in the
background of Chicago clubs he was too young to patronize. “It was like a
factory,” he told me. “If you had to go to the bathroom, you had to get one
of the other guys to pick it up. But you’re experimenting every night.” He
took the only free music lessons he could find, in clarinet, and tried to
transfer what he learned to the guitar. “There are eight million places on the
guitar to play the same notes,” he said. “I was just trying to find solutions to
problems, and you start to learn the fingerboard.” Pretty soon he was
performing with Frank Sinatra at the Villa Venice, Miriam Makeba at the
Apollo, and touring with Harry Belafonte from Carnegie Hall to packed
baseball stadiums. That’s where the second stumble came in.
During a show when Cecchini was twenty-three, one of Belafonte’s stage
dancers stepped on the cable that connected his guitar to an amplifier. His
instrument was reduced to a whisper. “Harry freaked out,” Cecchini
recalled. “He said, ‘Get rid of that thing and get yourself a classical
guitar!’” Getting one was easy, but he had been using a pick, and for
acoustic he had to learn fingering, so the trouble was learning to play it on
tour.

He fell in love with the instrument, and by thirty-one was so adept that he
was chosen as the soloist to play a concerto by none other than Vivaldi
accompanied by an orchestra for a crowd in Chicago’s Grant Park. The next
day, the Chicago Tribune ’s music critic began his review: “Despite the
ever-increasing number of enthusiasts who untiringly promote the
resurrection of the guitar as a classical instrument, there are but few men
who possess the talent and patience to master what remains one of the most
beautiful but obstinately difficult of all instruments.” Cecchini, he
continued, “proved to be one of those few.”
Despite his late and haphazard start, Cecchini also became a renowned
teacher of both jazz and classical guitar. Students traveled from out of state
to pick his brain, and by the early 1980s lines formed down the stairs of his
Chicago school in the evenings. His own formal training, of course, had
been those free clarinet lessons. “I’d say I’m 98 percent self-taught,” he told
me. He switched between instruments and found his way through trial and
error. It might sound unusual, but when Cecchini reeled off legends he
played with or admired, there was not a Tiger among them.
Duke Ellington was one of the few who ever actually took formal
lessons, when he was seven, from the exuberantly named teacher Marietta
Clinkscales. He lost interest immediately, before he learned to read notes,
and quit music entirely to focus on baseball. In school, his interests were
drawing and painting. (He later turned down a college art scholarship.)
When he was fourteen, Ellington heard ragtime, and for the first time in
seven years sat down at a piano and tried to copy what he had heard. “There
was no connection between me and music, until I started fiddling with it
myself,” he remembered. “As far as anyone teaching me, there was too
many rules and regulations. . . . As long as I could sit down and figure it out
for myself, then that was all right.” Even once he became arguably
America’s preeminent composer, he relied on copyists to decode his
personal musical shorthand into traditional musical notation.
Johnny Smith was Cecchini’s absolute favorite. Smith grew up in a
shotgun house in Alabama. Neighbors gathered to play music, and young
Johnny goofed around with whatever they left in a corner overnight. “John
played anything,” his brother Ben recalled. It allowed him to enter local
competitions for any instrument, and the prizes were groceries. He once
fiddled his way to a five-pound bag of sugar. He didn’t particularly like

violin, though. Smith said he would have walked fifty miles for a guitar
lesson, but there were no teachers around, so he just had to experiment.
When the United States entered World War II, Smith enlisted in the Army
hoping to be a pilot, but a left-eye problem disqualified him. He was sent to
the marching band, which had absolutely no use for a guitar player. He
could not yet read music, but was assigned to teach himself a variety of
instruments so he could play at recruiting events. Wide-ranging experience
set him up for his postwar work as NBC’s musical arranger. He had learned
to learn, and his multi-instrument and polygenre skill became so renowned
that it got him into a tricky spot.
He was leaving NBC one Friday evening when he was stopped at the
elevator and asked to learn a new guitar part. The classical player hired for
the job couldn’t hack it. It was for a live celebration of composer Arnold
Schoenberg’s seventy-fifth birthday, and would feature one of Schoenberg’s
atonal compositions, which had not been performed in twenty-five years.
Smith had four days. He continued with his Friday night, got home at 5
a.m., and then joined an emergency rehearsal at 7 a.m.======================================================== suffering locals marveled at the
young man’s endurance as he tried to soothe families. But they also found
him odd; the children he taught did not listen. Soon, his makeshift ministry
was finished. He was twenty-seven, and despondent. A decade after an
exuberant start as an art dealer, he had no possessions, accomplishments, or
direction.
He poured his heart out in a missive to his little brother, now a respected
art dealer himself. He likened himself to a caged bird in spring who feels

deeply that it is time for him to do something important but cannot recall
what it is, and so “bangs his head against the bars of his cage. And then the
cage stays there and the bird is mad with suffering.” A man, too, he
exhorted, “doesn’t always know himself what he could do, but he feels by
instinct, I’m good for something, even so! . . . I know that I could be a quite
different man! . . . There’s something within me, so what is it!” He had been
a student, an art dealer, a teacher, a bookseller, a prospective pastor, and an
itinerant catechist. After promising starts, he had failed spectacularly in
every path he tried.
His brothers suggested he try carpentry, or look for work as a barber. His
sister thought he would make a fine baker. He was an insatiable reader, so
perhaps a librarian. But in the depths of his despair, he turned his ferocious
energy on the last thing he could think of that he could start right away. His
next letter to his brother was very short: “I’m writing to you while drawing
and I’m in a hurry to get back to it.” Previously, the man had seen drawing
as a distraction from his aim of reaching people with truth. Now he began to
seek truth by documenting the lives around him in drawings. He had
stopped drawing freehand as a child when he realized he was a clumsy
draftsman, so he started at the very beginning, reading Guide to the ABCs of
Drawing .
In the coming years, he would make a few very brief attempts at formal
training. His cousin-in-law was a painter and tried to teach him watercolor.
The cousin would later be listed on the man’s Wikipedia page as the sole
entry beside “Education.” In truth, the man struggled with the fragile touch
required for watercolor, and the mentor/ mentee relationship ended after a
month. His former art-dealer boss, now an esteemed tastemaker in the art
world, pronounced his drawings unworthy of being displayed for sale. “Of
one thing I am sure,” the boss told him, “you are no artist.” He added flatly,
“You started too late.”
When he was nearly thirty-three, he enrolled in art school alongside
students a decade younger, but lasted only a few weeks. He entered the
class drawing competition, and the judges harshly suggested he revert to a
beginner’s class with ten-year-olds.
As he had between careers, he pinballed from one artistic passion to
another. On one day he felt true artists only painted realistic figures, and
then when his figures came out poorly, the next day true artists only cared
for landscapes. One day he strived for realism, another for pure expression.

This week art was a medium for declaring religious devotion, next week
such concerns encumbered pure creation. One year he decided all true art
consisted only of shades of black and gray, and then later that vibrant color
was the real pearl inside the artist’s shell. Each time he fell fully in love,
and then just as fully and quickly back out.
One day, he dragged an easel and oil paints—with which he had almost
no experience—out to a sand dune in a storm. He ran in and out of cover,
slapping and slathering paint on the canvas in staccato strokes between
gusts of wind that peppered the painting with grains of sand. He squeezed
color right from the tube onto the canvas when he had to. The viscous oil
paint and the speed required to apply it in the storm freed his imagination
and his hand from the crippling deficiencies that plagued him when he
strove for perfect realism. More than a century later, his definitive
biographers would write of that day, “[He] made an astonishing discovery:
he could paint.” And he felt it. “I enjoy it tremendously,” he wrote his
brother. “Painting has proved less difficult than I expected.”
He continued to whipsaw from one artistic experiment to another,
avowing and disavowing, roundly condemning the attempt to capture
sunlight in paint only to reverse course and place his canvas outside in the
sunlight to do just that. He obsessed over deeper and darker blacks in
colorless works, and then dispensed with that in an instant and forever in
favor of vibrant color, his about-face so thorough that he would not even
use black to depict the night sky. He started piano lessons because he
thought musical tones might teach him something about color tones.
His peregrinations continued for the few remaining years of his short life,
both geographically and artistically. He finally forsook the goal of ever
becoming a master draftsman, and then one by one left behind all of the
styles that he had previously claimed to be critical, but at which he had
failed. He emerged with a new art: impetuous, slathered with paint, erupting
with color, laden with no formality other than to capture something infinite.
*
 He wanted to make art that anyone could understand, not haughty works
for those with privileged training. For years he had tried and failed to
capture every proportion of a figure accurately. Now he let that go so
entirely that he left figures walking among trees with faces left blank and
hands like mittens.
Whereas he had once demanded live models to portray and images to
copy, now he wielded his mind’s eye. One evening, he looked out his

bedroom window toward the rolling hills in the distance and, as he had with
birds and beetles as a boy, watched the sky pass for hours. When he picked
up the brush, his imagination transformed a nearby town into a tiny village,
its towering church to a humble chapel. The dark green cypress tree in the
foreground became massive, winding up the canvas like seaweed in the
swirling rhythm of the night sky.
It was just a few years from the recommended relegation to a drawing
class for ten-year-olds. But that starry night, along with scores of other
paintings in his new style, the one he devised amid a succession of failures,
would launch a new era of art and inspire new conceptions of beauty and
expression. Works that he dashed off in hours as experiments over the final
two years of his life would become some of the most valuable objects—
culturally and monetarily—that have ever existed in the world.
It is a myth that Vincent van Gogh died in anonymity. An ecstatic review
cast him as a revolutionary months before he died, and made him the talk of
Paris. Claude Monet, the dean of impressionism—the movement Van Gogh
ignored, lamented, and then innovated upon—declared Van Gogh’s work
the cream of an annual exhibition.
Adjusted for inflation, four of Van Gogh’s paintings have sold for more
than $100 million, and they weren’t even the most famous ones. His work
now graces everything from socks to cell phone covers and an eponymous
vodka brand. But he reached far beyond commerce.
“What artists do changed because of Vincent Van Gogh,” artist and writer
Steven Naifeh told me. (Naifeh, with Gregory White Smith, wrote “the
definitive biography,” according to a curator of the Van Gogh Museum.)
Van Gogh’s paintings served as a bridge to modern art and inspired a
widespread devotion that no artist, perhaps no person, has equaled.
Teenagers who have never visited a museum tape his art to their walls;
Japanese travelers leave the ashes of their ancestors at his grave. In 2016,
the Art Institute of Chicago displayed together all three iconic
“Bedrooms”—pictures meant “to rest the brain, or rather the imagination,”
according to Van Gogh; the record number of visitors forced them to create
impromptu crowd control strategies, with a TSA-precheck-style express
lane.

And yet had Van Gogh died at thirty-four rather than thirty-seven (life
expectancy in the Netherlands when he was born was forty), he might not
even merit a historical footnote. The same goes for Paul Gauguin, a painter
who briefly lived with Van Gogh and innovated a style known as
synthetism, in which bold lines separated sections of brilliant color, without
the subtle gradations of classical painting. He, too, became one of the few
artists to crack the $100 million barrier. He spent the first six years of his
professional life with the merchant marine before he found his calling:
bourgeois stockbroker. Only after the market crash of 1882 did Gauguin
become a full-time artist, at the age of thirty-five. His switch is reminiscent
of J. K. Rowling’s. She “failed on an epic scale” in her twenties, she once
said, personally and professionally. A short marriage “imploded,” and she
was a single mother and unemployed former teacher on welfare. Like Van
Gogh in the coal country and Gauguin after the crash, she was “set free” by
failure to try work that better matched her talents and interests.
They all appear to have excelled in spite of their late starts. It would be
easy enough to cherry-pick stories of exceptional late developers
overcoming the odds. But they aren’t exceptions by virtue of their late
starts, and those late starts did not stack the odds against them. Their late
starts were integral to their eventual success.
“Match quality” is a term economists use to describe the degree of fit
between the work someone does and who they are—their abilities and
proclivities.
Northwestern University economist Ofer Malamud’s inspiration for
studying match quality was personal experience. He was born in Israel, but
his father worked for a shipping company, and when Malamud was nine the
family moved to Hong Kong, where he attended an English school. The
English system required that a student home in on an academic
specialization in the last two years of high school. “When you applied to a
college in England, you had to apply to a======================================================== cutting
edge of artificial intelligence: “neural networks” that learn how to identify
images from examples (when you search cat pictures, for instance) were
conceived as akin to the neurons of the brain, and “genetic algorithms” are
conceptually based on evolution by natural selection—solutions are tried,
evaluated, and the more successful solutions pass on properties to the next
round of solutions, ad infinitum. It is the furthest extension of the type of
thinking that was foreign to Luria’s premodern villagers, whose problem
solving depended on direct experience.
Kepler was facing a problem not just new to himself, but to all humanity.
There was no experience database to draw on. To investigate whether he
should be the first ever to propose “action at a distance” in the heavens (a

mysterious power invisibly traversing space and then appearing at its
target), he turned to analogy (odor, heat, light) to consider whether it was
conceptually possible. He followed that up with a litany of distant analogies
(magnets, boats) to think through the problem.
Most problems, of course, are not new, so we can rely on what Gentner
calls “surface” analogies from our own experience. “Most of the time, if
you’re reminded of things that are similar on the surface, they’re going to
be relationally similar as well,” she explained. Remember how you fixed
the clogged bathtub drain in the old apartment? That will probably come to
mind when the kitchen sink is clogged in the new one.
But the idea that surface analogies that pop to mind work for novel
problems is a “kind world” hypothesis, Gentner told me. Like kind learning
environments, a kind world is based on repeating patterns. “It’s perfectly
fine,” she said, “if you stay in the same village or the same savannah all
your life.” The current world is not so kind; it requires thinking that cannot
fall back on previous experience. Like math students, we need to be able to
pick a strategy for problems we have never seen before. “In the life we lead
today,” Gentner told me, “we need to be reminded of things that are only
abstractly or relationally similar. And the more creative you want to be, the
more important that is.”
In the course of studying problem solving in the 1930s, Karl Duncker posed
one of the most famous hypothetical problems in all of cognitive
psychology. It goes like this:
Suppose you are a doctor faced with a patient who has a malignant stomach tumor. It is
impossible to operate on this patient, but unless the tumor is destroyed the patient will die.
There is a kind of ray that can be used to destroy the tumor. If the rays reach the tumor all at
once at a sufficiently high intensity, the tumor will be destroyed. Unfortunately, at this
intensity the healthy tissue that the rays pass through on the way to the tumor will also be
destroyed. At lower intensities the rays are harmless to healthy tissue, but they will not affect
the tumor either. What type of procedure might be used to destroy the tumor with the rays, and
at the same time avoid destroying the healthy tissue?
It’s on you to excise the tumor and save the patient, but the rays are either
too powerful or too weak. How can you solve this? While you’re thinking, a
little story to pass the time: There once was a general who needed to capture
a fortress in the middle of a country from a brutal dictator. If the general
could get all of his troops to the fortress at the same time, they would have

no problem taking it. Plenty of roads that the troops could travel radiated
out from the fort like wheel spokes, but they were strewn with mines, so
only small groups of soldiers could safely traverse any one road. The
general came up with a plan. He divided the army into small groups, and
each group traveled a different road leading to the fortress. They
synchronized their watches, and made sure to converge on the fortress at the
same time via their separate roads. The plan worked. The general captured
the fortress and overthrew the dictator.
Have you saved the patient yet? Just one last story while you’re still
thinking: Years ago, a small-town fire chief arrived at a woodshed fire,
concerned that it would spread to a nearby house if it was not extinguished
quickly. There was no hydrant nearby, but the shed was next to a lake, so
there was plenty of water. Dozens of neighbors were already taking turns
with buckets throwing water on the shed, but they weren’t making any
progress. The neighbors were surprised when the fire chief yelled at them to
stop, and to all go fill their buckets in the lake. When they returned, the
chief arranged them in a circle around the shed, and on the count of three
had them all throw their water at once. The fire was immediately dampened,
and soon thereafter extinguished. The town gave the fire chief a pay raise as
a reward for quick thinking.
Are you done saving your patient? Don’t feel bad, almost no one solves
it. At least not at first, and then nearly everyone solves it. Only about 10
percent of people solve “Duncker’s radiation problem” initially. Presented
with both the radiation problem and the fortress story, about 30 percent
solve it and save the patient. Given both of those plus the fire chief story,
half solve it. Given the fortress and the fire chief stories and then told to use
them to help solve the radiation problem, 80 percent save the patient.
The answer is that you (the doctor) could direct multiple low-intensity
rays at the tumor from different directions, leaving healthy tissue intact, but
converging at the tumor site with enough collective intensity to destroy it.
Just like how the general divided up troops and directed them to converge at
the fortress, and how the fire chief arranged neighbors with their buckets
around the burning shed so that their water would converge on the fire
simultaneously.
Those results are from a series of 1980s analogical thinking studies.
Really, don’t feel bad if you didn’t get it. In a real experiment you would
have taken more time, and whether you got it or not is unimportant. The

important part is what it shows about problem solving. A gift of a single
analogy from a different domain tripled the proportion of solvers who got
the radiation problem. Two analogies from disparate domains gave an even
bigger boost. The impact of the fortress story alone was as large as if
solvers were just straight out told this guiding principle: “If you need a
large force to accomplish some purpose, but are prevented from applying
such a force directly, many smaller forces applied simultaneously from
different directions may work just as well.”
The scientists who did that work expected that analogies would be fuel
for problem solving, but they were surprised that most solvers working on
the radiation problem did not find clues in the fortress story until they were
directed to do so. “One might well have supposed,” the scientists wrote, that
“being in a psychology experiment would have led virtually all subjects to
consider how the first part [of the study] might be related to the second.”
Human intuition, it appears, is not very well engineered to make use of
the best tools when faced with what the researchers called “ ill-defined”
problems. Our experience-based instincts are set up well for Tiger domains,
the kind world Gentner described, where problems and solutions repeat.
An experiment on Stanford international relations students during the
Cold War provided a cautionary tale about relying on kind-world reasoning
—that is, drawing only on the first analogy that feels familiar. The students
were told that a small, fictional democratic country was under threat from a
totalitarian neighbor, and they had to decide how the United States should
respond. Some students were given descriptions that likened the situation to
World War II (refugees in boxcars; a president “from New York, the same
state as FDR”; a meeting in “Winston Churchill Hall”). For others, it was
likened to Vietnam, (a president “from Texas, the same state as LBJ,” and
refugees in boats). The international relations students who were reminded
of World War II were far more likely to choose to go to war; the students
reminded of Vietnam opted for nonmilitary diplomacy. That phenomenon
has been documented all over the place. College football coaches rated the
same player’s potential very differently depending on what former player he
was likened to in an introductory description, even with all other
information kept exactly the same.
With the difficult radiation problem, the most successful strategy
employed multiple situations that were not at all alike on the surface, but
held deep structural similarities. Most problem solvers are not like Kepler.

They will stay inside of the problem at hand, focused on the internal details,
and perhaps summon other medical knowledge, since it is on the surface a
medical problem. They will not intuitively turn to distant analogies to probe
solutions. They should, though, and they should make sure some of those
analogies are, on the surface, far removed from the current problem. In a
wicked world, relying upon experience from a single domain is not only
limiting, it can be disastrous .
The trouble with using no more than a single analogy, particularly one from
a very similar situation, is that it does not help battle the natural impulse to
employ the “inside view,” a term coined by psychologists Daniel Kahneman
and Amos Tversky. We take the inside view when we make judgments
based narrowly on the details of a particular project that are right in front of
us.
Kahneman had a personal experience with the dangers of the inside view
when he assembled a team to write a high school curriculum on the science
of decision making. After a full year of weekly meetings, he surveyed the
entire team to find out how long everyone thought the project would take.
The lowest estimate was one and a half years, the highest two and a half
years. Kahneman then asked a team member======================================================== home field can be so
constrained that a curious outsider is truly the only one who can see the
solution.
The email subject line caught my eye: “Olympic medalist and muscular
dystrophy patient with the same mutation.”
I had just written a book on genetics and athleticism, and figured it would
point to some journal article I had missed. Instead, it was a note from the

muscular dystrophy patient herself, Jill Viles, a thirty-nine-year-old woman
in Iowa. She had an elaborate theory connecting the gene mutation that
withered her muscles to those of an Olympic sprinter, and she offered to
send more info.
I expected a letter, maybe some news clippings. I got a stack of original
family photos, a detailed medical history, and a nineteen-page, bound and
illustrated packet that referenced gene mutations by their specific DNA
locations. She had done some serious homework.
On page 14 there was a photo of Jill in a blue bikini, blonde hair tousled,
smiling and sitting in the sand. Her torso looks normal, but her arms are
strikingly skinny, like twigs jabbed into a snowman. Her legs did not look
like they could possibly hold her, the thigh no wider than her knee joint.
Beside that photo was one of Priscilla Lopes-Schliep, one of the best
sprinters in Canadian history. At the 2008 Olympics in Beijing, she won a
bronze medal in the 100-meter hurdles. The juxtaposition was breathtaking.
Priscilla is midstride, ropes of muscle winding down her legs, veins
bursting from her forearms. She’s like the vision of a superhero a second
grader might draw. I could hardly have imagined two women who looked
less likely to share a biological blueprint.
In online pictures of Priscilla, Jill recognized something in her own,
vastly scrawnier physique—a familiar pattern of missing fat on her limbs.
Her theory was that she and Priscilla have the same mutated gene, but
because Priscilla doesn’t have muscular dystrophy, her body had found
some way “to go around it,” as Jill put it, and was instead making gigantic
muscles. If her theory was right, Jill hoped, scientists would want to study
her and Priscilla to figure out how to help people with muscles like Jill have
muscles a little more toward the Priscilla end of the human physique
spectrum. She wanted my help convincing Priscilla to get a genetic test.
The idea that a part-time substitute teacher, wielding the cutting-edge
medical instrument known as Google Images, would make a discovery
about a pro athlete who is examined by doctors as part of her job struck me
as somewhere between extremely unlikely and patently nuts. I consulted a
Harvard geneticist. He was concerned. “Empowering a relationship
between these two women could end badly,” he told me. “People go off the
deep end when they are relating to celebrities they think they have a
connection to.”

I hadn’t even considered that before; I certainly didn’t want to facilitate a
stalker. It took time for Jill to convince me that because of her unique life
experience, she could see what no specialist could .
When Jill was four, a preschool teacher noticed her stumbling. Jill told her
mother she was afraid of “witches’ fingers” that were grabbing her shins
and tripping her. Her pediatrician sent the family to the Mayo Clinic.
Blood tests showed that Jill, her father, and her brother had higher than
normal levels of creatine kinase, an enzyme that spills from damaged
muscles. Doctors thought some sort of muscular dystrophy might run in the
family, but it didn’t normally show up that way in little girls, and Jill’s
brother and father seemed fine.
“They said our family was extremely unique,” Jill told me. “That’s good
in one way because they’re being honest. But on the other hand, it was
terrifying.”
Jill returned to Mayo every summer, and it was always the same. She had
stopped falling, but by the time she was eight the fat on her limbs was
vanishing. Other kids could wrap their fingers around her arm, and when
veins started protruding from her legs, they asked her how it felt to be old.
Jill’s mother was so worried about her daughter’s social life that she
clandestinely paid another girl to hang out with her. At twelve, she began
struggling to hold her body upright on her bicycle, and had to cling to the
railing at a roller skating rink.
Jill began to hunt for answers, kid style. She checked out library books
on poltergeists. “It really freaked out my dad,” she told me. “He was like,
‘Well, are you into the occult, or what?’ It was nothing of the sort.” She just
could not explain what was happening to her, so when she read stories of
people with inexplicable afflictions, “Ya know, I believed them.”
By the time she left for college, Jill was five foot three and eighty-seven
pounds. She hit the library, poring over any scientific journal she could find
on muscle disease.
She came upon a paper in Muscle and Nerve, on a rare type of muscular
dystrophy called Emery-Dreifuss, and was startled by an accompanying
photo. That’s my dad’s arm, she thought .
Her dad was thin but his forearm muscles were unusually well defined.
Jill called it “Popeye arm” when she was little. Another paper describing

Emery-Dreifuss patients actually referred to a Popeye arm deformity. The
Muscle and Nerve paper reported that Emery-Dreifuss patients have
“contractures” that affect joint mobility.
“I’m getting chills reading this,” Jill recalled. She described her own
contractures as just like a Barbie doll: arms always bent, neck stiff, feet
perma-slanted for high heels. The research indicated that Emery-Dreifuss
only occurred in males, but Jill was certain she had it, and she was afraid. It
comes with heart problems.
She stuffed her bag with articles to bring home over college break. One
day, she found her father flipping through them. He had all the symptoms,
he told her. “Well, yeah, I know . . . the arm, and the neck,” Jill replied. No,
he said: the cardiac symptoms.
For years Jill’s father had been told that his irregular heart rhythms were
due to a virus. “It’s not,” Jill told him instantly. “We have Emery-Dreifuss.”
She took her forty-five-year-old father to the Iowa Heart Center and insisted
that a cardiologist see him. Nurses demanded a referral, but Jill was so
persistent that they relented. The cardiologist put a monitor on her dad that
tracked his heart’s electrical activity for a day, during which his pulse
dropped into the twenties. He was either ready to win the Tour de France or
about to drop dead. He was rushed into emergency surgery for a pacemaker.
“She saved her dad’s life,” Jill’s mother, Mary, told me.
Still, the Iowa Heart Center could not confirm the family condition. In
her reading, Jill came across an Italian research group searching for families
with Emery-Dreifuss. They were hoping to locate a gene mutation that
caused it.
Nineteen-year-old Jill put on her most imposing navy pantsuit, took her
papers to a neurologist in Des Moines, and asked to be connected to the
Italian study. “No, you don’t have that,” she recalled the neurologist saying
sternly. She refused even to look at the papers. In fairness, Jill was a
teenager self-diagnosing an extremely rare disease known to occur only in
men. So in 1995 she wrote to the Italians, and included a picture of herself.
The response she got from the Istituto di Genetica Biochimica ed
Evoluzionistica was clearly meant for a scientist. Please send DNA from the
entire family, it read. “If you cannot prepare DNA, just send fresh blood.”
Jill convinced a nurse friend to smuggle needles and test tubes to her house.
Fortunately, Italy accepted blood by normal mail.

It would be years before Jill heard from the Italians again, but she had
made up her mind. On her annual trip to the Mayo Clinic, against her
mother’s protestations she took her own pen and wrote “ Emery-Dreifuss”
on her medical chart.
In 1999, she got an email from Italy. She let the moment sink in, and then
clicked. She had a mutation on a gene known as LMNA, or the lamin gene,
colloquially. Her father did too. So did two brothers and a sister. So did four
other families in the study with Emery-Dreifuss. Jill had been right.
The lamin gene carries a recipe for constructing a tangle of proteins at the
center of every cell that influences how other genes are switched on or off,
like lights, changing how the body builds fat and muscle. Somewhere along
the three billion Gs, Ts, As, and Cs in Jill’s genome, a single-letter typo just
happened to be very poorly placed.
Jill was happy to have helped discover a new disease-causing mutation.
And yet “it’s almost darkly comical,” she told me. “It comes down to a G
that was changed to a C.”
Jill’s father was sixty-three, in 2012, when his heart finally failed.
By then, Jill had transitioned to a motorized scooter, gotten married and
had a son, and retired from her medical detective work .
Days after their father passed, her younger sister showed her a picture
online of an extremely muscular Olympic sprinter who was conspicuously
missing fat. “I took one look at it, and just . . . what?! We don’t have that.
What are you talking about?” Jill said. Then she got curious.
Jill had actually wondered about fat for a long time. Like muscle, it was
noticeably absent from her limbs. More than a decade earlier, when she was
twenty-five, a lab director at Johns Hopkins heard about her and, wanting a
real-life lamin mutant in the lab, offered her a summer internship perusing
journals for any condition caused by a lamin mutation. She came across an
incredibly rare disease called partial lipodystrophy, which causes fat on the
limbs to disappear, leaving veins and muscles shrink-wrapped in skin.
Again, Jill saw her family. Could she have not one, but two ridiculously
rare genetic diseases? She pestered doctors at a medical conference with
photos. They assured her she did not have lipodystrophy, and diagnosed her
with something more common: intern syndrome. “Where you have a

medical student introduced to a lot of new======================================================== “necessary nor healthy” for children to
be directed toward one career before they can make that decision
themselves—a decision that, again, took her years of adulthood. “So what
does grit look like early in life?” she wrote. “A young child who decides
today that she wants to become a doctor but thinks tomorrow that she’d
rather build houses. A teenager who decides, no, she won’t go out for track
this year and instead will see what it’s like to write for the school
newspaper.” Specialization has benefits, she added, “but before
specialization comes sampling, the exploration of possibilities that, really,
you cannot know anything about until you try them . . . Don’t confuse the
healthy development of a work ethic with the premature commitment to a
singular passion.”
As one researcher suggested to me: “When you get fit, it will look like
grit.” That is, if you help someone find a good fit, they are more likely to
display the characteristics of grit—like sticking with something—even if
they didn’t before.
Needless to say, most people aren’t going to be Tillman Scholars,
executives, or William Shakespeare. And while many of the stories in
Range portray uncommon achievements, I hoped those would serve as
memorable portals of engagement into research that applies to a much
broader swath of humanity.
In fact, international research that studied thousands of workers—more
than three-quarters of whom did not have tertiary education—
produced findings that resonate with a major theme of the book: that
sometimes the actions that provide a head start will undermine long-term
development , whether that is choosing a career or a course of study, or
simply developing a skill or learning new material.
A 2017 study published by four economists in the U.S., Germany, and
China, analyzed education and employment data in eleven countries with

large vocational education or apprenticeship programs, comparing people
within each country who had similar backgrounds—including test scores,
family background, and years of education—but differed in whether they
received career-focused or broader, general education. Naturally, there was
considerable variation between countries and certainly between individuals,
but the general pattern was: people who got narrow, career-focused
education were more likely to be employed right out of school and earned
more right away, but over time both advantages evaporated; decades later,
they had spent less overall time in the labor market and had lower lifetime
earnings. The early specializers often won in the short term, and lost in the
long run. Workers who received general education, the economists
concluded, were better positioned to adapt to change in a wicked world
where work next year might not look like work last year.
The pattern was particularly pronounced in two countries with famously
extensive apprenticeship programs—Denmark and Germany—an important
finding given that, over the last decade, U.S. politicians on both sides of the
aisle have advocated for a move toward the German apprenticeship model.
In 2017, President Trump issued an executive order to expand
apprenticeship programs to prepare workers for “today’s rapidly changing
economy”. The economists, on the other hand, concluded that the more
rapidly a nation’s economy is changing, the greater the long-term advantage
of general education. Of the three countries with widespread apprenticeship
programs—Denmark, Germany, Switzerland—early specialization only
resulted in a lifetime earnings advantage in Switzerland, which has had
easily the slowest growing economy of those three nations in recent
decades. “This comparison is consistent with the idea that those with
general education are more adaptable to changed economic demands,” two
of the economists wrote. “Vocational education has been promoted largely
as a way of improving the transition from schooling to work, but it also
appears to reduce the adaptability of workers to technological and structural
change in the economy.”
Does that mean we should have no early vocational training or
apprenticeships at all? I certainly don’t think so, and one of the economists
who did this work pointed out that apprenticeships still work well in
specific areas, like the building trades, but also that those trades are a small
portion of unfilled jobs. In my opinion, we should preserve a variety of
pathways, to fit a variety of life circumstances. But I also think we need to

be aware of how easy it is to be fooled by head starts, assuming that they
represent terminally stable trajectories, whether the head start be for child
athletes, college students learning math, or workers entering the labor force.
“The advantages of vocational training in smoothing entry into the labor
market,” the economists wrote, “have to be set against disadvantages later
in life, disadvantages that are likely to be more severe as we move more
into being a knowledge economy.”
The question of how broad or specialized to be is important to just about
everyone at some point or another, but usually only discussed with
intuition. Like any complex question that involves human beings, there is
no one-size-fits-all answer. My hope was to make discussions about that
crucial topic more interesting and productive.
I’m a science writer, so in doing that, I wanted to rely heavily on
scientific research that bears on the question from various angles. In talking
with readers after the hardcover publication, though, I’ve increasingly felt
that the stories of late starts or zig-zagging career paths have a specific
importance. The “availability heuristic” is a well-known cognitive bias in
which we tend to rely on the first example that comes to mind when making
a decision or judging an idea. Tiger stories have supplied millions of brains
with availability-heuristic ammo when they think of specialization. I hope
some of the stories in this book—from Federer and Van Gogh to Frances
Hesselbein (now 104, still working)—might stick in readers’ minds and
surface when the Tiger stories do, adding much needed balance to how we
consider the topic.
When I was allotted this space for an afterword to the paperback edition,
I first thought I should stuff it with research that I had to cut from the
hardcover due to space constraints. (My editor talked me off that cliff.)
Instead, I’d like to share one more memorable story.
When asked, Titus Kaphar reflexively says that nobody in his family went
to college. His mother didn’t go to college. His father went to prison, but
not to college. Neither his grandmother nor his grandfather went to college.
Nobody went to college. Except—he corrects himself—a distant cousin
went to college. Kaphar himself certainly wasn’t going to college. He often
didn’t even go to high school, hence the 0.65 GPA.

And yet, in his twenties, he decided to enroll in a few junior college
classes. Allow him to explain: he wanted to date a soon-to-be teacher; she
was four years older, contemplating grad school, and not impressed that he
had no plans for his future.
“So I just went over to the junior college,” Kaphar told me, “kind of as a
joke, not really taking it seriously, because, you know, I’m not an academic.
I’m not a person who does really well in school.” He picked a few classes
more or less at random. He came back and told the object of his affection.
They had a quick laugh about it.
One class was art history. Why? “I probably read the word ‘art’ and
thought, ‘art should be easy,’” Kaphar told me. In an unexpected way, it
was. Kaphar realized that he could remember details of paintings—not just
remember what he had seen, but associate the painting with the style of a
particular artist or artistic movement. “I remember one day we were talking
about Van Gogh,” he recalled, “and I remember seeing the image and being
very aware of where the painting sat in the history of art, where it sat in the
timeline the professor was trying to lay out for us.” He began to contribute
to class discussions. His confidence grew, and he got a B in the class.
“That was a new experience for me,” he told me, “a B overall in the class
at something that was academic. It made me go, ‘Hold up, wait a minute.’ I
realized this was, in fact, something that I was enjoying, and I could feel
myself wanting to push harder. When it became difficult, that grit became
more apparent.” He took more classes, and tested strategies until he found
something that worked, like dictating essays into a recorder for his first
draft, and studying for history tests by focusing on connecting the images in
a book to the surrounding material. Suddenly, college didn’t seem like such
a crazy idea.
Kaphar proceeded to San José State University to study fine arts. In an
art history survey course, to his dismay, the professor skipped over the
section on black painters. So Kaphar decided to compile his own syllabus
on the topic. “I think to some degree, it was like being a reporter doing an
investigation,” he said. A friend’s grandmother was a sculptor, and gave him
books. The first was on the Harlem Renaissance. “That sort of opened the
floodgates,” he recalled. He realized that the traditional artistic canon used
in class was not some magical pantheon, but just another syllabus
assembled by humans. He collected more books, and introduced new names
into class discussion.

Eventually, he took an actual painting class, but the teacher told the class
that he didn’t believe in painting anymore, so he gave no instruction
whatsoever on technique. Instead, Kaphar started looking over other
students’ shoulders and self-teaching. “It was like, last semester I painted an
apple, and it looked like a cannonball,” he told me. “This semester that
actually looks like an apple. Now, it’s loose, a child could do the same
thing, but it looks like an apple. Awesome, let’s keep going.” He began to
study paintings and then try to reverse-engineer them. When he noticed that
shadows in Velázquez paintings didn’t======================================================== every area. This must change, he argues, if students are to
capitalize on their unprecedented capacity for abstract thought. They must be

taught to think before being taught what to think about. Students come
prepared with scientific spectacles, but do not leave carrying a scientific-
reasoning Swiss Army knife.
Here and there, professors have begun to pick up the challenge. A class at
the University of Washington titled “Calling Bullshit” (in staid coursebook
language: INFO 198/ BIOL 106B), focused on broad principles fundamental
to understanding the interdisciplinary world and critically evaluating the
daily firehose of information. When the class was first posted in 2017,
registration filled up in the first minute.
Jeannette Wing, a computer science professor at Columbia University and
former corporate vice president of Microsoft Research, has pushed broad
“computational thinking” as the mental Swiss Army knife. She advocated
that it become as fundamental as reading, even for those who will have
nothing to do with computer science or programming. “Computational
thinking is using abstraction and decomposition when attacking a large
complex task,” she wrote. “It is choosing an appropriate representation for a
problem.”
Mostly, though, students get what economist Bryan Caplan called narrow
vocational training for jobs few of them will ever have. Three-quarters of
American college graduates go on to a career unrelated to their major—a
trend that includes math and science majors—after having become
competent only with the tools of a single discipline.
One good tool is rarely enough in a complex, interconnected, rapidly
changing world. As the historian and philosopher Arnold Toynbee said when
he described analyzing the world in an age of technological and social
change, “No tool is omnicompetent.”
Flynn’s passion resonated deeply with me. Before turning to journalism, I
was in grad school, living in a tent in the Arctic, studying how changes in
plant life might impact the subterranean permafrost. Classes consisted of
stuffing my brain with the details of Arctic plant physiology. Only years later
—as an investigative journalist writing about poor scientific research—did I
realize that I had committed statistical malpractice in one section of the
thesis that earned me a master’s degree from Columbia University. Like
many a grad student, I had a big database and hit a computer button to run a
common statistical analysis, never having been taught to think deeply (or at

all) about how that statistical analysis even worked. The stat program spit
out a number summarily deemed “statistically significant.” Unfortunately, it
was almost certainly a false positive, because I did not understand the
limitations of the statistical test in the context in which I applied it. Nor did
the scientists who reviewed the work. As statistician Doug Altman put it,
“Everyone is so busy doing research they don’t have time to stop and think
about the way they’re doing it.” I rushed into extremely specialized scientific
research without having learned scientific reasoning. (And then I was
rewarded for it, with a master’s degree, which made for a very wicked
learning environment.) As backward as it sounds, I only began to think
broadly about how science should work years after I left it.
Fortunately, as an undergrad, I did have a chemistry professor who
embodied Flynn’s ideal. On every exam, amid typical chemistry questions,
was something like this: “How many piano tuners are there in New York
City?” Students had to estimate, just by reasoning, and try to get the right
order of magnitude. The professor later explained that these were “Fermi
problems,” because Enrico Fermi—who created the first nuclear reactor
beneath the University of Chicago football field—constantly made back-of-
the-envelope estimates to help him approach problems. 
*
 The ultimate lesson
of the question was that detailed prior knowledge was less important than a
way of thinking.
On the first exam, I went with gut instinct (“I have no clue, maybe ten
thousand?”)— way too high . By the end of the class, I had a new tool in my
conceptual Swiss Army knife, a way of using what little I did know to make
a guess at what I didn’t. I knew the population of New York City; most
single people in studio apartments probably don’t have pianos that get tuned,
and most of my friends’ parents had one to three children, so how many
households are in New York? What portion might have pianos? How often
are pianos tuned? How long might it take to tune a piano? How many homes
can one tuner reach in a day? How many days a year does a tuner work?
None of the individual estimates has to be particularly accurate in order to
get a reasonable overall answer. Remote Uzbek villagers would not perform
well on Fermi problems, but neither did I before taking that class. It was
easy to learn, though. Having grown up in the twentieth century, I was
already wearing the spectacles, I just needed help capitalizing on them. I
remember nothing about stoichiometry, but I use Fermi thinking regularly,

breaking down a problem so I can leverage what little I know to start
investigating what I don’t, a “similarities” problem of sorts.
Fortunately, several studies have found that a little training in broad
thinking strategies, like Fermi-izing, can go a long way, and can be applied
across domains. Unsurprisingly, Fermi problems were a topic in the “Calling
Bullshit” course. It used a deceptive cable news report as a case study to
demonstrate “how Fermi estimation can cut through bullshit like a hot knife
through butter.” It gives anyone consuming numbers, from news articles to
advertisements, the ability quickly to sniff out deceptive stats. That’s a pretty
handy hot butter knife. I would have been a much better researcher in any
domain, including Arctic plant physiology, had I learned broadly applicable
reasoning tools rather than the finer details of Arctic plant physiology.
Like chess masters and firefighters, premodern villagers relied on things
being the same tomorrow as they were yesterday. They were extremely well
prepared for what they had experienced before, and extremely poorly
equipped for everything else. Their very thinking was highly specialized in a
manner that the modern world has been telling us is increasingly obsolete.
They were perfectly capable of learning from experience, but failed at
learning without experience. And that is what a rapidly changing, wicked
world demands—conceptual reasoning skills that can connect new ideas and
work across contexts. Faced with any problem they had not directly
experienced before, the remote villagers were completely lost. That is not an
option for us. The more constrained and repetitive a challenge, the more
likely it will be automated, while great rewards will accrue to those who can
take conceptual knowledge from one problem or domain and apply it in an
entirely new one.
The ability to apply knowledge broadly comes from broad training. A
particular skilled group of performers in another place and time turned broad
training into an art form. Their story is older, and yet a much better parable
than chess prodigies for the modern age.
OceanofPDF.com

CHAPTER 3
When Less of the Same Is More
ANYWHERE A TRAVELER to seventeenth-century Venice turned an ear, they
could hear music exploding from its traditional bounds. Even the name of
the musical era, “Baroque,” is taken from a jewelers’ term to describe a
pearl that was extravagantly large and unusually shaped.
Instrumental music—music that did not depend on words—underwent a
complete revolution. Some of the instruments were brand-new, like the
piano; others were enhanced—violins made by Antonio Stradivari would
sell centuries later for millions of dollars. The modern system of major and
minor keys was created. Virtuosos, the original musical celebrities, were
anointed. Composers seized on their skill and wrote elaborate solos to push
the boundaries of the best players’ abilities. The concerto was born—in
which a virtuoso soloist plays back and forth against an orchestra—and
Venetian composer Antonio Vivaldi (known as il Prete Rosso, the Red
Priest, for his flame-red hair) became the form’s undisputed champion. The
Four Seasons is as close to a pop hit as three-hundred-year-old music gets.
(A mashup with a song from Disney’s Frozen has ninety million YouTube
plays.)
Vivaldi’s creativity was facilitated by a particular group of musicians
who could learn new music quickly on a staggering array of instruments.
They drew emperors, kings, princes, cardinals, and countesses from across
Europe to be regaled by the most innovative music of the time. They were
the all-female cast known as the figlie del coro, literally, “daughters of the
choir.” Leisure activities like horseback riding and field sports were scarce
in the floating city, so music bore the full weight of entertainment for its

citizens. The sounds of violins, flutes, horns, and voices spilled into the
night from every bobbing barge and gondola. And in a time and place
seething with music, the figlie dominated for a century.
“Only in Venice,” a prominent visitor wrote, “can one see these musical
prodigies.” They were both ground zero of a musical revolution and an
oddity. Elsewhere, their instruments were reserved for men. “They sing like
angels, play the violin, the flute, the organ, the oboe, the cello, and the
bassoon,” an astonished French politician remarked. “In short, no
instrument is large enough to frighten them.” Others were less diplomatic.
Aristocratic British writer Hester Thrale complained, “The sight of girls
handling the double bass, and blowing into the bassoon did not much please
me.” After all, “suitable feminine instruments” were more along the lines of
the harpsichord or musical glasses.
The figlie left the king of Sweden in awe. Literary rogue Casanova
marveled at the standing-room-only crowds. A dour French concert
reviewer singled out a======================================================== cutting
edge of artificial intelligence: “neural networks” that learn how to identify
images from examples (when you search cat pictures, for instance) were
conceived as akin to the neurons of the brain, and “genetic algorithms” are
conceptually based on evolution by natural selection—solutions are tried,
evaluated, and the more successful solutions pass on properties to the next
round of solutions, ad infinitum. It is the furthest extension of the type of
thinking that was foreign to Luria’s premodern villagers, whose problem
solving depended on direct experience.
Kepler was facing a problem not just new to himself, but to all humanity.
There was no experience database to draw on. To investigate whether he
should be the first ever to propose “action at a distance” in the heavens (a

mysterious power invisibly traversing space and then appearing at its
target), he turned to analogy (odor, heat, light) to consider whether it was
conceptually possible. He followed that up with a litany of distant analogies
(magnets, boats) to think through the problem.
Most problems, of course, are not new, so we can rely on what Gentner
calls “surface” analogies from our own experience. “Most of the time, if
you’re reminded of things that are similar on the surface, they’re going to
be relationally similar as well,” she explained. Remember how you fixed
the clogged bathtub drain in the old apartment? That will probably come to
mind when the kitchen sink is clogged in the new one.
But the idea that surface analogies that pop to mind work for novel
problems is a “kind world” hypothesis, Gentner told me. Like kind learning
environments, a kind world is based on repeating patterns. “It’s perfectly
fine,” she said, “if you stay in the same village or the same savannah all
your life.” The current world is not so kind; it requires thinking that cannot
fall back on previous experience. Like math students, we need to be able to
pick a strategy for problems we have never seen before. “In the life we lead
today,” Gentner told me, “we need to be reminded of things that are only
abstractly or relationally similar. And the more creative you want to be, the
more important that is.”
In the course of studying problem solving in the 1930s, Karl Duncker posed
one of the most famous hypothetical problems in all of cognitive
psychology. It goes like this:
Suppose you are a doctor faced with a patient who has a malignant stomach tumor. It is
impossible to operate on this patient, but unless the tumor is destroyed the patient will die.
There is a kind of ray that can be used to destroy the tumor. If the rays reach the tumor all at
once at a sufficiently high intensity, the tumor will be destroyed. Unfortunately, at this
intensity the healthy tissue that the rays pass through on the way to the tumor will also be
destroyed. At lower intensities the rays are harmless to healthy tissue, but they will not affect
the tumor either. What type of procedure might be used to destroy the tumor with the rays, and
at the same time avoid destroying the healthy tissue?
It’s on you to excise the tumor and save the patient, but the rays are either
too powerful or too weak. How can you solve this? While you’re thinking, a
little story to pass the time: There once was a general who needed to capture
a fortress in the middle of a country from a brutal dictator. If the general
could get all of his troops to the fortress at the same time, they would have

no problem taking it. Plenty of roads that the troops could travel radiated
out from the fort like wheel spokes, but they were strewn with mines, so
only small groups of soldiers could safely traverse any one road. The
general came up with a plan. He divided the army into small groups, and
each group traveled a different road leading to the fortress. They
synchronized their watches, and made sure to converge on the fortress at the
same time via their separate roads. The plan worked. The general captured
the fortress and overthrew the dictator.
Have you saved the patient yet? Just one last story while you’re still
thinking: Years ago, a small-town fire chief arrived at a woodshed fire,
concerned that it would spread to a nearby house if it was not extinguished
quickly. There was no hydrant nearby, but the shed was next to a lake, so
there was plenty of water. Dozens of neighbors were already taking turns
with buckets throwing water on the shed, but they weren’t making any
progress. The neighbors were surprised when the fire chief yelled at them to
stop, and to all go fill their buckets in the lake. When they returned, the
chief arranged them in a circle around the shed, and on the count of three
had them all throw their water at once. The fire was immediately dampened,
and soon thereafter extinguished. The town gave the fire chief a pay raise as
a reward for quick thinking.
Are you done saving your patient? Don’t feel bad, almost no one solves
it. At least not at first, and then nearly everyone solves it. Only about 10
percent of people solve “Duncker’s radiation problem” initially. Presented
with both the radiation problem and the fortress story, about 30 percent
solve it and save the patient. Given both of those plus the fire chief story,
half solve it. Given the fortress and the fire chief stories and then told to use
them to help solve the radiation problem, 80 percent save the patient.
The answer is that you (the doctor) could direct multiple low-intensity
rays at the tumor from different directions, leaving healthy tissue intact, but
converging at the tumor site with enough collective intensity to destroy it.
Just like how the general divided up troops and directed them to converge at
the fortress, and how the fire chief arranged neighbors with their buckets
around the burning shed so that their water would converge on the fire
simultaneously.
Those results are from a series of 1980s analogical thinking studies.
Really, don’t feel bad if you didn’t get it. In a real experiment you would
have taken more time, and whether you got it or not is unimportant. The

important part is what it shows about problem solving. A gift of a single
analogy from a different domain tripled the proportion of solvers who got
the radiation problem. Two analogies from disparate domains gave an even
bigger boost. The impact of the fortress story alone was as large as if
solvers were just straight out told this guiding principle: “If you need a
large force to accomplish some purpose, but are prevented from applying
such a force directly, many smaller forces applied simultaneously from
different directions may work just as well.”
The scientists who did that work expected that analogies would be fuel
for problem solving, but they were surprised that most solvers working on
the radiation problem did not find clues in the fortress story until they were
directed to do so. “One might well have supposed,” the scientists wrote, that
“being in a psychology experiment would have led virtually all subjects to
consider how the first part [of the study] might be related to the second.”
Human intuition, it appears, is not very well engineered to make use of
the best tools when faced with what the researchers called “ ill-defined”
problems. Our experience-based instincts are set up well for Tiger domains,
the kind world Gentner described, where problems and solutions repeat.
An experiment on Stanford international relations students during the
Cold War provided a cautionary tale about relying on kind-world reasoning
—that is, drawing only on the first analogy that feels familiar. The students
were told that a small, fictional democratic country was under threat from a
totalitarian neighbor, and they had to decide how the United States should
respond. Some students were given descriptions that likened the situation to
World War II (refugees in boxcars; a president “from New York, the same
state as FDR”; a meeting in “Winston Churchill Hall”). For others, it was
likened to Vietnam, (a president “from Texas, the same state as LBJ,” and
refugees in boats). The international relations students who were reminded
of World War II were far more likely to choose to go to war; the students
reminded of Vietnam opted for nonmilitary diplomacy. That phenomenon
has been documented all over the place. College football coaches rated the
same player’s potential very differently depending on what former player he
was likened to in an introductory description, even with all other
information kept exactly the same.
With the difficult radiation problem, the most successful strategy
employed multiple situations that were not at all alike on the surface, but
held deep structural similarities. Most problem solvers are not like Kepler.

They will stay inside of the problem at hand, focused on the internal details,
and perhaps summon other medical knowledge, since it is on the surface a
medical problem. They will not intuitively turn to distant analogies to probe
solutions. They should, though, and they should make sure some of those
analogies are, on the surface, far removed from the current problem. In a
wicked world, relying upon experience from a single domain is not only
limiting, it can be disastrous .
The trouble with using no more than a single analogy, particularly one from
a very similar situation, is that it does not help battle the natural impulse to
employ the “inside view,” a term coined by psychologists Daniel Kahneman
and Amos Tversky. We take the inside view when we make judgments
based narrowly on the details of a particular project that are right in front of
us.
Kahneman had a personal experience with the dangers of the inside view
when he assembled a team to write a high school curriculum on the science
of decision making. After a full year of weekly meetings, he surveyed the
entire team to find out how long everyone thought the project would take.
The lowest estimate was one and a half years, the highest two and a half
years. Kahneman then asked a team member======================================================== the Oscar-
nominated war documentary Restrepo. “That cut was the best thing that
ever could have happened to me,” he told me. “It gave me this template for
seeing my career. Virtually every good thing in my life I can trace back to a
misfortune, so my feeling is you don’t know what’s good and what’s bad
when things happen. You do not know. You have to wait to find out.”
My favorite fiction writers might be darker dark horses still. Haruki
Murakami wanted to be a musician, “but I couldn’t play the instruments
very well,” he said. He was twenty-nine and running a jazz bar in Tokyo
when he went to a spring baseball game and the crack of the bat—“a
beautiful, ringing double,” Murakami wrote—gave him the revelation that
he could write a novel. Why did that thought come to him? “I didn’t know
then, and I don’t know now.” He started writing at night. “The sensation of
writing felt very fresh.” Murakami’s fourteen novels (all feature music
prominently) have been translated into more than fifty languages.

Fantasy writer Patrick Rothfuss began studying chemical engineering in
college, which “led to a revelation that chemical engineering is boring.” He
then spent nine years bouncing between majors “before being kindly asked
to graduate already.” After that, according to his official bio, “Patrick went
to grad school. He’d rather not talk about it.” Meanwhile, he was slowly
working on a novel. That novel, The Name of the Wind (in which chemistry
appears repeatedly), sold millions of copies worldwide and is source
material for a potential TV successor to Game of Thrones .
Hillary Jordan just happened to live downstairs from me in a Brooklyn
apartment building, and told me that she worked in advertising for fifteen
years before beginning to write fiction. Her first novel, Mudbound, won the
Bellwether Prize for socially engaged fiction. The film version was
purchased by Netflix and in 2018 received four Oscar nominations.
Unlike Jordan, Maryam Mirzakhani actually expected to be a novelist
from the start. She was enchanted by bookstores near her school when she
was young and dreamed of writing. She had to take math classes, but “I was
just not interested in thinking about it,” she said later. Eventually she came
to see math as exploration. “It is like being lost in a jungle and trying to use
all the knowledge that you can gather to come up with some new tricks, and
with some luck, you might find a way out.” In 2014, she became the first
woman to win the Fields Medal, the most famous math prize in the world.
Of the athletes I met when I worked at Sports Illustrated, the one I most
admired was British Ironman triathlete (and writer and humanitarian)
Chrissie Wellington, who sat atop a road bike for the first time in her life at
age twenty-seven. She was working on a sewage sanitation project in Nepal
when she found that she enjoyed cycling, and could keep up with Sherpas at
altitude in the Himalayas. Two years after returning home, she won the first
of four Ironman world championships, and then proceeded to go 13–0 at the
Ironman distance over a career that started late and spanned just five years.
“My passion for the sport hasn’t waned,” she said when she retired, “but my
passion for new experiences and new challenges is what is now burning the
most brightly.”
I’m a fan of Irish theater, and my favorite performer is Irish actor Ciarán
Hinds, more widely known for his HBO roles—Julius Caesar in Rome and
Game of Thrones ’ Mance Rayder, the “King Beyond the Wall”—and as a
star of AMC’s The Terror. (His voice may be best known as head troll
Grand Pabbie in Disney’s Frozen .) This book gave me an excuse to ask

Hinds about his career path, and he recalled having been a “flighty
gadabout” unsure of his direction when he enrolled as a law student at
Queen’s University Belfast. His attention was quickly diverted “due to a
keen interest in snooker, poker, and experimental dance,” he told me. One
of Hinds’s class tutors had seen him as a twelve-year-old portraying Lady
Macbeth in a school play, and suggested he bag legal studies and apply to
drama school. “He also had the goodness to speak to my parents on the
matter, who were rather trepidatious,” Hinds told me. “Off I went to study
at the Royal Academy of Dramatic Art, and my life in the professional
theater began.”
The Van Gogh biography by Steven Naifeh and his late partner and
coauthor Gregory White Smith is one of the best books I have ever read in
any genre. Naifeh and Smith met in law school as both were realizing it was
not for them. They started cowriting books on an eclectic array of topics,
from true crime to men’s style, even as an editor told them they needed to
pick one genre and stick with it. Their willingness to dive into new areas
paid unexpected dividends. When an editor at another publishing house
asked them to write a guide to using lawyers’ services, it led them to found
Best Lawyers, which spawned a massive industry of peer-recommendation
publications. “If we hadn’t taken that idea [to create a reference to help
people select lawyers] and run with it,” Naifeh told me, “our lives would
have been dramatically different, and it wasn’t like anything we had done
before.” They might never have had the means and freedom to spend a
decade researching their Van Gogh biography, or their biography of Jackson
Pollock that won the Pulitzer Prize.
Pollock, Naifeh told me, “was literally one of the least talented draftsmen
at the Art Students League.” Naifeh argues that, as with Van Gogh,
Pollock’s lack of traditional drawing skill was what led him to invent his
own rules for making art. As schools offering standardized paths in art have
proliferated, “one of the problems is that artists tend to be products of those
schools,” said Naifeh, an artist himself.
Maybe that has helped fuel an explosion of interest in so-called outsider
art, by practitioners who began without a standard path in sight. Of course,
there is nothing wrong with coming through the formal talent development
system, but if that’s the only pipeline that exists, some of the brightest
talents get missed. “Outsider artists” are the self-taught jazz masters of
visual art, and the originality of their work can be stunning. In 2018, the

National Gallery of Art featured a full exhibition dedicated to self-taught
artists; art history programs at Stanford, Duke, Yale, and the Art Institute of
Chicago now offer seminars in outsider art. Katherine Jentleson, who in
2015 was appointed as a full-time curator of self-taught art at the High
Museum of Art in Atlanta, told me that these artists typically started just by
experimenting and doing things they liked, while working other jobs. “The
majority did not begin their art making in earnest until after retirement,”
Jentleson said.
She introduced me to the sculptor and painter Lonnie Holley, a prominent
self-taught artist who grew up extremely poor in Alabama. In 1979, when
he was twenty-nine, his sister’s two children died in a fire. The family could
not afford gravestones, so Holley gathered discarded sandstone at a nearby
foundry and carved them himself. “I didn’t even know what art was!” he
told me, his eyes wide, as if taken by surprise at his own story. But it felt
good. He carved gravestones for other families and started making
sculptures out of anything he could find. I was standing with him near the
door of an Atlanta gallery featuring his work when he grabbed a paper clip
and quickly bent it into an intricate silhouette of a face, which he jabbed
decoratively into the eraser of a pencil the woman at the front desk was
using. It is hard to imagine a time before he made art, since it seems like he
can hardly touch something before his hands begin exploring what else it
might become .
Jentleson also pointed me to Paradise Garden, ninety miles north-west of
Atlanta, the painting-and sculpture-filled property of the late minister
Howard Finster, the Frances Hesselbein of modern art. Finster had long
compiled bricolage displays on his land, from collections of tools to
assortments of fruit-bearing plants. He was fixing a bicycle one day in
1976, when he was fifty-nine, and saw what looked like a face in a splotch
of white paint on his thumb. “A warm feelin’ come over my body,” he
recalled. Finster immediately began an oeuvre of tens of thousands of
artworks that filled his property, including thousands of paintings in his
unique, semi-cartoonish style, often densely packed with animals and
figures—Elvis, George Washington, angels—and set fancifully in
apocalyptic landscapes. In short order, he was appearing on Johnny
Carson’s Tonight Show and creating album covers for R.E.M. and Talking
Heads. Upon entry to the garden, I was greeted by a giant self-portrait of a
smirking Finster in a burgundy suit, affixed to a cinderblock wall. At the

bottom are the words “I began painting pictures in Jan-1976—without any
training. This is my painting. A person don’t know what he can do unless he
tryes. Trying things is the answer to find your talent.”
OceanofPDF.com

CHAPTER 8
The Outsider Advantage
ALPH BINGHAM WILL be the first to admit it: he is hyperspecialized, at least in
theory. “My PhD isn’t even in chemistry, it’s in organic chemistry!” he
exclaimed. “If there’s not a carbon in it, I’m technically not qualified,
okay?”
In graduate school in the 1970s, Bingham and his classmates had to
devise ways to create particular molecules. “This was a bunch of smart guys
and women and we could make these molecules,” he told me, “but
somehow someone’s solution was always cleverer than the others. I was
paying attention, and I noticed that the most clever solution always came
from a piece of knowledge that was not a part of the normal curriculum.”
One day, he was the cleverest.
He had come up with an elegant solution to synthesize a molecule in four
short steps, and the key piece of knowledge involved cream of tartar, a
baking ingredient Bingham happened to know from childhood. “You======================================================== dates to 1592. In the New Latin form “Johannes factotum ”, it was
contained in a pamphlet by a playwright criticizing his own industry. The
jab refers to a poet with no university education who was apparently
involved in various other roles, like copying scripts and bit-part acting, even
trying to write plays. The poet on the receiving end of the insult: a young
William Shakespeare. The phrase evolved over time, and today it’s usually
“jack of all trades, master of none.” I think it is culturally telling that we
habitually hack off the end of the long version: “A jack of all trades is a
master of none, but oftentimes better than a master of one.”
Lately I’ve been thinking in a more personal way about the implications
of these cultural cues, and of the research in Range . Between the time I
turned in the final manuscript and the time the hardcover was published, I
became a parent. I’ve been asking myself how, in this new adventure, I
might (eventually) wield some of what I learned. That, in turn, led me to a
bit of analogical thinking: at the moment, I’m conceiving of my role as akin
to the role of a coach-like mentor in the Army’s “talent-based branching”
program. I realize it might seem odd for me to liken my parenting strategy
to a military program—one that I mentioned only in a footnote here . But
this is not a surface analogy: it’s a deeper, structural analogy.
The talent-based branching program grew out of the Army’s realization
(discussed in chapter 6) that it had developed a match quality problem,
particularly with West Point and ROTC cadets who received scholarships.
The Army persisted in a traditional model of talent development: assigning
future officers to a career path before they knew much about their own
abilities and interests, or much of anything about the career. Cadets could
express preferences, but it amounted to requesting a profession they did not
know well enough for the person they had not yet become. And once they
chose, they were stuck. In a knowledge economy, bursting with sampling

and lateral mobility, cadets simply left the service (in droves) if they turned
out to have a subpar career match. The talent-based branching program was
designed to help young officers get a better understanding of potential
careers earlier in the selection process, and discover their own interests and
talents at the same time. Essentially, it provides them with a sampling
period.
As officers-in-training cycle through classes, internship-like work
experiences, and field training that exposes them to different jobs, they are
encouraged to take part in constant self-reflection, both on their own (which
they can track in an online portal) and with mentors. (Learning about and
reflecting on their own strengths and weaknesses, according to an Army
Strategic Studies Institute monograph, “can sometimes be a bit of a shock.”)
The idea is to foster better match quality, and in turn to improve
performance, satisfaction, and retention. When talent-based branching was
piloted with West Point cadets, nearly 90 percent of participating cadets
changed at least one of their top three career preferences. Once again: we
learn who we are in practice, not in theory.
I think that’s a useful model for parenting. First, I’d like to facilitate a
sampling period for my kid—to expose him to a variety of experiences and
possibilities. (A 2019 OECD report found that children already significantly
narrow their ideas of possible careers by age seven. “We must fight to keep
their horizons open,” said Andreas Schleicher, OECD’s director for
education and skills.) And then my role is that of the mentor, supporting my
son by helping him get the maximum amount of signal about his own
talents, interests, and options from each experience. I hope that will help
guide him to good match quality, broaden his toolbox en route, and form a
habit of regular reflection reminiscent of the dark horses from chapter 7,
who repeatedly say to themselves: “Here’s who I am at the moment, here
are my motivations, here’s what I’ve found I like to do, here’s what I’d like
to learn, and here are the opportunities. Which of these is the best match
right now? And maybe a year from now I’ll switch because I’ll find
something better.”
Shortly after Range came out, Ruth Brennan Morrey—a former college
soccer captain, pro triathlete, Olympic Trials marathon qualifier, and
psychology PhD—tagged me in an apt tweet: “Listening to @DavidEpstein
Range in the car with twelve-year-old daughter. ‘Mom, why do we make
“What I want to be when I grow up” signs on the first day of school? We

should make “Top 5 things I want to learn about this year” signs.’ Smart
cookie. :-)” I think I’ll borrow the twelve-year-old’s idea.
Ultimately, I think the idea of helping individuals get the maximum
match quality signal from each zig and zag is a good model, whether one is
“managing” kids, mentees, teammates, employees, or, as management
scholar Peter Drucker put it twenty years ago in a prophetic Harvard
Business Review article, “managing oneself.” The summary atop the article
—which predicts that workers would increasingly have longer and
multifaceted careers—reads: “Success in the knowledge economy comes to
those who know themselves—their strengths, their values, and how they
best perform.”
That is often easier said than done. One of the most common questions I
received after the hardcover publication of Range came from people who
viewed themselves as latecomers or generalists; the refrain was that they
believe employers will view their varied background as a liability, so they
downplay it. They would ask me how to make it a selling point, or at least
not a liability.
I get it. Weeks before publication, I had the honor of participating for the
second time on the final selection committee for the Pat Tillman
Foundation, which awards scholarships to veterans to aid professional
development and career changes. I was hyperconscious of the fact that
when I began reviewing an application by perusing the candidate’s résumé,
my first, reflexive impression was sometimes that they appeared a bit
scattered. But then I would delve more deeply into their journey, and what
appeared scattered at first blush became something completely different.
Let’s say a hypothetical candidate started work after high school or college.
They didn’t feel fulfilled, so they joined the military. Once enlisted, they
ended up doing something other than what they expected—say, organizing
medical care for citizens of a remote village in another country—and during
that time they learned something about international relations, or about
bureaucratic dysfunction, or about the administration of public health
initiatives. Meanwhile, they also learned they were good (or not so good) at
and interested in things they had not expected, and they returned to civilian
life with new ideas about a field to enter or a business to start. Viewed
holistically, what initially looked scattered on a résumé morphed into a

journey in which the traveler was responding to lived experience with
changes of direction, rather than continuing down an initial path just
because they started there. In my experience with the foundation, applicants
who win a scholarship are often those who explain a varied path—including
stops along the way that sometimes seem far afield—as a series of lessons
and subsequent pivots. I think that is a good strategy to keep in mind: rather
than hiding diverse experience, explain it.
People who told me that they downplayed their broad backgrounds
worried that their online résumés would not serve them well. I think that’s a
valid concern, and a shame if it holds them back. LinkedIn is the most
popular résumé database, and the site’s own research has found that one of
the strongest predictors of who will eventually become an executive is the
number of different job functions an individual has worked across. Based
on that analysis, LinkedIn’s principal economist, Guy Berger, gave
straightforward advice: “My recommendation for those of you who want to
become executives is to work across as many job functions as possible.”
Executives with more varied careers have also been found to be “more
likely to have novel strategies . . . which is key to a sustainable competitive
advantage,” according to Gina Dokko, a professor at the University of
California-Davis Graduate School of Management. “Research has
established pretty firmly that diverse groups of people are better at
innovation and problem solving, but more recent research is finding that
diverse career histories within a single person can also benefit
performance.”
Plus, career-path swerves are now common. Separate LinkedIn research
found that nearly half of professionals who switch jobs move to a different
industry—up about 10 percent from a decade ago—and 60 percent move to
a completely new job function. So perhaps it would be a good idea for sites
that host résumés, and organizations that review them, to include some
function that allows users the chance to share their résumé as a narrative
journey in which they can explain the lessons of their zigs and zags, rather
than just list them as bullet points. In my mind, a system that leads people
to downplay previous experiences, as if they were entirely wasted, is a
counterproductive one. We shouldn’t be ashamed of broad experience, or of
needing time to find match quality. Take it from Angela Duckworth, the
researcher whose work popularized the psychological construct of “grit.”

Two days before Range was published, an edition of Duckworth’s weekly
email was titled, “Summer is for Sampling.” “Many parents ask me for
advice on how to get their kids to stick to one thing for years and years like
the paragons of grit I study,” Duckworth wrote. “I can empathize. In the
decade of adult life it took me to commit to becoming a psychologist, I was
desperate for direction to match my determination.”
Duckworth added that it is neither======================================================== right.
Macduff got less than one in five. There was, though, an exception: the lists
on which they never had hints at all.
For those lists, on day one of practice the duo had performed terribly.
They were literally monkeys hitting buttons. But they improved steadily
each training day. On test day, Oberon nailed almost three-quarters of the
lists that he had learned with no hints. Macduff got about half of them.
The overall experiment results went like this: the more hints that were
available during training, the better the monkeys performed during early
practice, and the worse they performed on test day. For the lists that
Macduff spent three days practicing with automatic hints, he got zero
correct. It was as if the pair had suddenly unlearned every list that they

practiced with hints. The study conclusion was simple: “training with hints
did not produce any lasting learning.”
Training without hints is slow and error-ridden. It is, essentially, what we
normally think of as testing, except for the purpose of learning rather than
evaluation—when “test” becomes a dreaded four-letter word. The eighth-
grade math teacher was essentially testing her students in class, but she was
facilitating or outright giving them the answers.
Used for learning, testing, including self-testing, is a very desirable
difficulty. Even testing prior to studying works, at the point when wrong
answers are assured. In one of Kornell’s experiments, participants were
made to learn pairs of words and later tested on recall. At test time, they did
the best with pairs that they learned via practice quizzes, even if they had
gotten the answers on those quizzes wrong. Struggling to retrieve
information primes the brain for subsequent learning, even when the
retrieval itself is unsuccessful. The struggle is real, and really useful. “Like
life,” Kornell and team wrote, “retrieval is all about the journey.”
If that eighth-grade classroom followed a typical academic plan over the
course of the year, it is precisely the opposite of what science recommends
for durable learning—one topic was probably confined to one week and
another to the next. Like a lot of professional development efforts, each
particular concept or skill gets a short period of intense focus, and then on
to the next thing, never to return. That structure makes intuitive sense, but it
forgoes another important desirable difficulty: “spacing,” or distributed
practice.
It is what it sounds like—leaving time between practice sessions for the
same material. You might call it deliberate not-practicing between bouts of
deliberate practice. “There’s a limit to how long you should wait,” Kornell
told me, “but it’s longer than people think. It could be anything, studying
foreign language vocabulary or learning how to fly a plane, the harder it is,
the more you learn.” Space between practice sessions creates the hardness
that enhances learning. One study separated Spanish vocabulary learners
into two groups—a group that learned the vocab and then was tested on it
the same day, and a second that learned the vocab but was tested on it a
month later. Eight years later, with no studying in the interim, the latter

group retained 250 percent more. For a given amount of Spanish study,
spacing made learning more productive by making it easy to make it hard.
It does not take nearly that long to see the spacing effect. Iowa State
researchers read people lists of words, and then asked for each list to be
recited back either right away, after fifteen seconds of rehearsal, or after
fifteen seconds of doing very simple math problems that prevented
rehearsal. The subjects who were allowed to reproduce the lists right after
hearing them did the best. Those who had fifteen seconds to rehearse before
reciting came in second. The group distracted with math problems finished
last. Later, when everyone thought they were finished, they were all
surprised with a pop quiz: write down every word you can recall from the
lists. Suddenly, the worst group became the best. Short-term rehearsal gave
purely short-term benefits. Struggling to hold on to information and then
recall it had helped the group distracted by math problems transfer the
information from short-term to long-term memory. The group with more
and immediate rehearsal opportunity recalled nearly nothing on the pop
quiz. Repetition, it turned out, was less important than struggle.
It isn’t bad to get an answer right while studying. Progress just should not
happen too quickly, unless the learner wants to end up like Oberon (or,
worse, Macduff), with a knowledge mirage that evaporates when it matters
most. As with excessive hint-giving, it will, as a group of psychologists put
it, “produce misleadingly high levels of immediate mastery that will not
survive the passage of substantial periods of time.” For a given amount of
material, learning is most efficient in the long run when it is really
inefficient in the short run. If you are doing too well when you test yourself,
the simple antidote is to wait longer before practicing the same material
again, so that the test will be more difficult when you do. Frustration is not
a sign you are not learning, but ease is.
Platforms like Medium and LinkedIn are absolutely rife with posts about
shiny new, unsupported learning hacks that lead to mind-blowingly rapid
progress—from special dietary supplements and “ brain-training” apps to
audio cues meant to alter brain waves. In 2007, the U.S. Department of
Education published a report by six scientists and an accomplished teacher
who were asked to identify learning strategies that truly have scientific
backing. Spacing, testing, and using making-connections questions were on
the extremely short list. All three impair performance in the short term.

As with the making-connections questions Richland studied, it is difficult
to accept that the best learning road is slow, and that doing poorly now is
essential for better performance later. It is so deeply counterintuitive that it
fools the learners themselves, both about their own progress and their
teachers’ skill. Demonstrating that required an extraordinarily unique study.
One that only a setting like the U.S. Air Force Academy could provide.
In return for full scholarships, cadets at the Air Force Academy commit to
serve as military officers for a minimum of eight years after graduation. 
*
They submit to a highly structured and rigorous academic program heavy
on science and engineering. It includes a minimum of three math courses
for every student.
Every year, an algorithm randomly assigns incoming cadets to sections of
Calculus I, each with about twenty students. To examine the impact of
professors, two economists compiled data on more than ten thousand cadets
who had been randomly assigned to calculus sections taught by nearly a
hundred professors over a decade. Every section used the exact same
syllabus, the exact same exam, and the exact same postcourse professor
evaluation form for cadets to fill out.
After Calculus I, students were randomized again to Calculus II sections,
again with the same syllabus and exam, and then again to more advanced
math, science, and engineering courses. The economists confirmed that
standardized test scores and high school grades were spread evenly across
sections, so the instructors were facing similar challenges. The Academy
even standardized test-grading procedures, so every student was evaluated
in the same manner. “Potential ‘bleeding heart’ professors,” the economists
wrote, “had no discretion to boost grades.” That was important, because
they wanted to see what differences individual teachers made.
Unsurprisingly, there was a group of Calculus I professors whose
instruction most strongly boosted student performance on the Calculus I
exam, and who got sterling student evaluation ratings. Another group of
professors consistently added less to student performance on the exam, and
students judged them more harshly in evaluations. But when the economists
looked at another, longer-term measure of teacher value added—how those
students did on subsequent math and engineering courses that required
Calculus I as a prerequisite—the results were stunning. The Calculus I

teachers who were the best at promoting student overachievement in their
own class were somehow not great for their students in the long run.
“Professors who excel at promoting contemporaneous student
achievement,” the economists wrote, “on average, harm the subsequent
performance of their students in more advanced classes.” What looked like
a head start evaporated.
The economists suggested that the professors who caused short-term
struggle but long-term gains were facilitating “deep learning” by making
connections. They “broaden the curriculum and produce students with a
deeper understanding of the material.” It also made their courses more
difficult and frustrating, as evidenced by both the students’ lower Calculus I
exam scores and their harsher evaluations of their instructors. And vice
versa. The calculus professor who ranked dead last in deep learning out of
the hundred studied—that is, his students underperformed in subsequent
classes—was sixth in student evaluations, and seventh in student
performance during his own class. Students evaluated their instructors
based on how they performed on tests right now —a poor measure of how
well the teachers set them up for later development—so they gave the best
marks to professors who provided them with the least long-term benefit.
The economists concluded that students were actually selectively punishing
the teachers who provided them the most long-term benefit. Tellingly,
Calculus I students whose teachers had fewer qualifications and less
experience did better in that class, while the students of more experienced
and qualified teachers struggled in Calculus I but did better in subsequent
courses.
A similar study was conducted at Italy’s Bocconi University, on twelve
hundred======================================================== reverse.
In a separate study of twelve hundred young musicians, those who quit
reported “a mismatch between the instruments [they] wanted to learn to
play and the instruments they actually played.” Amy Chua described her
daughter Lulu as a “natural musician.” Chua’s singer friend called Lulu
“extraordinary,” with a gift “no one can teach.” Lulu made rapid progress
on the violin, but pretty soon told her mother ominously, “You picked it, not
me.” At thirteen, she quit most of her violin activities. Chua, candid and
introspective, wondered in the coda of her book if Lulu would still be
playing if she had been allowed to choose her own instrument.
When Sloboda and a colleague conducted a study with students at a
British boarding school that recruited from around the country—admission
rested entirely on an audition—they were surprised to find that the students
classified as exceptional by the school came from less musically active
families compared to less accomplished students, did not start playing at a
younger age, were less likely to have had an instrument in the home at a
very young age, had taken fewer lessons prior to entering the school, and

had simply practiced less overall before arriving—a lot less. “It seems very
clear,” the psychologists wrote, “that sheer amount of lesson or practice
time is not a good indicator of exceptionality.” As to structured lessons,
every single one of the students who had received a large amount of
structured lesson time early in development fell into the “average” skill
category, and not one was in the exceptional group. “The strong
implication,” the researchers wrote, is “that that too many lessons at a
young age may not be helpful.”
“ However,” they added, “the distribution of effort across different
instruments seems important. Those children identified as exceptional by
[the school] turn out to be those children who distributed their effort more
evenly across three instruments.” The less skilled students tended to spend
their time on the first instrument they picked up, as if they could not give up
a perceived head start. The exceptional students developed more like the
figlie del coro . “The modest investment in a third instrument paid off
handsomely for the exceptional children,” the scientists concluded.
The psychologists highlighted the variety of paths to excellence, but the
most common was a sampling period, often lightly structured with some
lessons and a breadth of instruments and activities, followed only later by a
narrowing of focus, increased structure, and an explosion of practice
volume. Sound familiar? A study that followed up on Sloboda’s work two
decades later compared young musicians admitted to a competitive
conservatory to similarly committed but less skilled music students. Nearly
all of the more accomplished students had played at least three instruments,
proportionally much more than the lower-level students, and more than half
played four or five. Learning to play classical music is a narrative linchpin
for the cult of the head start; as music goes, it is a relatively golflike
endeavor. It comes with a blueprint; errors are immediately apparent; it
requires repetitive practice of the exact same task until execution becomes
automatic and deviation is minimal. How could picking an instrument as
early as possible and starting in technical training not be the standard path
to success? And yet even classical music defies a simple Tiger story.
The Cambridge Handbook of Expertise and Expert Performance,
published in 2006, is a sort of bible for popular writers, speakers, and
researchers in the ten-thousand-hours school. It is a compilation of
essayistic chapters, each written by different researchers who delve into
dance, math, sports, surgery, writing, and chess. The music section focuses

very conspicuously on classical playing. At nine hundred oversized pages, it
is a handbook for large hands. In the chapter on developing music expertise,
there is just one single substantive mention of the beginnings of expert
players in all the genres of music in the world that are not classical. The
Handbook simply notes that, in contrast to classical players, jazz and folk
and modern popular musicians and singers do not follow a simple, narrow
trajectory of technical training, and they “start much later.”
Jack Cecchini can thank two stumbles, one metaphorical and one literal, for
making him one of the rare musicians who is world class in both jazz and
classical.
The first was in 1950 in Chicago, when he was thirteen and stumbled
across a guitar resting on his landlord’s couch. He ran his fingers over the
strings as he walked by. The landlord picked it up, demonstrated two
chords, and immediately asked Cecchini to play accompaniment with them.
Of course, he couldn’t. “He’d shake his head when it was time for me to
change the chord, and if I didn’t he’d start swearing,” Cecchini recalled
with a chuckle. Cecchini’s interest was ignited, and he started trying to
imitate songs he heard on the radio. By sixteen, he was playing jazz in the
background of Chicago clubs he was too young to patronize. “It was like a
factory,” he told me. “If you had to go to the bathroom, you had to get one
of the other guys to pick it up. But you’re experimenting every night.” He
took the only free music lessons he could find, in clarinet, and tried to
transfer what he learned to the guitar. “There are eight million places on the
guitar to play the same notes,” he said. “I was just trying to find solutions to
problems, and you start to learn the fingerboard.” Pretty soon he was
performing with Frank Sinatra at the Villa Venice, Miriam Makeba at the
Apollo, and touring with Harry Belafonte from Carnegie Hall to packed
baseball stadiums. That’s where the second stumble came in.
During a show when Cecchini was twenty-three, one of Belafonte’s stage
dancers stepped on the cable that connected his guitar to an amplifier. His
instrument was reduced to a whisper. “Harry freaked out,” Cecchini
recalled. “He said, ‘Get rid of that thing and get yourself a classical
guitar!’” Getting one was easy, but he had been using a pick, and for
acoustic he had to learn fingering, so the trouble was learning to play it on
tour.

He fell in love with the instrument, and by thirty-one was so adept that he
was chosen as the soloist to play a concerto by none other than Vivaldi
accompanied by an orchestra for a crowd in Chicago’s Grant Park. The next
day, the Chicago Tribune ’s music critic began his review: “Despite the
ever-increasing number of enthusiasts who untiringly promote the
resurrection of the guitar as a classical instrument, there are but few men
who possess the talent and patience to master what remains one of the most
beautiful but obstinately difficult of all instruments.” Cecchini, he
continued, “proved to be one of those few.”
Despite his late and haphazard start, Cecchini also became a renowned
teacher of both jazz and classical guitar. Students traveled from out of state
to pick his brain, and by the early 1980s lines formed down the stairs of his
Chicago school in the evenings. His own formal training, of course, had
been those free clarinet lessons. “I’d say I’m 98 percent self-taught,” he told
me. He switched between instruments and found his way through trial and
error. It might sound unusual, but when Cecchini reeled off legends he
played with or admired, there was not a Tiger among them.
Duke Ellington was one of the few who ever actually took formal
lessons, when he was seven, from the exuberantly named teacher Marietta
Clinkscales. He lost interest immediately, before he learned to read notes,
and quit music entirely to focus on baseball. In school, his interests were
drawing and painting. (He later turned down a college art scholarship.)
When he was fourteen, Ellington heard ragtime, and for the first time in
seven years sat down at a piano and tried to copy what he had heard. “There
was no connection between me and music, until I started fiddling with it
myself,” he remembered. “As far as anyone teaching me, there was too
many rules and regulations. . . . As long as I could sit down and figure it out
for myself, then that was all right.” Even once he became arguably
America’s preeminent composer, he relied on copyists to decode his
personal musical shorthand into traditional musical notation.
Johnny Smith was Cecchini’s absolute favorite. Smith grew up in a
shotgun house in Alabama. Neighbors gathered to play music, and young
Johnny goofed around with whatever they left in a corner overnight. “John
played anything,” his brother Ben recalled. It allowed him to enter local
competitions for any instrument, and the prizes were groceries. He once
fiddled his way to a five-pound bag of sugar. He didn’t particularly like

violin, though. Smith said he would have walked fifty miles for a guitar
lesson, but there were no teachers around, so he just had to experiment.
When the United States entered World War II, Smith enlisted in the Army
hoping to be a pilot, but a left-eye problem disqualified him. He was sent to
the marching band, which had absolutely no use for a guitar player. He
could not yet read music, but was assigned to teach himself a variety of
instruments so he could play at recruiting events. Wide-ranging experience
set him up for his postwar work as NBC’s musical arranger. He had learned
to learn, and his multi-instrument and polygenre skill became so renowned
that it got him into a tricky spot.
He was leaving NBC one Friday evening when he was stopped at the
elevator and asked to learn a new guitar part. The classical player hired for
the job couldn’t hack it. It was for a live celebration of composer Arnold
Schoenberg’s seventy-fifth birthday, and would feature one of Schoenberg’s
atonal compositions, which had not been performed in twenty-five years.
Smith had four days. He continued with his Friday night, got home at 5
a.m., and then joined an emergency rehearsal at 7 a.m.======================================================== in cartoons when a robot’s belly opens
up and a boxing glove fires out. He stuck a gripping tool on the outer end
that closed when he squeezed handles to extend the arm. Now he could
lazily retrieve distant objects .
The company president saw the new hire goofing around with his
contraption and called him into his office. “I thought I would be scolded,”
Yokoi recalled. Instead, the desperate executive told Yokoi to turn his
device into a game. Yokoi added a group of colored balls that could be
grabbed, and the “Ultra Hand” went to market immediately. It was
Nintendo’s first toy, and it sold 1.2 million units. The company paid off a
chunk of its debt. That was the end of Yokoi’s maintenance career. The
president assigned him to start Nintendo’s first research and development
department. The facility that briefly made instant rice was converted into a
toy factory.
More toy success followed, but it was an abject failure that first year that
profoundly influenced Yokoi. He helped create Drive Game, a tabletop unit
where a player used a steering wheel to guide a plastic car along a
racetrack, which scrolled beneath the car via electric motor. It was the first
Nintendo toy that required electricity, and a complete flop. The internal
mechanism was advanced for the time and ended up so complex and fragile
that it was expensive and hard to produce, and units were riddled with

defects. But the debacle was the seed of a creative philosophy Yokoi would
hone for the next thirty years.
Yokoi was well aware of his engineering limitations. As one aficionado
of game history put it, “He studied electronics at a time where the
technology was evolving faster than the snow melts in sunlight.” Yokoi had
no desire (or capability) to compete with electronics companies that were
racing one another to invent some entirely new sliver of dazzling
technology. Nor could Nintendo compete with Japan’s titans of traditional
toys—Bandai, Epoch, and Takara—on their familiar turf. With that, and
Drive Game, in mind, Yokoi embarked on an approach he called “lateral
thinking with withered technology.” Lateral thinking is a term coined in the
1960s for the reimagining of information in new contexts, including the
drawing together of seemingly disparate concepts or domains that can give
old ideas new uses. By “withered technology,” Yokoi meant tech that was
old enough to be extremely well understood and easily available, so it
didn’t require a specialist’s knowledge. The heart of his philosophy was
putting cheap, simple technology to use in ways no one else considered. If
he could not think more deeply about new technologies, he decided, he
would think more broadly about old ones. He intentionally retreated from
the cutting edge, and set to monozukuri .
He connected a transistor to a cheap, store-bought galvanometer, and
noticed he could measure the current flowing through his coworkers. Yokoi
imagined a toy that would make it fun for boys and girls to hold hands,
risqué at the time in Japan. 
*
 The Love Tester was nothing more than two
conductive handles and a gauge. Players grasped a handle and joined hands,
thereby completing the circuit. The gauge reported electrical current as if it
were a measure of the love between participants. The sweatier their palms,
the better a couple’s conductance. It was a hit among teenagers, and a party
prop for adults. Yokoi was encouraged. He committed to using technology
that had already become cheap, even obsolete, in new ways.
By the early 1970s, radio-controlled toy cars were popular, but good RC
technology could cost a month’s salary, so it was a hobby reserved for
adults. As he often did, Yokoi pondered a way to democratize RC toys. So
he took the tech backward. Expense came from the need for multiple radio
control channels. Cars started with two channels, one to control the engine
output and one the steering wheel. The more functions a toy had, the more
channels it required. Yokoi stripped the technology down to the absolute

bare minimum, a single-channel RC car that could only turn left. Product
name: Lefty RX. It was less than a tenth the cost of typical RC toys, and
just fine for counterclockwise races. Even when it did have to navigate
obstacles, kids easily learned how to left-turn their way out of trouble.
One day in 1977, while riding the bullet train back from a business trip in
Tokyo, Yokoi awoke from a nap to see a salaryman playing with a
calculator to relieve the boredom of his commute. The trend at the time was
to make toys as impressively big as possible. What if, Yokoi wondered,
there was a game small enough that an adult could play it discreetly while
commuting? He sat on the idea for a while, until one day when he was
drafted to be the company president’s chauffeur. The normal driver had the
flu, and thanks to Yokoi’s interest in foreign vehicles, he was the only one
of Nintendo’s hundred employees who had driven a car with the steering
wheel on the left, like the president’s Cadillac. He floated his miniature
game idea from the front seat. “He was nodding along,” Yokoi recalled,
“but he didn’t seem all that interested.”
A week later, Yokoi received a surprise visit from executives at Sharp, a
calculator manufacturer. At the meeting Yokoi had driven him to, the
Nintendo president sat next to the head of Sharp, and relayed his
chauffeur’s idea. For several years, Sharp had been engaged in calculator
wars with Casio. In the early 1970s a calculator cost a few hundred dollars,
but as components got cheaper and companies raced for market share, cost
plummeted and the market saturated. Sharp was eager to find a new use for
its LCD screens.
When Sharp executives heard Yokoi’s idea for a video game the size of a
business card holder, and that could be held in the lap and played with
thumbs, they were intrigued, and skeptical. Was it worth mobilizing a new
partnership just to reuse technology that had become dirt cheap? They
weren’t convinced it was even possible to make a display smooth enough
for the game Yokoi proposed, which involved a juggler whose arms move
left and right, trying not to drop balls as they speed up. Nonetheless, the
Sharp engineers made Yokoi an LCD screen in the appropriate size. Then he
hit a severe problem. The electronics in the tiny game were packed in such
a thin space that the liquid crystal display element touched a plate in the
screen, which created a visual distortion of light and dark bands, known as
Newton’s rings. Yokoi needed a sliver of space between the LCD and the
plate. He took an idea from the credit card industry. With a slight tweak of

the old hanafuda printing machines, he delicately embossed the screen with
hundreds of dots to keep the plate and the display element narrowly
separated. As a final flourish, with just a few hours of work, a colleague
helped him program a clock into the display. LCD screens were already in
wristwatches, and they figured it would give adults an excuse to buy their
“Game & Watch.”
In 1980, Nintendo released its first three Game & Watch models, with
high hopes for one hundred thousand sales. Six hundred thousand copies
sold in the first year. Nintendo could not keep up with international
demand. The Donkey Kong Game & Watch was released in 1982 and alone
sold eight million units. Game & Watch remained in production for eleven
years and sold 43.4 million units. It also happened to include another Yokoi
invention that would be used laterally: the directional pad, or “D-pad,”
which allowed a player to move their character in any direction using just a
thumb. After the success of the Game & Watch, Nintendo put the D-pad in
controllers on its new Nintendo Entertainment System. That home console
brought arcade games into millions of homes around the world, and
launched a new era of gaming. The combination of successes—the Game &
Watch and the NES—also led to Yokoi’s lateral-thinking magnum opus, a
handheld console that played any game a developer could put on a
cartridge: the Game Boy.
From a technological standpoint, even in 1989, the Game Boy was
laughable. Yokoi’s team cut every corner. The Game Boy’s processor had
been cutting edge—in the 1970s. By the mid-1980s, home consoles were in
fierce competition over graphics quality. The Game Boy was an eyesore. It
featured a total of four grayscale shades, displayed on a tiny screen that was
tinted a greenish hue somewhere between mucus and old alfalfa. Graphics
in fast lateral motion smeared across the screen. To top it off, the Game Boy
had to compete with handheld consoles from Sega and Atari that were
technologically superior in every way. And it destroyed them .
What its withered technology lacked, the Game Boy made up in user
experience. It was cheap. It could fit in a large pocket. It was all but
indestructible. If a drop cracked the screen—and it had to be a horrific drop
—it kept on ticking. If it were left in a backpack that went in the washing
machine, once it dried out it was ready to roll a few days later. Unlike its
power-guzzling color competitors, it played for days (or weeks) on AA
batteries. Old hardware was extremely familiar to developers inside and

outside Nintendo, and with their creativity and speed unencumbered by
learning new technology, they pumped out games as if they were early
ancestors of iPhone app designers— Tetris, Super Mario Land , The Final
Fantasy Legend, and a slew of sports games released in the first year were
all smash hits. With simple technology, Yokoi’s team sidestepped the
hardware arms race and drew the game programming community onto its
team.
The Game Boy became the Sony Walkman of video gaming, forgoing
top-of-the-line tech for portability and affordability. It sold 118.7 million
units, far and away the bestselling console of the twentieth century. Not bad
for the little company that was allowed to sell hanafuda .
Even though he was revered by then, Yokoi had to push and shove
internally for his “lateral thinking with withered======================================================== and diapers that stay
on wiggly babies. She never studied materials science at all, and claimed
she is “not that great a scientist.” “What I mean,” she said, “is I’m not
qualified fundamentally to do what I do.” She described her approach to
innovation almost like investigative journalism, except her version of shoe-
leather reporting is going door-to-door among her peers. She is a “T-shaped
person,” she said, one who has breadth, compared to an “I-shaped person,”
who only goes deep, an analog to Dyson’s birds and frogs. “T-people like
myself can happily go to the I-people with questions to create the trunk for
the T,” she told me. “My inclination is to attack a problem by building a
narrative. I figure out the fundamental questions to ask, and if you ask those
questions of the people who actually do know their stuff, you are still
exactly where you would be if you had all this other knowledge inherently.
It’s mosaic building. I just keep putting those tiles together. Imagine me in a
network where I didn’t have the ability to access all these people. That
really wouldn’t work well.”
In his first eight years at 3M, Ouderkirk worked with more than a
hundred different teams. Nobody handed him important projects, like
multilayer optical film, with potential impact spanning an enormous array
of technologies; his breadth helped him identify them. “If you’re working
on well-defined and well-understood problems, specialists work very, very
well,” he told me. “As ambiguity and uncertainty increases, which is the
norm with systems problems, breadth becomes increasingly important.”

Research by Spanish business professors Eduardo Melero and Neus
Palomeras backed up Ouderkirk’s idea. They analyzed fifteen years of tech
patents from 32,000 teams at 880 different organizations, tracking each
individual inventor as he or she moved among teams, and then tracking the
impact of each invention. Melero and Palomeras measured uncertainty in
each technological domain: a high-uncertainty area had a lot of patents that
proved totally useless, and some blockbusters; low-uncertainty domains
were characterized by linear progression with more obvious next steps and
more patents that were moderately useful. In low-uncertainty domains,
teams of specialists were more likely to author useful patents. In high-
uncertainty domains—where the fruitful questions themselves were less
obvious—teams that included individuals who had worked on a wide
variety of technologies were more likely to make a splash. The higher the
domain uncertainty, the more important it was to have a high-breadth team
member. As with the molecular biology groups Kevin Dunbar studied that
used analogical thinking to solve problems, when the going got uncertain,
breadth made the difference.
Like Melero and Palomeras, Dartmouth business professor Alva Taylor and
Norwegian School of Management professor Henrich Greve wanted to
examine the creative impact of individual breadth, just in a slightly less
technical domain: comic books.
The comic book industry afforded a well-defined era of creative
explosion. From the mid-1950s to 1970, comic creators agreed to self-
censor after psychiatrist Fredric Wertham convinced Congress that comics
were causing children to become deviants. (Wertham manipulated or
fabricated aspects of his research.) In 1971, Marvel Comics broke ranks.
The U.S. Department of Health, Education, and Welfare asked Marvel
editor in chief Stan Lee to create a story that educated readers about drug
abuse. Lee wrote a Spider-Man narrative in which Peter Parker’s best friend
overdosed on pills. The Comics Code Authority, the industry’s self-
censorship body, did not approve. Marvel published anyway. It was
received so well that censorship standards were immediately relaxed, and
the creative floodgates swung open. Comic creators developed superheroes
with complex emotional problems; Maus became the first graphic novel to

win a Pulitzer Prize; the avant-garde Love and Rockets created an ethnically
diverse cast that aged with readers in real time.
Taylor and Greve tracked individual creators’ careers and analyzed the
commercial value of thousands of comic books from 234 publishers since
that time. Each comic required the integration, by one or multiple creators,
of narrative, dialogue, art, and layout design. The research duo made
predictions about what would improve the average value of comics
produced by an individual or team creator, and what would increase the
value variance—that is, the chance that a creator would make a comic book
that either failed spectacularly compared to their typical work, or that
succeeded tremendously beyond their norm.
Taylor and Greve expected a typical industrial production learning curve:
creators learn by repetition, so creators making more comics in a given span
of time would make better ones on average. They were wrong. Also, as had
been shown in industrial production, they guessed that the more resources a
publisher had, the better its creators’ average product would be. Wrong. And
they made the very intuitive prediction that as creators’ years of experience
in the industry increased, they would make better comics on average.
Wrong again.
A high-repetition workload negatively impacted performance. Years of
experience had no impact at all. If not experience, repetition, or resources,
what helped creators make better comics on average and innovate?
The answer (in addition to not being overworked) was how many of
twenty-two different genres a creator had worked in, from comedy and
crime, to fantasy, adult, nonfiction, and sci-fi. Where length of experience
did not differentiate creators, breadth of experience did. Broad genre
experience made creators better on average and more likely to innovate.
Individual creators started out with lower innovativeness than teams—
they were less likely to produce a smash hit—but as their experience
broadened they actually surpassed teams: an individual creator who had
worked in four or more genres was more innovative than a team whose
members had collective experience across the same number of genres.
Taylor and Greve suggested that “individuals are capable of more creative
integration of diverse experiences than teams are.”
They titled their study Superman or the Fantastic Four? “When seeking
innovation in knowledge-based industries,” they wrote, “it is best to find
one ‘super’ individual. If no individual with the necessary combination of

diverse knowledge is available, one should form a ‘fantastic’ team.” Diverse
experience was impactful when created by platoon in teams, and even more
impactful when contained within an individual. That finding immediately
reminded me of my own favorite comics creators. Japanese comics and
animated-film creator Hayao Miyazaki may be best known for the
dreamlike epic Spirited Away , which surpassed Titanic as the highest-
grossing film ever in Japan, but his comics and animation career before that
left almost no genre untouched. He ranged from pure fantasy and fairy tales
to historical fiction, sci-fi, slapstick comedy, illustrated historical essays,
action-adventure, and much more. Novelist, screenwriter, and comics
author Neil Gaiman has a similarly expansive range, from journalism and
essays on art to a fiction oeuvre encompassing both stories that can be read
to (or by) the youngest readers as well as psychologically complex
examinations of identity that have enthralled mainstream adult audiences.
Jordan Peele is not a comics creator, but the writer and first-time director of
the extraordinarily unique surprise hit Get Out struck a similar note when
he credited comedy writing for his skill at timing information reveals in a
horror film. “In product development,” Taylor and Greve concluded,
“specialization can be costly.”
In kind environments, where the goal is to re-create prior performance
with as little deviation as possible, teams of specialists work superbly.
Surgical teams work faster and make fewer mistakes as they repeat specific
procedures, and specialized surgeons get better outcomes even independent
of repetitions. If you need to have surgery, you want a doctor who
specializes in the procedure and has done it many times, preferably with the
same team, just as you would want Tiger Woods to step in if your life was
on the line for a ten-foot putt. They’ve been there, many times, and now
have to re-create a well-understood process that they have executed
successfully before. The same goes for airline crews. Teams that have
experience working together become exceedingly efficient at delegating all
of the well-understood tasks required to ensure a smooth flight. When the
National Transportation Safety Board analyzed its database of major flight
accidents, it found that 73 percent occurred on a flight crew’s first day
working together. Like surgeries and putts, the best flight is one in which
everything goes according to routines long understood and optimized by
everyone involved, with no surprises.

When the path is unclear—a game of Martian tennis—those same
routines no longer suffice. “Some tools work fantastically in certain
situations, advancing technology in smaller but important ways, and those
tools are well known and well practiced,” Andy Ouderkirk told me. “Those
same tools will also pull you away from a breakthrough innovation. In fact,
they’ll turn a breakthrough innovation into an incremental one.”
University of Utah professor Abbie Griffin has made it her work to study
modern Thomas Edisons—“serial innovators,” she and two colleagues
termed them. Their findings about who these people are should sound
familiar by now: “high tolerance for ambiguity”; “systems thinkers”;
“additional technical knowledge from peripheral domains”; “repurposing
what is already available”; “adept at using analogous domains for finding
inputs to the invention process”; “ability to connect disparate pieces of
information in new ways”; “synthesizing information from======================================================== retention
bonuses—just cash payments to junior officers if they agreed to serve a few
more years. It cost taxpayers $500 million, and was a massive waste.
Officers who had planned to stay anyway took it, and those who already
planned to leave did not. The Army learned a hard lesson: the problem was
not a financial one; it was a matching one.
In the industrial era, or the “company man” era, as the monograph
authors called it, “firms were highly specialized,” with employees generally
tackling the same suite of challenges repeatedly. Both the culture of the
time—pensions were pervasive and job switching might be viewed as
disloyal—and specialization were barriers to worker mobility outside of the

company. Plus, there was little incentive for companies to recruit from
outside when employees regularly faced kind learning environments, the
type where repetitive experience alone leads to improvement. By the 1980s,
corporate culture was changing. The knowledge economy created
“overwhelming demand for . . . employees with talents for
conceptualization and knowledge creation.” Broad conceptual skills now
helped in an array of jobs, and suddenly control over career trajectory
shifted from the employer, who looked inward at a ladder of opportunity, to
the employee, who peered out at a vast web of possibility. In the private
sector, an efficient talent market rapidly emerged as workers shuffled
around in pursuit of match quality. While the world changed, the Army
stuck with the industrial-era ladder.
The West Point professors explained that the Army, like many
bureaucratic organizations, missed out on match quality markets. “There is
no talent matching market mechanism,” they wrote. When a junior officer
changed direction and left the Army, it did not signal a loss of drive. It
signaled that a strong drive for personal development had changed the
officer’s goals entirely. “I’ve yet to meet a classmate who left the Army and
regretted it,” said Ashley Nicolas, the former intelligence officer. She went
on to become a math teacher and then a lawyer. She added that all were
grateful for the experience, even though it didn’t become a lifelong career.
While the private sector adjusted to the burgeoning need for high match
quality, the Army just threw money at people. It has, though, begun to
subtly change. That most hierarchical of entities has found success
embracing match flexibility. The Officer Career Satisfaction Program was
designed so that scholarship-ROTC and West Point graduates can take more
control of their own career progression. In return for three additional years
of active service, the program increased the number of officers who can
choose a branch (infantry, intelligence, engineering, dental, finance,
veterinary, communication technology, and many more), or a geographic
post. Where dangling money for junior officers failed miserably, facilitating
match quality succeeded. In the first four years of the program, four
thousand cadets agreed to extend their service commitments in exchange
for choice. 
*
It is just a small step. When Defense Secretary Ash Carter visited West
Point in 2016 for student meetings, he was flooded with concerns from very
gritty cadets about rigid career paths that did not allow them to adjust to

their own development. Carter had pledged to drastically reshape the
Army’s “industrial era” personnel management from the strict “up-or-out”
model to one that allows officers a shot to improve their own match quality
as they grow.
When they were high school graduates, with few skills and little
exposure to a world of career options, West Point cadets might easily have
answered “Not like me at all” to the Grit Scale statement “I often set a goal
but later choose to pursue a different one.” A few years later, with more
knowledge of their skills and preferences, choosing to pursue a different
goal was no longer the gritless route; it was the smart one .
Intuitively, grit research appeals to me. In the nonscientific, colloquial use
of the word, I tend to think I have a lot of it. After running track and playing
football, basketball, and baseball at a large public high school—and I’m
only five foot six—I walked on to a Division I track team in college as an
800-meter runner.
I was not close to the worst 800 runner on my college team freshman
year; I was the worst, by a landslide. I was allowed to keep practicing with
the team because as long as you are not chosen for travel, it doesn’t cost
anybody anything, not even the pair of shoes the recruits got. When the
traveling team went to South Carolina to train over spring break, I stayed on
the eerily quiet campus rather than going home, to train without distraction.
I stuck with it for two miserable years of vomit-inducing workouts and ego-
bruising races, while blue-chip recruits quit and were replaced by others.
There were plenty of days (and weeks, and an entire month or three) when I
felt like I should probably quit. But I was learning about the kind of training
that worked for me, and I was improving. In my senior season, I cracked the
university’s all-time top ten list indoors, was twice All-East, and part of a
relay that set the university record. The only other guy in my class who held
a university record was my gritty roommate, the other walk-on. Nearly the
entire recruited class from our year quit. Hilariously, I was awarded the
Gustave A. Jaeger Memorial Prize for the athlete who “achieved significant
athletic success in the face of unusual challenge and difficulty”—my
“unusual challenge and difficulty” just being that I epically stunk at first.
After the presentation, the head coach, with whom I’d had little direct

conversation as a walk-on, shared that he had felt sorry for me watching
workouts my freshman year.
There’s nothing particularly special about that story—it exists on every
team. But I think it is indicative of my approach to work. Nonetheless, I
scored at the 50th percentile on the Grit Scale compared to American adults
at large. I racked up points for assessing myself as a very hard worker who
is not discouraged by setbacks, but I missed a lot of points for confessing
that “my interests change from year to year,” and, like so many West Point
graduates, I sometimes “set a goal but later choose to pursue a different
one.” When I was seventeen and positive that I was going to go to the U.S.
Air Force Academy to become a pilot and then an astronaut, I probably
would have self-assessed at the very top of the Grit Scale. I got all the way
to Chicago-area congressman Sidney Yates agreeing to provide a
nomination.
But I never did any of that. Instead, at the last minute I changed my mind
and went elsewhere to study political science. I took a single poli-sci class,
and ended up majoring in Earth and environmental sciences and minoring
in astronomy, certain I would become a scientist. I worked in labs during
and after college and realized that I was not the type of person who wanted
to spend my entire life learning one or two things new to the world, but
rather the type who wanted constantly to learn things new to me and share
them. I transitioned from science to journalism; my first job was as a
midnight-shift street reporter in New York City. (Nothing happy that’s
going in the New York Daily News happens between midnight and 10 a.m.)
Growing self-knowledge kept changing my goals and interests until I
landed in a career the very lifeblood of which is investigating broad
interests. When I later worked at Sports Illustrated , determined students
would ask me whether it was better to study journalism or English to work
at SI . I told them I had no clue, but that a statistics or biology course never
hurt anyone.
I don’t think I have become less passionate or resilient over time, nor do I
think that all those former West Point cadets who left the Army lost the
drive that got them there in the first place. It makes sense to me that grit
would be powerfully predictive for cadets trying to get through their
rigorous orientation, or for a sample of schoolchildren or spelling bee
contestants. Very young people often have their goals set for them, or at
least have a limited menu to choose from, and pursuing them with passion

and resilience is the main challenge. The same goes for 800 runners. One of
the compelling aspects of sports goals is how straightforward and easily
measurable they are. On the final weekend of the 2018 Winter Olympics,
Sasha Cohen, a 2006 silver medalist figure skater, wrote an advice column
to retiring athletes. “Olympic athletes need to understand that the rules for
life are different from the rules for sports,” she wrote. “Yes, striving to
accomplish a single overarching goal every day means you have grit,
determination and resilience. But the ability to pull yourself together
mentally and physically in competition is different from the new challenges
that await you. So after you retire, travel, write a poem, try to start your
own business, stay out a little too late, devote time to something that
doesn’t have a clear end goal.” In the wider world of work, finding a goal
with high match quality in the first place is the greater challenge, and
persistence for the sake of persistence can get in the way.
A recent international Gallup survey of more than two hundred thousand
workers in 150 countries reported that 85 percent were either “not engaged”
with their work or “actively disengaged.” In that condition, according to
Seth Godin, quitting takes a lot more guts than continuing to be carried
along like debris on an ocean wave. The trouble, Godin noted, is that
humans are bedeviled by the “sunk cost fallacy.” Having invested time or
money in something, we are loath to leave it, because that would mean we
had wasted our time or money, even though it is already gone. Writer,
psychology PhD, and professional poker player Maria Konnikova explained
in her book The Confidence Game how the sunk cost mindset is so======================================================== technology” concept to be
approved for the Game Boy. “It was difficult to get Nintendo to
understand,” he said later. Yokoi was convinced, though, that if users were
drawn into the games, technological power would be an afterthought. “If
you draw two circles on a blackboard, and say, ‘That’s a snowman,’
everyone who sees it will sense the white color of the snow,” he argued.
When the Game Boy was released, Yokoi’s colleague came to him “with
a grim expression on his face,” Yokoi recalled, and reported that a
competitor handheld had hit the market. Yokoi asked him if it had a color
screen. The man said that it did. “Then we’re fine,” Yokoi replied.
Yokoi’s strategy of finding novel uses for technology, after others had
moved on, smacks of exactly what a well-known psychological creativity
exercise asks for. In the Unusual (or Alternative) Uses Task, test takers have
to come up with original uses for an object. Given the prompt “brick,” a test
taker will generate familiar uses first (part of a wall, a doorstop, a weapon).
To score higher, they have to generate uses that are conceptually distant and
rarely given by other test takers, but still feasible. For the brick: a
paperweight; a nutcracker; a theatrical coffin at a doll’s funeral; a water
displacement device dropped in a toilet tank to use less per flush. (In 2015,
Ad Age awarded “Pro Bono Campaign of the Year” to the cheeky lateral
thinkers of the “Drop-A-Brick” project, which manufactured rubber bricks
for use in California toilets during a drought.)

There is, to be sure, no comprehensive theory of creativity. But there is a
well-documented tendency people have to consider only familiar uses for
objects, an instinct known as functional fixedness. The most famous
example is the “candle problem,” in which participants are given a candle, a
box of tacks, and a book of matches and told to attach the candle to the wall
such that wax doesn’t drip on the table below. Solvers try to melt the candle
to the wall or tack it up somehow, neither of which work. When the
problem is presented with the tacks outside of their box, solvers are more
likely to view the empty box as a potential candle holder, and to solve the
problem by tacking it to the wall and placing the candle inside. For Yokoi,
the tacks were always outside the box.
Unquestionably, Yokoi needed narrow specialists. The first true electrical
engineer Nintendo hired was Satoru Okada, who said bluntly, “Electronics
was not Yokoi’s strong point.” Okada was Yokoi’s codesigner on the Game
& Watch and Game Boy. “I handled more of the internal systems of the
machine,” he recalled, “with Yokoi handling more of the design and
interface aspects.” Okada was the Steve Wozniak to Yokoi’s Steve Jobs.
Yokoi was the first to admit it. “I don’t have any particular specialist
skills,” he once said. “I have a sort of vague knowledge of everything.” He
advised young employees not just to play with technology for its own sake,
but to play with ideas. Do not be an engineer, he said, be a producer. “The
producer knows that there’s such a thing as a semiconductor, but doesn’t
need to know its inner workings. . . . That can be left to the experts.” He
argued, “Everyone takes the approach of learning detailed, complex skills.
If no one did this then there wouldn’t be people who shine as engineers. . . .
Looking at me, from the engineer’s perspective, it’s like, ‘Look at this
idiot,’ but once you’ve got a couple hit products under your belt, this word
‘idiot’ seems to slip away somewhere.”
He spread his philosophy as his team grew, and asked everyone to
consider alternate uses for old technology. He realized that he had been
fortunate to come to a playing card company rather than an established
electronic toymaker with entrenched solutions, so his ideas were not
thwarted because of his technical limitations. As the company grew, he
worried that young engineers would be too concerned about looking stupid
to share ideas for novel uses of old technology, so he began intentionally
blurting out crazy ideas at meetings to set the tone. “Once a young person

starts saying things like, ‘Well, it’s not really my place to say . . .’ then it’s
all over,” he said.
Tragically, Yokoi died in a traffic accident in 1997. But his philosophy
survived. In 2006, Nintendo’s president said that the Nintendo Wii was a
direct outgrowth of Yokoi’s doctrine. “If I can speak without fear of being
misunderstood,” the president explained, “I would like to say that Nintendo
is not producing next-generation game consoles.” The Wii used extremely
simple games and technology from a previous console, but motion-based
controls were a literal game changer. Given its basic hardware, the Wii was
criticized as not innovative. Harvard Business School professor Clayton
Christensen argued that it was actually the most important kind of
innovation, an “empowering innovation”—one that creates both new
customers and new jobs, like the rise of personal computers before it—
because it brought video games to an entirely new (often older) audience.
Nintendo “simply innovated in a different way,” Christensen and a
colleague wrote. “It understood that the barrier to new consumers using
video game systems was the complexity of game play, not the quality of
existing graphics.” Queen Elizabeth II of England made headlines when she
saw her grandson Prince William playing Wii Bowling and decided to get in
on the action herself.
Yokoi’s greatest failure came when he departed from his own design
tenets. One of his last Nintendo projects was the Virtual Boy, a gaming
headset that employed experimental technology. It relied on a processor that
produced high radio emissions, and before cell phones, no one knew if that
was safe so close to a user’s head. A metal plate had to be constructed
around the processor, which in turn made the unit too heavy to work as
goggles. It was transformed into a device that sat on a table and required the
user to assume an unnatural posture to see the screen. It was ahead of its
time, but nobody bought it.
Yokoi’s greatest triumphs occurred when he thought laterally. He needed
specialists, but his concern was that as companies grew and technology
progressed, vertical-thinking hyperspecialists would continue to be valued
but lateral-thinking generalists would not. “The shortcut [for a lack of
ideas] is competition in the realm of computing power,” Yokoi explained.
“When it comes to that . . . the screen manufacturers and expert graphics
designers come out on top. Then Nintendo’s reason for existence

disappears.” He felt that the lateral and vertical thinkers were best together,
even in highly technical fields.
Eminent physicist and mathematician Freeman Dyson styled it this way:
we need both focused frogs and visionary birds. “Birds fly high in the air
and survey broad vistas of mathematics out to the far horizon,” Dyson
wrote in 2009. “They delight in concepts that unify our thinking and bring
together diverse problems from different parts of the landscape. Frogs live
in the mud below and see only the flowers that grow nearby. They delight in
the details of particular objects, and they solve problems one at a time.” As
a mathematician, Dyson labeled himself a frog, but contended, “It is stupid
to claim that birds are better than frogs because they see farther, or that
frogs are better than birds because they see deeper.” The world, he wrote, is
both broad and deep. “We need birds and frogs working together to explore
it.” Dyson’s concern was that science is increasingly overflowing with
frogs, trained only in a narrow specialty and unable to change as science
itself does. “This is a hazardous situation,” he warned, “for the young
people and also for the future of science.”
Fortunately, it is possible, even today, even at the cutting edge, even in
the most hyperspecialized specialties, to cultivate land where both birds and
frogs can thrive.
Andy Ouderkirk laughed as he recalled the story. “It was with three
gentlemen who owned the company, and I’ll just forever remember them
holding up a vial and just looking at me and saying, ‘This is a breakthrough
in glitter.’”
Standard glitter sparkles; this glitter blazed, as if the vial held a colony of
magical prismatic fireflies. Ouderkirk envisioned a lot of applications for
multilayer optical film, but glitter was a pleasant surprise. “Here I am, a
physical chemist,” he told me. “I usually think of breakthroughs as being
very sophisticated advanced technologies.”
Ouderkirk was an inventor at Minnesota-based 3M, one of twenty-eight
“corporate scientists,” the highest title among the company’s sixty-five
hundred scientists and engineers. The road to breakthrough glitter began
when he endeavored to challenge the conception of a two-hundred-year-old
principle of physics known as Brewster’s law, which had been interpreted to
mean that no surface could reflect light near perfectly at every angle.

Ouderkirk wondered if layering many thin plastic surfaces on top of one
another, each with distinct optical qualities, could create a film that custom-
reflected and -refracted various wavelengths of light in all directions. A
group of optics specialists he consulted assured him it could not be done,
which was exactly what he wanted to hear. “If they say, ‘It’s a great idea, go
for it, makes sense,’ what is the chance you’re the first person to come up
with it? Precisely zero,” he told me.
In fact, he was certain it was physically possible. Mother Nature offered
proof of concept. The iridescent blue morpho butterfly has no blue pigment
whatsoever; its wings glow azure and sapphire from thin layers of scales
that refract and reflect particular wavelengths of blue light. There were
more pedestrian examples too. The plastic of a water bottle refracts light
differently depending on the light’s angle. “Everybody knows this, that
knows anything about polymers,” Ouderkirk said. “It’s in front of you
literally every day. But nobody ever======================================================== have won the Nobel Prize are more likely still.
Compared to other scientists, Nobel laureates are at least twenty-two times
more likely to partake as an amateur actor, dancer, magician, or other type
of performer. Nationally recognized scientists are much more likely than
other scientists to be musicians, sculptors, painters, printmakers,
woodworkers, mechanics, electronics tinkerers, glassblowers, poets, or
writers, of both fiction and nonfiction. And, again, Nobel laureates are far
more likely still. The most successful experts also belong to the wider
world. “To him who observes them from afar,” said Spanish Nobel laureate
Santiago Ramón y Cajal, the father of modern neuroscience, “it appears as
though they are scattering and dissipating their energies, while in reality
they are channeling and strengthening them.” The main conclusion of work
that took years of studying scientists and engineers, all of whom were
regarded by peers as true technical experts, was that those who did not
make a creative contribution to their field lacked aesthetic interests outside
their narrow area. As psychologist and prominent creativity researcher Dean
Keith Simonton observed, “rather than obsessively focus[ing] on a narrow
topic,” creative achievers tend to have broad interests. “This breadth often
supports insights that cannot be attributed to domain-specific expertise
alone.”
Those findings are reminiscent of a speech Steve Jobs gave, in which he
famously recounted the importance of a calligraphy class to his design
aesthetics. “When we were designing the first Macintosh computer, it all
came back to me,” he said. “If I had never dropped in on that single course
in college, the Mac would have never had multiple typefaces or
proportionally spaced fonts.” Or electrical engineer Claude Shannon, who

launched the Information Age thanks to a philosophy course he took to
fulfill a requirement at the University of Michigan. In it, he was exposed to
the work of self-taught nineteenth-century English logician George Boole,
who assigned a value of 1 to true statements and 0 to false statements and
showed that logic problems could be solved like math equations. It resulted
in absolutely nothing of practical importance until seventy years after Boole
passed away, when Shannon did a summer internship at AT& T’s Bell Labs
research facility. There he recognized that he could combine telephone call-
routing technology with Boole’s logic system to encode and transmit any
type of information electronically. It was the fundamental insight on which
computers rely. “It just happened that no one else was familiar with both
those fields at the same time,” Shannon said.
In 1979, Christopher Connolly cofounded a psychology consultancy in
the United Kingdom to help high achievers (initially athletes, but then
others) perform at their best. Over the years, Connolly became curious
about why some professionals floundered outside a narrow expertise, while
others were remarkably adept at expanding their careers—moving from
playing in a world-class orchestra, for example, to running one. Thirty years
after he started, Connolly returned to school to do a PhD investigating that
very question, under Fernand Gobet, the psychologist and chess
international master. Connolly’s primary finding was that early in their
careers, those who later made successful transitions had broader training
and kept multiple “career streams” open even as they pursued a primary
specialty. They “traveled on an eight-lane highway,” he wrote, rather than
down a single-lane one-way street. They had range. The successful adapters
were excellent at taking knowledge from one pursuit and applying it
creatively to another, and at avoiding cognitive entrenchment. They
employed what Hogarth called a “circuit breaker.” They drew on outside
experiences and analogies to interrupt their inclination toward a previous
solution that may no longer work. Their skill was in avoiding the same old
patterns. In the wicked world, with ill-defined challenges and few rigid
rules, range can be a life hack .
Pretending the world is like golf and chess is comforting. It makes for a
tidy kind-world message, and some very compelling books. The rest of this
one will begin where those end—in a place where the popular sport is
Martian tennis, with a view into how the modern world became so wicked
in the first place.

OceanofPDF.com

CHAPTER 2
How the Wicked World Was Made
THE TOWN OF DUNEDIN sits at the base of a hilly peninsula that juts off of
New Zealand’s South Island into the South Pacific. The peninsula is famous
for yellow-eyed penguins, and Dunedin boasts, demurely, the world’s
steepest residential street. It also features the University of Otago, the oldest
university in New Zealand, and home to James Flynn, a professor of political
studies who changed how psychologists think about thinking.
He started in 1981, intrigued by a thirty-year-old paper that reported IQ
test scores of American soldiers in World Wars I and II. The World War II
soldiers had performed better, by a lot. A World War I soldier who scored
smack in the middle of his peers—the 50th percentile—would have made
only the 22nd percentile compared to soldiers in World War II. Flynn
wondered if perhaps civilians had experienced a similar improvement. “I
thought, if IQ gains had occurred anywhere,” he told me, “maybe they had
occurred everywhere.” If he was right, psychologists had been missing
something big right before their eyes.
Flynn wrote to researchers in other countries asking for data, and on a dull
November Saturday in 1984, he found a letter in his university mailbox. It
was from a Dutch researcher, and it contained years of raw data from IQ
tests given to young men in the Netherlands. The data were from a test
known as Raven’s Progressive Matrices, designed to gauge the test taker’s
ability to make sense of complexity. Each question of the test shows a set of
abstract designs with one design missing. The test taker must try to fill in the
missing design to complete a pattern. Raven’s was conceived to be the
epitome of a “culturally reduced” test; performance should be unaffected by
material learned in life, inside or outside of school. Should Martians alight

on Earth, Raven’s should be the test capable of determining how bright they
are. And yet Flynn could immediately see that young Dutchmen had made
enormous gains from one generation to the next.
Flynn found more clues in test reference manuals. IQ tests are all
standardized so that the average score is always 100 points. (They are graded
based on a curve, with 100 in the middle.) Flynn noticed that the tests had to
be restandardized from time to time to keep the average at 100, because test
takers were giving more correct answers than they had in the past. In the
twelve months after he received the Dutch letter, Flynn collected data from
fourteen countries. Every single one showed huge gains for both children
and adults. “Our advantage over our ancestors,” as he put it, is “from the
cradle to the grave.”
Flynn had asked the right question. Score gains had occurred everywhere.
Other academics had stumbled upon pieces of the same data earlier, but none
had investigated whether it was part of a global pattern, even those who were
having to tweak the test scoring system to keep the average at 100. “As an
outsider,” Flynn told me, “things strike me as surprising that I think people
trained in psychometrics just accepted.”
The Flynn effect—the increase in correct IQ test answers with each new
generation in the twentieth century—has now been documented in more than
thirty countries. The gains are startling: three points every ten years. To put
that in perspective, if an adult who scored average today were compared to
adults a century ago, she would be in the 98th percentile.
When Flynn published his revelation in 1987, it hit the community of
researchers who study cognitive ability like a firebomb. The American
Psychological Association convened an entire meeting on the issue, and
psychologists invested in the immutable nature of IQ test scores offered an
array of explanations to usher the effect away, from more education and
better nutrition—which presumably contributed—to test-taking experience,
but none fit the unusual pattern of score improvements. On tests that gauged
material picked up in school or with independent reading or study—general
knowledge, arithmetic, vocabulary—scores hardly budged. Meanwhile,
performance on more abstract tasks that are never formally taught, like the
Raven’s matrices, or “similarities” tests, which require a description of how
two things are alike, skyrocketed.

A young person today asked to give similarities between “dusk” and
“dawn” might immediately realize that both connote times of day. But they
would be far more likely than their grandmothers to produce a higher-level
similarity: both separate day from night. A child today who scores average
on similarities would be in the 94th percentile of her grandparents’
generation. When a group of Estonian researchers used national test scores
to compare word understandings of schoolkids in the 1930s to those in 2006,
they saw that improvement came very specifically on the most abstract
words. The more abstract the word, the bigger the improvement. The kids
barely bested their grandparents on words for directly observable objects or
phenomena (“hen,” “eating,” “illness”), but they improved massively on
imperceptible concepts (“law,” “pledge,” “citizen”).
The gains around the world on Raven’s Progressive Matrices—where
change was least expected—were the biggest of all. “The huge Raven’s
gains show that today’s children are far better at solving problems on the
spot without a previously learned method for doing so,” Flynn concluded.
They are more able to extract rules and patterns where none are given. Even
in countries that have recently had a decrease in verbal and math IQ test
scores, Raven’s scores went======================================================== particular violinist: “She is the first of her sex to
challenge the success of our great artists.” Even listeners not obviously
disposed to support the arts were moved. Francesco Coli described “angelic
Sirens,” who exceeded “even the most ethereal of birds” and “threw open
for listeners the doors of Paradise.” Especially surprising praise, perhaps,
considering that Coli was the official book censor for the Venetian
Inquisition.
The best figlie became Europe-wide celebrities, like Anna Maria della
Pietà. A German baron flatly declared her “the premier violinist in Europe.”
The president of the parliament of Burgundy said she was “unsurpassed”
even in Paris. An expense report that Vivaldi recorded in 1712 shows that
he spent twenty ducats on a violin for sixteen-year-old Anna Maria, an
engagement-ring-like sum for Vivaldi, who made that much in four months.
Among the hundreds of concertos Vivaldi wrote for the figlie del coro are
twenty-eight that survived in the “Anna Maria notebook.” Bound in leather
and dyed Venetian scarlet, it bears Anna Maria’s name in gold leaf
calligraphy. The concertos, written specifically to showcase her prowess,
are filled with high-speed passages that require different notes to be played
on multiple strings at the same time. In 1716, Anna Maria and the figlie
were ordered by the Senate to intensify their musical work in an effort to
bring God’s favor to the Venetian armies as they battled the Ottoman

Empire on the island of Corfu. (In that siege, the Venetian violin, and a
well-timed storm, proved mightier than the Turkish cannon.)
Anna Maria was middle-aged in the 1740s, when Jean-Jacques Rousseau
came to visit. The rebel philosopher who would fuel the French Revolution
was also a composer. “I had brought with me from Paris the national
prejudice against Italian music,” Rousseau wrote. And yet he declared that
the music played by the figlie del coro “has not its like, either in Italy, or the
rest of the world.” Rousseau had one problem, though, that “drove me to
despair.” He could not see the women. They performed behind a thin crepe
hung in front of wrought-iron latticework grilles in elevated church
balconies. They could be heard, but only their silhouettes seen, tilting and
swaying with the tides of the music, like shadow pictures in a vaudeville
stage set. The grilles “concealed from me the angels of beauty,” Rousseau
wrote. “I could talk of nothing else.”
He talked about it so much that he happened to talk about it with one of
the figlie ’s important patrons. “If you are so desirous to see those little
girls,” the man told Rousseau, “it will be an easy matter to satisfy your
wishes.”
Rousseau was so desirous. He pestered the man incessantly until he took
him to meet the musicians. And there, Rousseau, whose fearless writing
would be banned and burned before it fertilized the soil of democracy, grew
anxious. “When we entered the salon which confined these longed-for
beauties,” he wrote, “I felt an amorous trembling, which I had never before
experienced.”
The patron introduced the women, the siren prodigies whose fame had
spread like a grassfire through Europe—and Rousseau was stunned.
There was Sophia—“horrid,” Rousseau wrote. Cattina—“she had but one
eye.” Bettina—“the smallpox had entirely disfigured her.” “Scarcely one of
them,” according to Rousseau, “was without some striking defect.”
A poem had recently been written about one of the best singers: “Missing
are the fingers of her left hand / Also absent is her left foot.” An
accomplished instrumentalist was the “poor limping lady.” Other guests left
even less considerate records.
Like Rousseau, English visitor Lady Anna Miller was entranced by the
music and pleaded to see the women perform with no barrier hiding them.

“My request was granted,” Miller wrote, “but when I entered I was seized
with so violent a fit of laughter, that I am surprised they had not driven me
out again. . . . My eyes were struck with the sight of a dozen or fourteen
beldams ugly and old . . . these with several young girls.” Miller changed
her mind about watching them play, “so much had the sight of the
performers disgusted me.”
The girls and women who delighted delicate ears had not lived delicate
lives. Many of their mothers worked in Venice’s vibrant sex industry and
contracted syphilis before they had babies and dropped them off at the
Ospedale della Pietà. The name literally means “Hospital of Pity,” but
figuratively it was the House of Mercy, where the girls grew up and learned
music. It was the largest of four ospedali, charitable institutions in Venice
founded to ameliorate particular social ills. In the Pietà’s case, the ill was
that fatherless babies (mostly girls) frequently ended up in the canals.
Most of them would never know their mothers. They were dropped off in
the scaffetta, a drawer built into the outer wall of the Pietà. Like the size
tester for carry-on luggage at the airport, if a baby was small enough to fit,
the Pietà would raise her.
The great Anna Maria was a representative example. Someone, probably
her mother, who was probably a prostitute, took baby Anna Maria to the
doorstep of the Pietà on the waterfront of Venice’s St. Mark’s Basin, along a
bustling promenade. A bell attached to the scaffetta alerted staff of each
new arrival. Babies were frequently delivered with a piece of fabric, a coin,
ring, or some trinket left in the scaffetta as a form of identification should
anyone ever return to claim them. One mother left half of a brilliantly
illustrated weather chart, hoping one day to return with the other half. As
with many of the objects, and many of the girls, it remained forever in the
Pietà. Like Anna Maria, most of the foundlings would never know a blood
relative, and so they were named for their home: Anna Maria della Pietà—
Anna Maria of the Pieta. An eighteenth-century roster lists Anna Maria’s de
facto sisters: Adelaide della Pietà, Agata della Pietà, Ambrosina della Pietà,
and on and on, all the way through Violeta, Virginia, and Vittoria della
Pietà.
The ospedali were public-private partnerships, each overseen by a
volunteer board of upper-class Venetians. The institutions were officially
secular, but they were adjoined to churches, and life inside ran according to
quasi-monastic rules. Residents were separated according to age and

gender. Daily Mass was required before breakfast, and regular confession
was expected. Everyone, even children, worked constantly to keep the
institution running. One day a year, girls were allowed a trip to the
countryside, chaperoned, of course. It was a rigid existence, but there were
benefits.
The children were taught to read, write, and do arithmetic, as well as
vocational skills. Some became pharmacists for the residents, others
laundered silk or sewed ship sails that could be sold. The ospedali were
fully functioning, self-contained communities. Everyone was compensated
for their work, and the Pietà had its own interest-paying bank meant to help
wards learn to manage their own money. Boys learned a trade or joined the
navy and left as teenagers. For girls, marriage was the primary route to
emancipation. Dowries were kept ready, but many wards stayed forever.
As the ospedali accrued instruments, music was added to the education
of dozens of girls so that they could play during religious ceremonies in the
adjacent churches. After a plague in 1630 wiped out one-third of the
population, Venetians found themselves in an especially “penitential mood,”
as one historian put it. The musicians suddenly became more important.
The ospedali governors noticed that a lot more people were attending
church, and that the institutional endowments swelled with donations
proportional to the quality of the girls’ music. By the eighteenth century, the
governors were openly promoting the musicians for fundraising. Each
Saturday and Sunday, concerts began before sunset. The church was so
packed that the Eucharist had to be moved. Visitors were still welcome for
free, of course, but if a guest wanted to sit, ospedali staff were happy to rent
out chairs. Once the indoor space was full, listeners crowded outside
windows, or paused their gondolas in the basin outside. Foundlings became
an economic engine not just sustaining the social welfare system in Venice,
but drawing tourists from abroad. Entertainment and penitence mixed in
amusing ways. Audience members were not allowed to applaud in church,
so after the final note they coughed and hemmed and scraped their feet and
blew their noses in admiration.
The ospedali commissioned composers for original works. Over one six-
year period, Vivaldi wrote 140 concertos exclusively for the Pietà
musicians. A teaching system evolved, where the older figlie taught the
younger, and the younger the beginners. They held multiple jobs—Anna
Maria was a teacher and copyist—and yet they produced star after virtuoso

star. After Anna Maria, her soloist successor, Chiara della Pietà, was hailed
as the greatest violinist in all of Europe .
It all raises the question: Just what magical training mechanism was
deployed to transform the orphan foundlings of the Venetian sex industry,
who but for the grace of charity would have died in the city’s canals, into
the world’s original international rock stars?
The Pietà’s music program was not unique for its rigor. According to a list
of Pietà directives, formal lessons were Tuesdays, Thursdays, and
Saturdays, and figlie were free to practice on their own. Early in the rise of
the figlie del coro, work and chores took most of their time, so they were
only allowed an hour a day of music study.
The most surprising feature was how many instruments they learned.
Shortly after he received his music doctorate from Oxford, eighteenth-
century English composer and historian Charles Burney set out to write a
definitive history of modern music, which involved several ospedali visits.
Burney, who became famous as both a travel writer and======================================================== specialize, ref1
science curiosity, ref1
and scientific literature, ref1 , ref2
scientific reasoning, ref1
value of range/inefficiency in, ref1
working abroad, ref1
Serial Innovators (Griffin, Price, and Vojak), ref1
Seth, Jayshree, ref1
Shafer, Mary, ref1
Shakespeare, William, ref1 , ref2 , ref3
Shannon, Claude, ref1
Shoda, Yuichi, ref1
short term planning, ref1
Simmons, Michael, ref1
Simon, Herbert A., ref1
Simon, Julian, ref1
Simonton, Dean Keith, ref1 , ref2 , ref3 , ref4n , ref5
Sloboda, John, ref1
Smith, Gregory White, ref1 , ref2
Smith, Johnny, ref1
Smithies, Oliver, ref1 , ref2
soccer, ref1
Socrates, ref1
Southern, Edwin, ref1
Soviet Union
predictions/forecasts regarding, ref1
premodern villagers of, ref1 , ref2
spelling bee competitors, ref1 , ref2 , ref3
The Sports Gene (Epstein), ref1
standardization covenant, ref1

StarCraft video games, ref1
stents (coronary), ref1
Storm King Mountain fire, ref1
strategic thinking, ref1 , ref2
struggling, benefits of, ref1 , ref2
sunk cost fallacy, ref1
Super Bowl, 2018, ref1
superforecasters, ref1
Superforecasting (Tetlock and Gardner), ref1
surgeons and surgical teams, ref1 , ref2 , ref3
Suzuki Method, ref1
Swanson, Don, ref1 , ref2 , ref3
Swanson, Judy, ref1
Syed, Matthew, ref1
Talent Is Overrated (Colvin), ref1
Taylor, Alva, ref1
teachers, ref1 , ref2
teams
innovation in, ref1
of specialists in “kind” learning environments, ref1
tech companies, founders of, ref1
technological inventors, ref1
tennis, ref1
ten-thousand-hours rule of expertise, ref1 , ref2
test-and-learn model for exploring options, ref1
testing/self-testing, ref1 , ref2 , ref3
Tetlock, Philip, ref1 , ref2 , ref3 , ref4 , ref5 , ref6
Thrale, Hester, ref1
Tiger parents, ref1 , ref2
Tillman Foundation, ref1 , ref2 , ref3 , ref4
Togelius, Julian, ref1
tools
and Air Force pararescue jumpers, ref1 , ref2
and cultural congruence/ incongruence, ref1 , ref2
in medical world, ref1
and NASA’s quantitative culture, ref1 , ref2 , ref3 , ref4 , ref5 , ref6
and overlearned behavior, ref1 , ref2
and reliance on trusted methods/ beliefs, ref1 , ref2
in wilderness firefighting, ref1 , ref2
Toynbee, Arnold, ref1 , ref2
Treffert, Darold, ref1
Tucker, Ross, ref1
Tu Youyou, ref1
Tversky, Amos, ref1
University of Chicago, ref1
University of Washington, ref1
Unusual (or Alternative) Uses Task, ref1
U.S. Air Force Academy, ref1
U.S. Army, ref1 , ref2 , ref3n , ref1

“using procedures” question type, ref1 , ref2
U.S. Military Academy, ref1 , ref2 , ref3
U.S. National Library of Medicine, ref1
Uzzi, Brian, ref1
Van Gogh, Vincent, ref1 , ref2 , ref3 , ref4
Vaughan, Diane, ref1 , ref2 , ref3
Venice, seventeenth-century, ref1
video games, ref1 , ref2 , ref3 , ref4
Viles, Jill, ref1
Vivaldi, Antonio, ref1 , ref2 , ref3
vocabulary learning, ref1 , ref2
Von Braun, Wernher, ref1 , ref2
Wallace, William, ref1
Wallenda, Karl, ref1
Warshaw, Howard Scott, ref1
Watson (IBM), ref1
Weick, Karl, ref1 , ref2 , ref3 , ref4
Wellington, Chrissie, ref1
Wertham, Fredric, ref1
West Point, ref1 , ref2 , ref3 , ref4
Whiteread, Rachel, ref1
Whole Candidate Score of U.S. Military Academy, ref1 , ref2
“wicked” learning environments, ref1 , ref2
Wii by Nintendo, ref1
Williams, Anson, ref1
Wing, Jeannette, ref1
Williams, Serena ref1
Winner, Ellen, ref1 , ref2
Winter Olympics, 2018, ref1
Woods, Earl, ref1 , ref2
Woods, Tiger, ref1 , ref2 , ref3 , ref4 , ref5
writers, ref1 , ref2 , ref3 , ref4
Yates, Ian, ref1
Yokoi, Gunpei, ref1 , ref2 , ref3
youth, perceived intelligence of, ref1
youth sports programs, ref1n
Zuckerberg, Mark, ref1 , ref2
OceanofPDF.com

Praise for Range
‘David Epstein manages to make me thoroughly enjoy the experience of
being told that everything I thought about something was wrong. I loved
Range ’
Malcolm Gladwell, author of Outliers
‘An urgent and important book, an essential read for bosses, parents,
coaches and anyone who cares about improving performance’
Daniel H. Pink, author of Drive and To Sell is Human
‘It’s a joy to spend hours in the company of a writer as gifted as David
Epstein. And the joy is all the greater when that writer shares so much
crucial and revelatory information about performance, success and
education’
Susan Cain, author of Quiet
‘A captivating read that will leave you questioning the next steps in your
career – and the way you raise your children’
Adam Grant, author of Originals and co-author of Option B
‘Extraordinary’
Guardian
‘A goldmine of surprising insights. Makes you smarter with every page’
James Clear, author of Atomic Habits
‘Brilliant, timely and utterly impossible to put down. If you care about
improving skill, innovation and performance, you need to read this book’
Daniel Coyle, author of The Talent Code
‘I want to give Range to . . . everyone who wants humans to thrive in an age
of robots. Range is full of surprises and hope, a twenty-first-century
survival guide’
Amanda Ripley, author of The Smartest Kids in the World

‘Masterful. Perfect holiday reading’
Dr Adam Rutherford, author of A Brief History of Everyone Who Ever
Lived
‘Anyone contemplating a change of career late in life will find Range
immensely reassuring. If you calculate that you don’t have 10,000 hours left
in which you can reasonably practise, you can use your range to connect
ideas and use your varied experience’
Daniel Finkelstein, The Times
‘The storytelling is so dramatic, the wielding of data so deft and the lessons
so strikingly framed [it’s] a pleasure to read . . . Range offers such a wealth
of thought-provoking material’
New York Times Books Review
‘Fabulous . . . If you are interested in champions’ journeys, this is for you’
Judy Murray on Twitter
‘As David Epstein shows us, cultivating range prepares us for the wickedly
unanticipated . . . a well-supported and smoothly written case on behalf of
breadth and late starts’
Wall Street Journal
‘Range elevates Epstein to one of the very best science writers at work
today. The scope of the book – and the implications – are breathtaking’
Sebastian Junger, filmmaker and author of The Perfect Storm
‘One of the most thought-provoking and enlightening books I’ve read’
Maria Konnikova, poker player and author of The Confidence Game
‘A fresh, brisk look at creativity, learning and the meaning of achievement’
Kirkus Reviews
‘An assiduously researched and accessible argument for being a jack of all
trades’
O Magazine , Best Nonfiction Books of 2019

‘Range is a convincing, engaging survey of research and anecdotes that
confirm a thoughtful, collaborative world is also a better and more
innovative one’
NPR
‘A clear and unfussy writer . . . this book is likely to resonate strongly with
most teachers’
Tes
OceanofPDF.com

About the Author
David Epstein is the author of the New York Times bestseller The Sports
Gene . He has master’s degrees in environmental science and journalism
and has worked as an investigative reporter for ProPublica and a senior
writer for Sports Illustrated . He lives in Washington, D.C.
OceanofPDF.com

ALSO BY DAVID EPSTEIN
The Sports Gene
OceanofPDF.com

First published 2019 by Riverhead Books
an imprint of Penguin Random House
First published in the UK 2019 by Macmillan
This electronic edition published 2020 by Pan Books
an imprint of Pan Macmillan
The Smithson, 6 Briset Street, London EC1M 5NR
Associated companies throughout the world
www.panmacmillan.com
ISBN  978-1-5098-4351-0
Copyright © David Epstein 2019
New afterword copyright © David Epstein 2020
Front Cover Image © Image Source/Getty Images
The right of David Epstein to be identified as the author of this work has been asserted by him in
accordance with the Copyright, Designs and Patents Act 1988.
Pan Macmillan does not have any control over, or any responsibility for, any author or third-party
websites referred to in or on this book.
You may not copy, store, distribute, transmit, reproduce or otherwise make available this publication
(or any part of it) in any form, or by any means (electronic, digital, optical, mechanical,
photocopying, recording or otherwise), without the prior written permission of the publisher. Any
person who does any unauthorized act in relation to this publication may be liable to criminal
prosecution and civil claims for damages.
A CIP catalogue record for this book is available from the British Library.
Visit www.panmacmillan.com to read more about all our books and to buy them. You will also find
features, author interviews and news of any author events, and you can sign up for e-newsletters so
that you’re always first to hear about our new releases.
OceanofPDF.com======================================================== tactical prowess were
combined with human big-picture, strategic thinking?
In 1998, he helped organize the first “advanced chess” tournament, in
which each human player, including Kasparov himself, paired with a
computer. Years of pattern study were obviated. The machine partner could
handle tactics so the human could focus on strategy. It was like Tiger
Woods facing off in a golf video game against the best gamers. His years of
repetition would be neutralized, and the contest would shift to one of
strategy rather than tactical execution. In chess, it changed the pecking
order instantly. “Human creativity was even more paramount under these
conditions, not less,” according to Kasparov. Kasparov settled for a 3–3
draw with a player he had trounced four games to zero just a month earlier
in a traditional match. “My advantage in calculating tactics had been
nullified by the machine.” The primary benefit of years of experience with
specialized training was outsourced, and in a contest where humans focused
on strategy, he suddenly had peers.
A few years later, the first “freestyle chess” tournament was held. Teams
could be made up of multiple humans and computers. The lifetime-of-
specialized-practice advantage that had been diluted in advanced chess was
obliterated in freestyle. A duo of amateur players with three normal
computers not only destroyed Hydra, the best chess supercomputer, they
also crushed teams of grandmasters using computers. Kasparov concluded
that the humans on the winning team were the best at “coaching” multiple
computers on what to examine, and then synthesizing that information for
an overall strategy. Human/Computer combo teams—known as
“centaurs”—were playing the highest level of chess ever seen. If Deep

Blue’s victory over Kasparov signaled the transfer of chess power from
humans to computers, the victory of centaurs over Hydra symbolized
something more interesting still: humans empowered to do what they do
best without the prerequisite of years of specialized pattern recognition.
In 2014, an Abu Dhabi–based chess site put up $20,000 in prize money
for freestyle players to compete in a tournament that also included games in
which chess programs played without human intervention. The winning
team comprised four people and several computers. The captain and
primary decision maker was Anson Williams, a British engineer with no
official chess rating. His teammate, Nelson Hernandez, told me, “What
people don’t understand is that freestyle involves an integrated set of skills
that in some cases have nothing to do with playing chess.” In traditional
chess, Williams was probably at the level of a decent amateur. But he was
well versed in computers and adept at integrating streaming information for
strategy decisions. As a teenager, he had been outstanding at the video game
Command & Conquer, known as a “real time strategy” game because
players move simultaneously. In freestyle chess, he had to consider advice
from teammates and various chess programs and then very quickly direct
the computers to examine particular possibilities in more depth. He was like
an executive with a team of mega-grandmaster tactical advisers, deciding
whose advice to probe more deeply and ultimately whose to heed. He
played each game cautiously, expecting a draw, but trying to set up
situations that could lull an opponent into a mistake.
In the end, Kasparov did figure out a way to beat the computer: by
outsourcing tactics, the part of human expertise that is most easily replaced,
the part that he and the Polgar prodigies spent years honing.
In 2007, National Geographic TV gave Susan Polgar a test. They sat her at
a sidewalk table in the middle of a leafy block of Manhattan’s Greenwich
Village, in front of a cleared chessboard. New Yorkers in jeans and fall
jackets went about their jaywalking business as a white truck bearing a
large diagram of a chessboard with twenty-eight pieces in midgame play
took a left turn onto Thompson Street, past the deli, and past Susan Polgar.
She glanced at the diagram as the truck drove by, and then perfectly re-
created it on the board in front of her. The show was reprising a series of

famous chess experiments that pulled back the curtain on kind-learning-
environment skills.
The first took place in the 1940s, when Dutch chess master and
psychologist Adriaan de Groot flashed midgame chessboards in front of
players of different ability levels, and then asked them to re-create the
boards as well as they could. A grandmaster repeatedly re-created the entire
board after seeing it for only three seconds. A master-level player managed
that half as often as the grandmaster. A lesser, city champion player and an
average club player were never able to re-create the board accurately. Just
like Susan Polgar, grandmasters seemed to have photographic memories.
After Susan succeeded in her first test, National Geographic TV turned
the truck around to show the other side, which had a diagram with pieces
placed at random. When Susan saw that side, even though there were fewer
pieces, she could barely re-create anything at all.
That test reenacted an experiment from 1973, in which two Carnegie
Mellon University psychologists, William G. Chase and soon-to-be Nobel
laureate Herbert A. Simon, repeated the De Groot exercise, but added a
wrinkle. This time, the chess players were also given boards with the pieces
in an arrangement that would never actually occur in a game. Suddenly, the
experts performed just like the lesser players. The grandmasters never had
photographic memories after all. Through repetitive study of game patterns,
they had learned to do what Chase and Simon called “chunking.” Rather
than struggling to remember the location of every individual pawn, bishop,
and rook, the brains of elite players grouped pieces into a smaller number of
meaningful chunks based on familiar patterns. Those patterns allow expert
players to immediately assess the situation based on experience, which is
why Garry Kasparov told me that grandmasters usually know their move
within seconds. For Susan Polgar, when the van drove by the first time, the
diagram was not twenty-eight items, but five different meaningful chunks
that indicated how the game was progressing.
Chunking helps explain instances of apparently miraculous, domain-
specific memory, from musicians playing long pieces by heart to
quarterbacks recognizing patterns of players in a split second and making a
decision to throw. The reason that elite athletes seem to have superhuman
reflexes is that they recognize patterns of ball or body movements that tell
them what’s coming before it happens. When tested outside of their sport
context, their superhuman reactions disappear.

We all rely on chunking every day in skills in which we are expert. Take
ten seconds and try to memorize as many of these twenty words as you can:
Because groups twenty patterns
meaningful are words easier into chunk remember
really sentence familiar can to you much in a.
Okay, now try again:
Twenty words are really much easier to
remember in a meaningful sentence because
you can chunk familiar patterns into groups.
Those are the same twenty pieces of information, but over the course of
your life, you’ve learned patterns of words that allow you to instantly make
sense of the second arrangement, and to remember it much more easily.
Your restaurant server doesn’t just happen to have a miraculous memory;
like musicians and quarterbacks, they’ve learned to group recurring
information into chunks.
Studying an enormous number of repetitive patterns is so important in
chess that early specialization in technical practice is critical. Psychologists
Fernand Gobet (an international master) and Guillermo Campitelli (coach to
future grandmasters) found that the chances of a competitive chess player
reaching international master status (a level down from grandmaster)
dropped from one in four to one in fifty-five if rigorous training had not
begun by age twelve. Chunking can seem like magic, but it comes from
extensive, repetitive practice. Laszlo Polgar was right to believe in it. His
daughters don’t even constitute the most extreme evidence.
For more than fifty years, psychiatrist Darold Treffert studied savants,
individuals with an insatiable drive to practice in one domain, and ability in
that area that far outstrips their abilities in other areas. “Islands of genius,”
Treffert calls it. 
*
 Treffert documented the almost unbelievable feats of
savants like pianist Leslie Lemke, who can play thousands of songs from
memory. Because Lemke and other savants have seemingly limitless
retrieval capacity, Treffert initially attributed their abilities to perfect
memories; they are human tape recorders. Except, when they are tested
after hearing a piece of music for the first time, musical savants reproduce
“tonal” music—the genre of nearly all pop and most classical music—more
easily than “atonal” music, in which successive notes do not follow familiar
harmonic structures. If savants were human tape recorders playing notes

back, it would make no difference whether they were asked to re-create
music that follows popular rules of composition or not. But in practice, it
makes an enormous difference. In one study of a savant pianist, the
researcher, who had heard the man play hundreds of songs flawlessly, was
dumbstruck when the savant could not re-create an atonal piece even after a
practice session with it. “What I heard seemed so unlikely that I felt obliged
to check that the keyboard had not somehow slipped into transposing
mode,” the researcher recorded. “But he really had made a mistake, and the
errors continued.” Patterns and familiar structures were critical to the
savant’s extraordinary recall ability. Similarly, when artistic savants are
briefly shown pictures and asked to reproduce them, they do much better
with images of real-life objects than with more abstract depictions.
It took Treffert