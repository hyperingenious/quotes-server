======================================================== later survival will depend on being able to  cope when prevention and delaying tactics have failed. Obviously we  need to work towards cures. But we can do that only for diseases that  we already know about. So we need the capacity to deal with unfore- seen, unforeseeable failures. For this we need a large and vibrant  research community, interested in explanation and problem-solving.  We need the wealth to fund it, and the technological capacity to  implement what it discovers. This is also true of the problem of climate change, about which there  is currently great controversy. We face the prospect that carbon-dioxide  emissions from technology will cause an increase in the average temp- erature of the atmosphere, with harmful effects such as droughts,  sea-level rises, disruption to agriculture, and the extinctions of some  species. These are forecast to outweigh the beneficial effects, such as  an increase in crop yields, a general boost to plant life, and a reduction  in the number of people dying of hypothermia in winter. Trillions of  dollars, and a great deal of legislation and institutional change, in    - tended to reduce those emissions, currently hang on the outcomes of  simulations of the planet’s climate by the most powerful supercomputers,  and on projections by economists about what those computations  imply about the economy in the next century. In the light of the above  discussion, we should notice several things about the controversy and  about the underlying problem. First, we have been lucky so far. Regardless of how accurate the  prevailing climate models are, it is uncontroversial from the laws of  physics, without any need for supercomputers or sophisticated model- ling, that such emissions  must ,  eventually ,   increase the temperature,  which must, eventually, be harmful. Consider, therefore: what if the  relevant parameters had been just slightly different and the moment  of disaster had been in, say, 1902 – Veblen’s time – when carbon-  dioxide emissions were already orders of magnitude above their  pre-Enlightenment values. Then the disaster would have happened  438 the beginning of infinity before anyone could have predicted it or known what was happening.  Sea levels would have risen, agriculture would have been disrupted,  millions would have begun to die, with worse to come. And the great  issue of the day would have been not how to prevent it but what could  be done about it .  They had no supercomputers then. Because of Babbage’s failures  and the scientific community’s misjudgements – and, perhaps most  importantly, their lack of wealth –  they lacked the vital technology of  automated computing altogether. Mechanical calculators and roomfuls  of clerks would have been insufficient. But, much worse: they had  almost no atmospheric physicists. In fact the total number of physicists  of all kinds was a small fraction of the number who today work on  climate change alone. From society’s point of view, physicists were a  luxury in 1902, like colour televisions were in the 1970s. Yet, to recover  from the disaster, society would have needed more scientific knowledge,  and better technology, and more of it – that is to say, more wealth. For  instance, in 1900, building a sea wall to protect the coast of a low-lying  island would have required resources so enormous that the only islands  that could have afforded it would have been those with either large  concentrations of cheap labour or exceptional wealth, as in the Nether- lands, much of whose population already lived below sea level thanks  to the technology of dyke-building.  This is a challenge that is highly susceptible to automation. But people  were in no position to address it in that way. All relevant machines were  underpowered, unreliable, expensive, and impossible to produce in large  numbers. An enormous effort to construct a Panama canal had just failed  with the loss of thousands of lives and vast amounts of money, due to  inadequate technology and scientific know  ledge. And, to compound  those problems, the world as a whole had very little wealth by today’s  standards. Today, a coastal defence project would be well within the  capabilities of almost any coastal nation – and would add decades to  the time available to find other solutions to rising sea levels. If none are found, what would we do  then ? That is a question of a  wholly different kind, which brings me to my second observation on  the climate-change controversy. It is that, while the supercomputer  simulations make (conditional)  predictions , the economic forecasts  make almost pure  prophecies . For we can expect the future of human  439 Unsustainable responses to climate to depend heavily on how successful people are  at creating new knowledge to address the problems that arise. So  comparing predictions with prophecies is going to lead to that same  old mistake.  Again, suppose that disaster had already been under way in 1902.  Consider======================================================== 112, 113, 256, 446 knowledge   78 in adaptation  55, 56–65, 78–81, 88;  and the problem of creationism   79–81 and authority   see  authority and  knowledge creation of  see  creation of knowledge cultural  50, 51, 55, 59, 422 and deduction  5 certain  see  fallibilism and ‘a dream of Socrates’  226–43,  245, 252–3 effects on an environment  74–5;  see  also   under  biosphere encoded/embodied in matter  50, 56,  74–5, 266–7, 375–7 and evolution  77, 78–105 explanatory  see  explanations; scientific  theories genetic  see  DNA; genes; genomes inexplicit   see  inexplicit knowledge infinite ignorance as potential for  447 moral   see  moral knowledge as ‘nearly there’  445–6 non-explanatory  29, 73, 78, 94;  see  also  inexplicit knowledge; rules of  thumb objective  vii, 15, 31, 122, 185, 193,  203, 209, 221–2, 226, 236, 238,  242, 253, 255, 308, 314, 345, 350,  353–4, 358–68, 388, 394, 448 Plato’s theory of  119, 252, 252–3 as a replicator  95, 114, 266–7 significance of people and  70–75,   76 and survival  202, 207 see also  epistemology Kuhn, Thomas  313 Kurrild-Klitgaard, Peter  339 476 index Lagrange, Joseph-Louis  198–9, 206,  445, 446 Lamarck, Jean-Baptiste  87–8, 89 Lamarckism  87–9, 96, 103,  105 , 106,  158, 210, 376, 411, 446 language  93, 94, 125–6, 142, 154, 268,  280, 309, 311, 315, 323, 363, 365,  366, 369–70, 405, 407, 409, 413,  414, 428 other than natural language  144, 154,  159–62, 199, 292, 361, 365, 366,  399 see also  universality: the jump to;  writing systems Laplace, Pierre Simon  133 lasers  73, 266, 267, 273–4, 294, 393,  446 see also  atomic lasers laws of nature  see  nature, laws of laws of physics  see  physics, laws of Leibniz, Gottfried Wilhelm  137, 164,  181, 199–200, 265–6, 268, 269 Leonardo da Vinci  219 liberty  see  freedom life-support system  44–51,  45 , 64,  71  see also  Spaceship Earth;  sustainability light  2, 3, 8, 11, 16, 38, 46, 47, 54, 61,  68, 80, 85, 208, 228, 240n, 261,  273, 305, 314, 357, 413, 433, 452 faster-than-light communication  55– 6, 275–6, 283, 434 speed of  192, 199, 262, 263, 273,  291, 293, 294, 451 sunlight  8, 47, 57, 441 see also  photons Littlefield, John E.  333 llamas  426–7, 429 Locke, John  4, 134 Loebner, Hugh  (Prize) 150–51 logical positivism  313, 314,  325 Lovelace, Ada, Countess of  136, 137, 148 ‘Lady Lovelace’s objection’  138 low-level phenomena  109–10, 111, 138 Mach, Ernst  312, 324 Mach, Ludwig  312 Mach–Zehnder interferometers  286–7,  296–7, 305, 309, 312 Machiavelli, Niccolò  219 magic  16, 19–21, 53–4, 81, 82, 173,  242, 301 wizards  260   see also  conjuring tricks Malthus, Thomas  201, 205–7, 421, 435,  436 Malthusian prophetic fallacy  206,  214, 432 Marx, Karl  371, 426, 428, 430, 442 mathematical proof  see  proof mathematical truth  see  truth mating  90, 91, 144, 359, 360, 362, 400,  401, 402, 413, 415 matter  14, 16, 40, 45–6, 61–2, 66, 68–9,  74, 75, 85, 97, 134, 203, 290–91,  305 dark  36, 46, 67 ordinary  45–6 prominent  73 Maxwell, James Clerk  255 measure theory for infinite sets  102,  178–83, 277–8, 281, 283, 287,  303 ,  453, 458 for histories  301,  303 , 307, 454, 455 measurement  11, 35, 62, 68, 72, 99,  108, 158, 183, 274, 299, 309, 316,  338, 340, 357, 443 errors  140–42, 298, 321–3;  see also  fallibility; fooling ourselves see also  proxies measuring instruments  18, 34–41, 179,  192, 269, 294–5, 308, 446 human sensory systems as  40 SETI  72–3   see also  microscopes; telescopes Medawar, Peter  193 Medici, Lorenzo de’  218, 429 Medici family  218–20 Mediocrity, Principle of  43–4, 45, 51–4,  64,  76 , 101, 110, 166, 434 memes  93, 94–5,  105 , 369–72 in animals  see  aping; parroting anti-rational  81, 381, 385, 388–90,  391–3, 394– 396 , 397, 413, 428,  457 compared with viruses  384 creativity and  in meme replication   402–15, 416 evolution of  372–8, 383, 390, 393,  400, 412–13 faithful replication of  257, 370, 374,  377, 378–80, 382–4, 390, 405,   413 generations of  376, 379 477 index and genes  372–97, 404, 405, 407,  408, 413, 414 living with  394–6 long-lived  222, 370, 377, 380, 382–3,  384, 387, 388, 394, 399 memeplexes  93,  105 , 374, 384 mutual enhancement of creativity and  meme transmission  400 in pre-humans and early humans  50,  55, 72, 207, 399, 412–13, 414 puzzle of how they can possibly be  replicated  402–10 rational  388–90, 392, 393,  396 , 397 ‘selfish’  378–9, 387 slavery to  130, 383, 384, 392 Messenians  218 Michelangelo  219 Michelson, Albert  198–9, 445–6 micro-organisms  82, 196, 425, 436 bacteria  82, 145, 162, 436 microprocessors  see  computers/ computation microscopes  34, 37, 38, 39, 220, 312,  324, 355 microwave background radiation  46,  47, 68 Milky Way  1, 2, 47, 70–71, 101, 202–3 Mills, Roger Q.  333, 334 mind–body problem  117–22, 130 minds, animal  320–21 see also  memes, in animals mirages  228, 229, 231 mirror neurons  405–6, 408, 414 mirrors, semi-silvered  286–7 momentum  55, 273–4, 297 moon  24, 55, 57–8, 61–3, 66, 67, 68,  74, 143, 215, 366,======================================================== capable of causing other objects to undergo  transformations without undergoing any net change itself. Universal constructor   A constructor that can cause any raw materials  to undergo any physically possible transformation, given the right  information. meanings of ‘the beginning of infinity’  encountered in this chapter –  The fact that everything that is not forbidden by laws of nature is  achievable, given the right knowledge. ‘Problems are soluble.’ –  The ‘perspiration’ phase can always be automated. –  The knowledge-friendliness of the physical world. –  People are universal constructors. –  The beginning of the open-ended creation of explanations. –  The environments that could create an open-ended stream of know- ledge, if suitably primed – i.e. almost all environments. –  The fact that new explanations create new problems. summary Both the Principle of Mediocrity and the Spaceship Earth idea are,  contrary to their motivations, irreparably parochial and mistaken.  From the least parochial perspectives available to us,  people  are the  most significant entities in the cosmic scheme of things. They are not  ‘supported’ by their environments, but support themselves by creating  knowledge. Once they have suitable knowledge (essentially, the know- ledge of the Enlightenment), they are capable of sparking unlimited  further progress. Apart from the thoughts of people, the only process known to be  77 The Spark capable of creating knowledge is biological evolution. The knowledge  it creates (other than via people) is inherently bounded and parochial.  Yet it also has close similarities with human knowledge. The similarities  and the differences are the subject of the next chapter. 78 4 Creation The knowledge in human brains and the knowledge in biological  adaptations are both created by  evolution  in the broad sense: the  variation of existing information, alternating with selection. In the  case of human knowledge, the variation is by conjecture, and the  selection is by criticism and experiment. In the biosphere, the variation  consists of mutations (random changes) in genes, and natural selection  favours the variants that most improve the ability of their organisms  to reproduce, thus causing those variant genes to spread through    the population.  That a gene is  adapted  to a given function means that few, if any,  small changes would improve its ability to perform that function. Some  changes might make no practical difference to that ability, but most  of those that did would make it worse. In other words good adaptations,  like good explanations, are distinguished by being hard to vary while  still fulfilling their functions. Human brains and DNA molecules each have many functions, but  among other things they are general-purpose information-storage  media: they are in principle capable of storing any kind of information.  Moreover, the two types of information that they respectively evolved  to store have a property of cosmic significance in common:  once they  are physically  embodied in a suitable environment, they tend to cause  themselves to remain so . Such information – which I call  knowledge   – is very unlikely to come into existence other than through the error- correcting processes of evolution or thought.  There are also important differences between those two kinds of  knowledge. One is that biological knowledge is non-explanatory, and  therefore has limited reach; explanatory human knowledge can have  79 Creation broad or even unlimited reach. Another difference is that mutations  are random, while conjectures can be constructed intentionally for a  purpose. Nevertheless, the two kinds of knowledge share enough of  their underlying logic for the theory of evolution to be highly relevant  to human knowledge. In particular, some historic misconceptions    about biological evolution have counterparts in misconceptions about    human knowledge. So in this chapter I shall describe some of those  misconceptions in addition to the actual explanation of biological  adaptations, namely modern Darwinian evolutionary theory, sometimes  known as ‘neo-Darwinism’. Creationism Creationism is the idea that some supernatural being or beings designed  and created all biological adaptations. In other words, ‘the gods did  it.’ As I explained in Chapter 1, theories of that form are bad ex    - planations. Unless supplemented by hard-to-vary specifics, they do not  even address the problem – just as ‘the laws of physics did it’ will never  win you a Nobel prize, and ‘the conjurer did it’ does not solve the  mystery of the conjuring trick.  Before a conjuring trick is ever performed, its explanation must be  known to the person who invented it. The origin of that knowledge is  the origin of the trick. Similarly, the problem of explaining the biosphere  is that of explaining how the knowledge embodied in its adaptations  could possibly have been created. In particular, a putative designer of  any======================================================== that these new  universes might have different laws of physics – and that, moreover,  those laws would be affected by conditions in the parent universe. In  particular, intelligent beings in the parent universe could influence the  black holes to produce further universes with person-friendly laws of  physics. But there is a problem with explanations of this type (known  as ‘evolutionary cosmologies’): how many universes were there to  begin with? If there were infinitely many, then we are left with the  problem of how to count them – and the mere fact that each  astrophysicist-bearing universe would give rise to several others need  not meaningfully increase the  proportion  of such universes in the total.  If there was no first universe or universes, but the whole ensemble has  already existed for an infinite time, then the theory has an infinite- regress problem. For then, as the cosmologist Frank Tipler has pointed  out, the entire collection must have settled into its equilibrium state  ‘an infinite time ago’, which would mean that the evolution that  brought about that equilibrium – the very process that is supposed to  explain the fine-tuning –  never happened  (just as the lost puppy is  nowhere ). If there was initially only one universe, or a finite number,  179 A Window on Infinity then we are left with the fine-tuning problem for the original universe(s):  did they contain astrophysicists? Presumably not; but if the original  universes produced an enormous chain of descendants until one, by  chance, contains astrophysicists, then that still does not answer the  question of why the entire system – now operating under a single law  of physics in which the apparent ‘constants’ are varying according    to laws of nature – permits this ultimately astrophysicist-friendly  mechanism to happen. And there would be no anthropic explanation  for  that  coincidence. Smolin’s theory does the right thing: it proposes an overarching  framework for the ensemble of universes, and some physical connec- tions between them. But the explanation connects only universes and  their ‘parent’ universes, which is insufficient. So it does not work. But now suppose we also tell a story about the reality that connects  all these universes and gives a preferred physical meaning to one way  of labelling them. Here is one. A girl called Lyra, who was born in  universe 1, discovers a device that can move her to other universes. It  also keeps her alive inside a small sphere of life support, even in universes  whose laws of physics do not otherwise support life. So long as she  holds down a certain button on the device, she moves from universe to  universe,  in a fixed order , at intervals of exactly one minute. As soon  as she lets go, she returns to her home universe. Let us label the universes  1, 2, 3 and so on, in the order in which the device visits them.  Sometimes Lyra also takes with her a measuring instrument that  measures the constant  D , and another that measures – rather like the  SETI  project, only much faster and more reliably – whether there are  astrophysicists in the universe. She is hoping to test the predictions of  the anthropic principle. But she can only ever visit a finite number of universes, and she has  no way of telling whether those are representative of the whole infinite  set. However, the device does have a second setting. On that setting, it  takes Lyra to universe 2 for one minute, then universe 3 for  half  a  minute, universe 4 for a quarter of a minute and so on. If she has not  released the button by the time two minutes are up, she will have visited  every universe in the infinite set, which in this story means every universe  in existence. The device then returns her automatically to universe 1. If  she presses it again, her journey begins again with universe 2. 180 the beginning of infinity Most of the universes flash by too fast for Lyra to see. But her  measuring instruments are not subject to the limitations of human  senses – nor to  our  world’s laws of physics. After they are switched  on, their displays show a running average of the values from all the  universes they have been in, regardless of how much time they spent  in each. So, for instance, if the even-numbered universes have astro- physicists and the odd-numbered ones do not, then at the end of a  two-minute journey through all the universes her  SETI -like instrument  will be displaying 0.5. So in that multiverse it  is  meaningful to say that  half the universes have astrophysicists. Using a universe-travelling device that visited the same universes in  a different order, one would obtain a different value for that proportion.  But , suppose that the laws of physics permit visiting them in only one  order (rather as our own laws of physics normally allow us to be at  different  times  only in one particular order). Since there is now only  one way for measuring instruments to respond to averages, typical  values and so======================================================== story, it would also vibrate with their steps and  set off sound waves which people in the ordinary world could hear. So  there must be a separate floor and walls as well as an entire spaceship  hull in the phantom zone. Even the space outside cannot be ordinary  space, because if one could get back into ordinary space by leaving the  ship, then the exiles could return by that route. But if there is an entire  phantom-zone space out there – a parallel universe – how could a mere  transporter malfunction have created  that ?  We should not be surprised that good fictional science is hard to  invent: it is a variant of real science, and real scientific knowledge is  262 the beginning of infinity very hard to vary. Thus few if any of the storylines that I have outlined  make sense as they stand. But I want to continue with one of my own,  making sure that it (eventually) does make sense.  A writer of real science fiction faces two conflicting incentives. One  is, as with all fiction, to allow the reader to engage with the story, and  the easiest way to do that is to draw on themes that are already familiar.  But that is an anthropocentric incentive. For instance, it pushes authors  to imagine ways around the absolute speed limit that the laws of  physics impose on travel and communication (namely the speed of  light). But when authors do that, they relegate  distance  to the role that  it has in stories about our home planet: star systems play the same role  that remote islands or the Wild West did in the fiction of earlier eras.  Similarly, the temptation in parallel-universe stories is to allow com  - munication or travel between universes. But then the story is really  about a single universe: once the barrier between the universes is easily  penetrable, it becomes no more than an exotic version of the oceans  that separate continents. A story that succumbs entirely to this anthro- pocentric incentive is not really science fiction but ordinary fiction    in disguise.  The opposing incentive is to explore the strongest possible version  of a fictional-science premise, and its strangest possible implications  – which pushes in the anti-anthropocentric direction. This may make  the story harder to engage with, but it allows for a much broader range  of scientific speculations. In the story that I shall tell here, I shall use  a succession of such speculations, increasingly distant from the familiar,  as means of explaining the world according to quantum theory.  Quantum theory is the deepest explanation known to science. It  violates many of the assumptions of common sense, and of all previous  science – including some that no one suspected were being made at all  until quantum theory came along and contradicted them. And yet this  seemingly alien territory is the reality of which we and everything we  experience are part. There is no other. So, in setting a story there,  perhaps what I lose in terms of the familiar ingredients of drama I    shall gain in terms of opportunity to explain something that is more  astounding than any fiction, yet is the purest and most basic fact we  know about the physical world. I had better warn the reader that the account that I shall give –  263 The Multiverse known as the ‘many-universes interpretation’ of quantum theory (rather  inadequately, since there is much more to it than ‘universes’) – remains  at the time of writing a decidedly minority view among physicists. In  the next chapter I shall speculate why that is so despite the fact that  many well-studied phenomena have no other known explanation. For  the moment, suffice it to say that the very idea of  science as explanation ,  in the sense that I am advocating in this book (namely an account of  what is really out there), is itself still a minority view even among  theoretical physicists. Let me begin with perhaps the simplest possible ‘parallel-universe’  speculation: a ‘phantom zone’ has existed all along (ever since its own  Big Bang). Until our story begins, it has been an exact  doppelgänger   of the entire universe, atom for atom and event for event. All the flaws that I mentioned in the phantom-zone stories derive  from the asymmetry that things in the ordinary world affect things in  the phantom zone but not vice versa. So let me eliminate those flaws  by imagining, for the moment, that the universes are completely im    - perceptible to each other. Since we are heading towards real physics,  let me also retain the speed-of-light limit on communication, and let  the laws of physics be universal and symmetrical (i.e. they make no  distinction between the universes). Moreover, they are deterministic:  nothing random ever happens, which is why the universes have  remained alike – so far. So how can they ever become different?    That is a key question in the theory of the multiverse, which I shall    answer below. All these basic properties of my fictional world can be thought of as  conditions on the flow of======================================================== if the experimenters tried to eliminate  the subjective self-assessment and instead observed happy and unhappy  behaviour  (such as facial expressions, or how often a person whistles  317 A Physicist’s History of Bad Philosophy a happy tune). The connection with happiness would still involve  comparing subjective interpretations which there is no way of calibrat- ing to a common standard; but in addition there would be an extra  level of interpretation: some people believe that behaving in ‘happy’  ways is a remedy for unhappiness, so, for those people, such behaviours  might be a proxy for  un happiness.  For these reasons, no behavioural study can detect whether happiness  is inborn or not. Science simply cannot resolve that issue until we    have explanatory theories about what objective attributes people are  referring to when they speak of their happiness, and also about what  physical chain of events connects genes to those attributes. So how does explanation-free science address the issue? First, one  explains that one is not measuring happiness directly, but only a proxy  such as the behaviour of marking checkboxes on a scale called ‘hap  - piness’. All scientific measurements use chains of proxies. But, as I  explained in Chapters 2 and 3, each link in the chain is an additional  source of error, and we can avoid fooling ourselves only by criticizing  the theory of each link – which is impossible unless an explanatory  theory links the proxies to the quantities of interest. That is why, in  genuine science, one can claim to have measured a quantity only when  one has an explanatory theory of how and why the measurement  procedure should reveal its value, and with what accuracy.  There are circumstances under which there  is  a good explanation  linking the measurable proxy such as marking checkboxes with a  quantity of interest, and in such cases there need be nothing unscientific  about the study. For example, political opinion surveys may ask whether  respondents are ‘happy’ with a given politician facing re-election, under  the theory that this gives information about which checkbox the  respondents will choose in the election itself. That theory is then tested  at the election. There is no analogue of such a test in the case of  happiness: there is no independent way of measuring it. Another  example of bona-fide science would be a clinical trial to test a drug  purported to alleviate (particular identifiable types of) unhappiness. In  that case, the objective of the study is, again, to determine whether the  drug causes  behaviour  such as saying that one is happier (without also  experiencing adverse side effects). If a drug passes that test, the issue of  whether it really makes the patients happier, or merely alters their  318 the beginning of infinity personality to have lower standards or something of that sort, is in    - accessible to science until such time as there is a testable explanatory  theory of what happiness is In explanationless science, one may acknowledge that actual happi- ness and the proxy one is measuring are not necessarily equal .  But one  nevertheless calls the proxy ‘happiness’ and moves on. One chooses a  large number of people, ostensibly at random (though in real life    one is restricted to small minorities such as university students, in a  particular country, seeking additional income), and one excludes those  who have detectable extrinsic reasons for happiness or unhappiness  (such as recent lottery wins or bereavement). So one’s subjects are just  ‘typical people’ – though in fact one cannot tell whether they are  statistically representative without an explanatory theory. Next, one  defines the ‘heritability’ of a trait as its degree of statistical correlation  with how genetically related the people are .  Again, that is a non- explanatory definition: according to it, whether one was a slave or not  was once a highly ‘heritable’ trait in America: it ran in families. More  generally, one acknowledges that statistical correlations do not imply  anything about what causes what. But one adds the inductivist   equivo-  cation that ‘they can be suggestive, though.’  Then one does the study and finds that ‘happiness’ is, say, 50 per cent  ‘heritable’. This asserts nothing about happiness itself, until the relevant  explanatory theories are discovered (at some time in the future – perhaps  after consciousness is understood and AIs are commonplace technology).  Yet people find the result interesting, because they interpret it via  everyday meanings of the words ‘happiness’ and ‘heritable’. Under that  interpretation – which the authors of the study, if they are scrupulous,  will nowhere have endorsed – the result is a profound contribution to  a wide class of philosophical and scientific debates about the nature of  the human mind. Press reports of the discovery will reflect this. The  headline will say, ‘New Study Shows Happiness 50% Genetically  Determined’ –======================================================== consecutive cubes in any direction  the story would be the same.  Cold, dark and empty. That unimaginably desolate environment is  typical of the universe – and is another measure of how  un typical the  Earth and its chemical scum are, in a straightforward physical sense.  48 the beginning of infinity The issue of the cosmic significance of this type of scum will shortly  take us back out into intergalactic space. But let me first return to  Earth, and consider the Spaceship Earth metaphor, in  its  straightforward  physical version.  This much is true: if, tomorrow, physical conditions on the Earth’s  surface were to change even slightly by astrophysical standards, then  no humans could live here unprotected, just as they could not survive  on a spaceship whose life-support system had broken down. Yet I am  writing this in Oxford, England, where winter nights are likewise often  cold enough to kill any human unprotected by clothing and other  technology. So, while intergalactic space would kill me in a matter of  seconds, Oxfordshire in its primeval state might do it in a matter of  hours – which can be considered ‘life support’ only in the most contrived  sense. There  is  a life-support system in Oxfordshire today, but it was  not provided by the biosphere. It has been built by humans. It consists  of clothes, houses, farms, hospitals, an electrical grid, a sewage system  and so on. Nearly the whole of the Earth’s biosphere in its primeval  state was likewise incapable of keeping an unprotected human alive  for long. It would be much more accurate to call it a death trap for  humans rather than a life-support system. Even the Great Rift Valley  in eastern Africa, where our species evolved, was barely more hospitable  than primeval Oxfordshire. Unlike the life-support system in that  imagined spaceship, the Great Rift Valley lacked a safe water supply,  and medical equipment, and comfortable living quarters, and was  infested with predators, parasites and disease organisms. It frequently  injured, poisoned, drenched, starved and sickened its ‘passengers’, and  most of them died as a result.  It was similarly harsh to all the other organisms that lived there:    few individuals live comfortably or die of old age in the supposedly  beneficent biosphere. That is no accident: most populations, of most  species, are living close to the edge of disaster and death. It has to be  that way, because as soon as some small group, somewhere, begins to  have a slightly easier life than that, for any reason – for instance, an  increased food supply, or the extinction of a competitor or predator –  then its numbers increase. As a result, its other resources are depleted  by the increased usage; so an increasing proportion of the population  now has to colonize more marginal habitats and make do with inferior  49 The Spark resources, and so on. This process continues until the disadvantages  caused by the increased population have exactly balanced the advantage  conferred by the beneficial change. That is to say, the new birth rate is  again just barely keeping pace with the rampant disabling and killing  of individuals by starvation, exhaustion, predation, overcrowding and  all those other natural processes. That is the situation to which evolution adapts organisms. And that,  therefore, is the lifestyle in which the Earth’s biosphere ‘seems adapted’  to sustaining them. The biosphere only ever achieves stability – and  only temporarily at that – by continually neglecting, harming, disabling  and killing individuals. Hence the metaphor of a spaceship or a life- support system, is quite perverse: when humans design a life-support  system, they design it to provide the maximum possible comfort, safety  and longevity for its users within the available resources; the biosphere  has no such priorities.  Nor is the biosphere a great preserver of  species . In addition to being  notoriously cruel to individuals, evolution involves continual extinctions  of entire species. The average rate of extinction since the beginning of  life on Earth has been about ten species per year (the number is known  only very approximately), becoming much higher during the relatively  brief periods that palaeontologists call ‘mass extinction events’. The  rate at which species have come into existence has on balance only  slightly exceeded the extinction rate, and the net effect is that the  overwhelming majority of species that have ever existed on Earth  (perhaps 99.9 per cent of them) are now extinct. Genetic evidence  suggests that our own species narrowly escaped extinction on at least  one occasion. Several species closely related to ours did become extinct.  Significantly, the ‘life-support system’ itself wiped them out – by means  such as natural disasters, evolutionary changes in other species, and  climate change. Those cousins of ours had not invited extinction by  changing their lifestyles or overloading the biosphere: on the======================================================== be able to harness physical phenomena of which  we are unaware. Also, that teleportation to or from another location  would be mistaken for ‘destruction’ (without trace) and ‘creation’ (out  of thin air) in your experiment and that therefore this cannot be ruled  out as a possible cause of the anomalies. When headlines appear of the form ‘Teleportation Possibly  Observed in City Museum, Say Scientists’ and ‘Scientists Prove Alien  323 A Physicist’s History of Bad Philosophy Abduction is Real,’ protest mildly that you have claimed no such  thing, that your results are not conclusive, merely suggestive, and  that more studies are needed to determine the mechanism of this  perplexing phenomenon. You have made no false claim. Data can become ‘inconsistent with  conventional physics’ by the mundane means of containing errors, just  as genes can ‘cause happiness’ by countless mundane means such as  affecting your appearance. The fact that your paper does not point this  out does not make it false. Moreover, as I said, the crucial step consists  of a definition, and definitions, provided only that they are consistent,  cannot be false. You have  defined  an observation of more people entering  than leaving as a ‘destruction’ of people. Although, in everyday language,  that phrase has a connotation of people disappearing in puffs of smoke,  that is not what it means in this study. For all you know, they  could  be  disappearing in puffs of smoke, or in invisible spaceships: that would  be consistent with your data. But your paper takes no position on that.  It is entirely about the outcomes of your observations.  So you had better not name your research paper ‘Errors Made When  Counting People Incompetently’. Aside from being a public-relations  blunder, that title might even be considered unscientific, according to  explanationless science. For it would be taking a position on the  ‘interpretation’ of the observed data, about which it provides no  evidence.  In my view this is a scientific experiment in form only. The substance  of scientific theories is explanation, and explanation  of   errors  constitutes  most of the content of the design of any non-trivial scientific experiment. As the above example illustrates, a generic feature of experimentation  is that the bigger the errors you make, either in the numbers or in your  naming and interpretation of the measured quantities, the more exciting  the results are,  if true . So, without powerful techniques of error-detection  and -correction – which depend on explanatory theories – this gives  rise to an instability where false results drown out the true. In the ‘hard  sciences’ – which usually do good science – false results due to all sorts  of errors are nevertheless common. But they are corrected when    their explanations are criticized and tested. That cannot happen in  explanationless science. Consequently, as soon as scientists allow themselves to stop demand- 324 the beginning of infinity ing good explanations and consider only whether a prediction is  accurate or inaccurate, they are liable to make fools of themselves. This  is the means by which a succession of eminent physicists over the  decades have been fooled by conjurers into believing that various  conjuring tricks have been done by ‘paranormal’ means. Bad philosophy cannot easily be countered by good philosophy –  argument and explanation – because it holds itself immune. But it can  be countered by  progress . People want to understand the world, no  matter how loudly they may deny that. And progress makes bad  philosophy harder to believe. That is not a matter of refutation by logic  or experience, but of explanation. If Mach were alive today I expect  he would have accepted the existence of atoms once he saw them  through a microscope, behaving according to atomic theory. As a matter  of logic, it would still be open to him to say, ‘I’m not seeing atoms, I’m  only seeing a video monitor. And I’m only seeing that theory’s predict- ions  about me , not about atoms, come true.’ But the fact that that is a  general-purpose bad explanation would be borne in upon him. It would  also be open to him to say, ‘Very well, atoms do exist, but electrons do  not.’ But he might well tire of that game if a better one seems to be  available – that is to say, if rapid progress is made. And then he would  soon realize that it is not a game. Bad philosophy is philosophy that denies the possibility, desirability  or existence of progress. And progress is the only effective way of  opposing bad philosophy. If progress cannot continue indefinitely, bad  philosophy will inevitably come again into the ascendancy – for it will  be true. terminology Bad philosophy   Philosophy that actively prevents the growth of  knowledge. Interpretation   The explanatory part of a scientific theory, supposedly  distinct from its predictive or instrumental part. Copenhagen interpretation   Niels Bohr’s combination of instrument-======================================================== then  explained seasons. And, without any further modification, it also  explained why seasons are out of phase in the two hemispheres, and  why tropical regions do not have them, and why the summer sun shines  at midnight in polar regions – three phenomena of which its creators  may well have been unaware.  The reach of an explanation is not a ‘principle of induction’; it is not  something that the creator of the explanation can use to obtain or justify  it. It is not part of the creative process at all. We find out about it only  after we have the explanation – sometimes long after. So it has nothing  to do with ‘extrapolation’, or ‘induction’, or with ‘deriving’ a theory in  any other alleged way. It is exactly the other way round: the reason that  the explanation of seasons reaches far outside the experience of its  29 The Reach of Explanations creators is precisely that it  does not  have to be extrapolated. By its  nature as an explanation, when its creators first thought of it, it already  applied in our planet’s other hemisphere, and throughout the solar  system, and in other solar systems, and at other times.  Thus the reach of an explanation is neither an additional assumption  nor a detachable one. It is determined by the content of the explanation  itself. The better an explanation is, the more rigidly its reach is determined  – because the harder it is to vary an explanation, the harder it is in  particular to construct a variant with a different reach, whether larger  or smaller, that is still an explanation. We expect the law of gravity to  be the same on Mars as on Earth because only one viable explanation  of gravity is known – Einstein’s general theory of relativity – and that  is a universal theory; but we do not expect the  map  of Mars to resemble  the map of Earth, because our theories about how Earth looks, despite  being excellent explanations, have no reach to the appearance of any  other astronomical object. Always, it is explanatory theories that tell  us which (usually few) aspects of one situation can be ‘extrapolated’    to others. It also makes sense to speak of the reach of non-explanatory forms  of knowledge – rules of thumb, and also knowledge that is implicit in  the genes for biological adaptations. So, as I said, my rule of thumb  about cups-and-balls tricks has reach to a certain class of tricks; but I  could not know what that class is without the explanation for why the  rule works.  Old ways of thought, which did not seek good explanations, permitted  no process such as science for correcting errors and misconceptions.  Improvements happened so rarely that most people never experienced  one. Ideas were static for long periods. Being bad explanations, even  the best of them typically had little reach and were therefore brittle and  unreliable beyond, and often within, their traditional applications. When  ideas did change, it was seldom for the better, and when it did happen  to be for the better, that seldom increased their reach. The emergence  of science, and more broadly what I am calling the Enlightenment, was  the beginning of the end of such static, parochial systems of ideas. It  initiated the present era in human history, unique for its sustained, rapid  creation of knowledge with ever-increasing reach. Many have wondered  how long this can continue. Is it inherently bounded? Or is this the  30 the beginning of infinity beginning of infinity – that is to say, do these methods have unlimited  potential to create further knowledge? It may seem paradoxical to claim  anything so grand (even if only potentially) on behalf of a project that  has swept away all the ancient myths that used to assign human beings  a special significance in the scheme of things. For if the power of the  human faculties of reason and creativity, which have driven the En    - lightenment, were indeed unlimited, would humans not have just such  a significance?  And yet, as I mentioned at the beginning of this chapter, gold can  be created only by stars and by intelligent beings. If you find a nugget  of gold anywhere in the universe, you can be sure that in its history  there was either a supernova or an intelligent being with an explanation.  And if you find an explanation anywhere in the universe, you know  that there must have been an intelligent being. A supernova alone  would not suffice.  But – so what? Gold is important  to us , but in the cosmic scheme  of things it has little significance. Explanations are important to us:  we need them to survive. But is there anything significant, in the cosmic  scheme of things, about explanation, that apparently puny physical  process that happens inside brains? I shall address that question in  Chapter 3, after some reflections about appearance and reality. terminology Explanation  Statement about what is there, what it does, and how  and why. Reach  The ability of some explanations to solve problems beyond  those that they were created to======================================================== found in the current user’s input. Weizenbaum was shocked that many people using  Eliza  were fooled  by it. So it had passed the Turing test – at least, in its most naive version.  Moreover, even after people had been told that it was not a genuine  AI, they would sometimes continue to have long conversations with it  about their personal problems, exactly as though they believed that it  understood them. Weizenbaum wrote a book,  Computer Power and  Human Reason  (1976), warning of the dangers of anthropomorphism  when computers seem to exhibit human-like functionality. However, anthropomorphism is not the main type of overconfidence  that has beset the field of AI. For example, in 1983 Douglas Hofstadter  was subjected to a friendly hoax by some graduate students. They  convinced him that they had obtained access to a government-run AI  program, and invited him to apply the Turing test to it. In reality, one  of the students was at the other end of the line, imitating an  Eliza  program. As Hofstadter relates in his book  Metamagical Themas   (1985), the student was from the outset displaying an implausible  degree of understanding of Hofstadter’s questions. For example, an  early exchange was: 150 the beginning of infinity hofstadter : What are ears? student : Ears are auditory organs found on animals. That is not a dictionary definition. So  something  must have processed  the meaning of the word ‘ears’ in a way that distinguished it from most  other nouns. Any one such exchange is easily explained as being due  to luck: the question must have matched one of the templates that the  programmer had provided, including customized information about  ears. But after half a dozen exchanges on different subjects, phrased  in different ways, such luck becomes a very bad explanation and the  game should have been up. But it was not. So the student became ever  bolder in his replies, until eventually he was making jokes directed  specifically at Hofstadter – which gave him away. As Hofstadter remarked, ‘In retrospect, I am quite amazed at how  much genuine intelligence I was willing to accept as somehow having  been implanted in the program . . . It is clear that I was willing to accept  a huge amount of fluidity as achievable in this day and age simply by  putting together a large bag of isolated tricks, kludges and hacks.’ The  fact was (and this alone should have alerted Hofstadter) that, nineteen  years after  Eliza , not one of the  Eliza -like programs of the day resembled  a person even slightly more than the original had. Although they were  able to parse sentences better, and had more pre-programmed templates  for questions and answers, that is almost no help in an extended  conversation on diverse subjects. The probability that the outputs of  such templates will continue to resemble the products of human  thought diminishes exponentially with the number of utterances. So  Hofstadter should have been able to pronounce quite soon that the  candidate had passed the Turing test – and that, because it nevertheless  sounded rather like  Eliza , it must be a person pretending to be a  computer program. Programs written today – a further twenty-six years later – are still  no better at the task of seeming to think than  Eliza  was. They are now  known as ‘chatbots’, and their main application is still amusement, both  directly and in computer games. They have also been used to pro            vide  friendly seeming interfaces to lists of ‘frequently asked questions’ about  subjects like how to operate computers. But I think that users find them  no more helpful than a searchable list of the questions and answers. In 1990 the inventor Hugh Loebner endowed a prize for passing the  151 Artificial Creativity Turing test, to be judged at an annual competition. Until the test is  passed, a lesser prize is awarded each year for the entry judged to be  closest to passing. The test is harder to implement than it may seem at  first. One issue is that requiring the program to  pretend  to be human  is both biased and not very relevant to whether it can think .  Yet, if it  does not pretend to be human, it will be easy to identify as a computer  regardless of its ability to think. A related difficulty is that the human  participant in the test might intentionally imitate a chatbot – as in the  Hofstadter hoax – and so spoil the test, which is based on comparing  the two. Should the rules nevertheless allow the human to do this, in  order to mitigate the previous problem?  Unfortunately, such subtleties are not relevant at the current state  of the art. This is well illustrated by the following excerpts from the  conversation with which the program  Elbot  won the (lesser) Loebner  prize in 2008: judge :   do you understand the point of a turing test? elbot :   There are some people who would not pass the Turing  test themselves. Why must they inflict it on  computers? judge :  I spose it is a little harsh elbot :   If we======================================================== not. When  wondering leads to conjecture, that constitutes  speculation , which is  not irrational either. In fact it is vital. Every one of those deeply un    - foreseeable new ideas that make the future unpredictable will begin as  a speculation. And every speculation begins with a problem:  problems  in regard to the future can reach beyond the horizon of prediction too  – and problems have solutions. In regard to understanding the physical world, we are in much the  same position as Eratosthenes was in regard to the Earth: he could  measure it remarkably accurately, and he knew a great deal about  certain aspects of it – immensely more than his ancestors had known  only a few centuries before. He must have known about such things  as seasons in regions of the Earth about which he had no evidence. But  he also  knew  that most of what was out there was far beyond his  theoretical knowledge as well as his physical reach. We cannot yet measure the universe as accurately as Eratosthenes  measured the Earth. And we, too,  know  how ignorant we are. For  instance, we know from universality that AI is attainable by writing  computer programs, but we have no idea how to write (or evolve) the  right one. We do not know what qualia are or how creativity works,  despite having working examples of qualia and creativity inside all of  us. We learned the genetic code decades ago, but have no idea why it  has the reach that it has. We know that both of the deepest prevailing  theories in physics must be false. We know that  people  are of funda- mental significance, but we do not know whether we are among those  people: we may fail, or give up, and intelligences originating elsewhere  in the universe may be the beginning of infinity. And so on for all the  problems I have mentioned and many more.  Wheeler once imagined writing out all the equations that might be  the ultimate laws of physics on sheets of paper all over the floor. And  then: 459 The Beginning Stand up, look back on all those equations, some perhaps more hopeful  than others, raise one’s finger commandingly, and give the order ‘Fly!’  Not one of those equations will put on wings, take off, or fly. Yet the  universe ‘flies’. C. W. Misner, K. S. Thorne and J. A.Wheeler,  Gravitation  (1973) We do not know why it ‘flies’. What is the difference between laws    that are instantiated in physical reality and those that are not? What  is the difference between a computer simulation of a person (which  must  be  a person, because of universality) and a recording of that  simulation (which cannot be a person)? When there are two identical  simulations under way, are there two sets of qualia or one? Double    the moral value or not?  Our world, which is so much larger, more unified, more intricate and  more beautiful than that of Eratosthenes, and which we understand  and control to an extent that would have seemed godlike to him, is  nevertheless just as mysterious, yet open, to us now as his was to him  then. We have lit only a few candles here and there. We can cower in  their parochial light until something beyond our ken snuffs us out, or  we can resist. We already see that we do not live in a senseless world.  The laws of physics make sense: the world is explicable. There are higher  levels of emergence and higher levels of explanation. Profound abstrac- tions in mathematics, morality and aesthetics are accessible to us. Ideas  of tremendous reach are possible. But there is also plenty in the world  that does not and will not make sense until we ourselves work out    how to rectify it. Death does not make sense. Stagnation does not    make sense. A bubble of sense within endless senselessness does    not make sense. Whether the world ultimately does make sense will  depend on how  people  – the likes of us – chose to think and to act. Many people have an aversion to infinity of various kinds. But there  are some things that we do not have a choice about. There is only one  way of thinking that is capable of making progress, or of surviving in  the long run, and that is the way of seeking good explanations through  creativity and criticism. What lies ahead of us is in any case infinity.  All we can choose is whether it is an infinity of ignorance or of  knowledge, wrong or right, death or life. 460 Bibliography Everyone should read these Jacob Bronowski,  The Ascent of Man  (BBC Publications, 1973) Jacob Bronowski,  Science and Human Values  (Harper & Row, 1956) Richard Byrne, ‘Imitation as Behaviour Parsing’,  Philosophical Trans- actions of the Royal Society  B358 (2003) Richard Dawkins,  The Selfish Gene  (Oxford University Press, 1976) David Deutsch, ‘Comment on Michael Lockwood, “‘Many Minds’  Interpretations of Quantum Mechanics”’,  British Journal for the  Philosophy of Science  47, 2 (1996) David Deutsch,  The Fabric of Reality  (Allen Lane, 1997) Karl Popper,  Conjectures and Refutations  (Routledge, 1963) Karl Popper,  The Open Society and Its======================================================== creativity  7–8 letting them die in our place  see under   Popper mistake of separating prediction from  explanation  315–16, 326 needed to build and operate  instruments  40 theory-laden observation  10,  30 ,  38–41, 165, 199 see also  explanations; testability thermodynamics, second law of  110,  111 Thucydides  216 tides  143 tidal forces  3, 450 time  298–9 see also  spacetime Tipler, Frank  178–9, 450–51 Titanic   201 tolerance  23, 121, 217, 250, 343 tools  12, 50, 92, 154, 381, 383, 384,  399–400 trade  131, 217, 234, 419, 427, 428, 436 tradition of criticism   13 , 23, 31–3, 209,  216, 220, 231, 308, 390, 431 transmutation  1, 2, 3, 11, 13–14, 40, 58,  61, 67, 71, 84, 97, 203, 266, 425 trees  see  forests trial and error  36, 160, 392, 399, 400,  408, 411–12 triangles  119, 183–4, 188, 233 truth convergence upon  231, 257, 350, 368 and beauty  355  mathematical  183, 185, 186, 188,  189 necessary truths  183 random truths  189 Turing, Alan  138, 139, 148, 152–3,  154–5, 156, 184, 187, 461 Turing test  148, 149–50, 151, 152–3,  154–6, 158, 161, 320 tyranny  66, 200, 209, 211, 214, 337,  343, 431, 445, 447 Uglow, Jenny:  The Lunar Men   66 uncertainty principle  289, 291,  303–4 undecidable questions/statements  185,  186, 187, 191, 192, 195 universality universal explainers  123, 157, 415 and AI  157 computational  135–42, 148, 189,   191 and the Enlightenment  133–4 and infinity  164–5 the jump to  125–47,  146 , 414; in  computers  135–42; in the genetic  code  142–6, 162–3, 458; necessity  of digital systems for  139–42; and  error correction  147; in numerals  and arithmetic  128–33; in printing   134; unintended   127 , 129, 131,  133, 134, 135, 136, 139, 147; in  writing systems  125–7 of the laws of nature vii, 6, 32, 54, 56,  75, 191, 192 prediction, the brain and  189 of reason  166 universal constructors   76 , 145; DNA  as  142–6, 162–3, 458; humans as   58–60, 62, 429 universe in an astronomer’s view  1–3 distinguished from ‘world’,  ‘multiverse’ and ‘history’ 265 initial expansion rate  96–7 initial state  118  ‘omega-point universes’  450–51 recollapsing  450–51 unknowability  103, 190, 197, 198, 199,  204, 208, 214, 215, 221–2, 358 487 index see also  undecidable; unpredictability;  optimism unpredictability of knowledge growth  104, 133, 193,  194,  197 , 198, 199, 206, 212, 358,  387–8, 425, 438, 439, 440, 457, 458 of new art  358 of qualia  153–4, 268, 367 due to randomness  197 reasons for  269–70 due to the ‘Singularity’ 456 unsustainability  422, 441 uranium  13, 145, 436 utilitarianism  122 utopias  65 blind optimism of revolutionary  utopians  210 utopian (Continental) Enlightenment   65–6 see also  Golden Age myths vacuum  39, 46, 47, 53, 62, 267 variation and selection  Veblen, Thorstein  433 Vinge, Vernor  456 virtual reality  7, 68, 119, 190, 241n,  455 and the simulation argument  453–5 vitamin C  57, 80, 88 volcanoes  143, 292 super-volcano  208 von Neumann, John  334, 335 voting  216, 234, 328 decision-making in  342, 344–5 plurality voting system  346–50, 352 proportional representation  326–33,  339, 346, 347–8 women’s right to vote  351 see also  representative government wars/warfare  20, 109, 110, 139, 148,  196, 205, 206, 218, 244, 245,  246–7, 248, 249, 250, 251, 259,  294, 303, 334, 380, 390, 418, 427,  428, 431, 457 see also  World War II; Cold War Washington, George  326, 330 waves of differentiation  273–4, 275, 276,  278–9, 283–5, 295, 297–8, 303 and particles  291 and the Schrödinger equation  307 wealth   202 , 204, 208, 213, 217, 219,  221, 249, 424, 428, 437, 438, 442,  444–5, 456 weapons  50, 196, 208, 400 biological  196, 204, 205 civilization-destroying  196, 204, 208 nuclear  139, 196, 205 weather  20, 207 forecasting  27, 96, 139 Webster, Daniel  330, 343–4 ‘weighing’ metaphor in decision-making   340–42 Weizenbaum, Joseph  148–9 ‘what is it like to be a’ (Nagel) bat  367 dollar  268 West, the  23,  31 , 121, 214, 254, 313–14,  335, 350, 351, 386, 387, 390, 391,  393, 397, 428, 431, 442 Wheeler, John Archibald  1, 26, 104,  353, 354, 458–9 ‘who should rule’  see  Popper, Karl:  criterion of ridding ourselves of bad  governments without violence Wigner, Eugene  189, 308 paradox of Wigner’s friend  308 will of the people  335, 336, 337–8, 350 Wittgenstein, Ludwig  166, 313, 314 wizards  260 Wolfe, Art  56–7 Wooters, William  299 world, distinguished from ‘universe’,  ‘multiverse’ and ‘history’ 265 World War II  109, 139, 205, 334 computers of  140, 148 in  Fatherland   259 writing systems 125–7 X-rays  2, 68 Xenophanes of Colophon  216–17, 227,  230, 231, 238, 242 Xenophon  83–4, 216 Young, Peyton  334 Balinski and Young’s theorem  334, 339 Zeno of Elea  182–3 Zeno’s mistake (confusing abstract  attributes with physical ones of the  same name)  182–6, 343 Zuse, Konrad  139 Zweig, Stefan  205======================================================== humans (whether in the cosmic scheme of things or according to any  rational human criterion) is our ability to create new explanations, and  we have that in common with all people. You do not become less of a  person if you lose a limb in an accident; it is only if you lose your brain  that you do. Changing our genes in order to improve our lives and    to facilitate further improvements is no different in this regard from  augment  ing our skin with clothes or our eyes with telescopes.  60 the beginning of infinity One might wonder whether the reach of people in general might be  greater than the reach of humans. What if, for instance, the reach    of technology is indeed unlimited, but only to creatures with two  opposable thumbs on each hand; or if the reach of scientific knowledge  is unlimited, but only to beings whose brains are twice the size of ours?  But our faculty of being universal constructors makes these issues as  irrelevant as that of access to vitamins. If progress at some point were  to depend on having two thumbs per hand, then the outcome would  depend not on the knowledge we inherit in our genes, but on whether  we could discover how to build robots, or gloves, with two thumbs  per hand, or alter ourselves to have a second thumb. If it depends on  having more memory capacity, or speed, than a human brain, then the  outcome would depend on whether we could build computers to do  the job. Again, such things are already commonplace in technology.  The astrophysicist Martin Rees has speculated that somewhere in  the universe ‘there could be life and intelligence out there in forms we  can’t conceive. Just as a chimpanzee can’t understand quantum theory,  it could be there are aspects of reality that are beyond the capacity of  our brains.’ But that cannot be so. For if the ‘capacity’ in question    is mere computational speed and amount of memory, then we can  understand the aspects in question with the help of computers – just  as we have understood the world for centuries with the help of pencil  and paper. As Einstein remarked, ‘My pencil and I are more clever than  I.’ In terms of computational repertoire, our computers – and brains  – are already universal (see Chapter 6). But if the claim is that we    may be  qualitatively  unable to understand what some other forms of  intelligence can – if our disability cannot be remedied by mere auto- mation – then this is just another claim that the world is not explicable.  Indeed, it is tantamount to an appeal to the supernatural, with all the  arbitrariness that is inherent in such appeals, for if we wanted to  incorporate into our world view an imaginary realm explicable only  to superhumans, we need never have bothered to abandon the myths  of Persephone and her fellow deities.  So human reach is essentially the same as the reach of explanatory  knowledge itself. An environment is within human reach if it is possible  to create an open-ended stream of explanatory knowledge there. That  means that if knowledge of a suitable kind were instantiated in such  61 The Spark an environment in suitable physical objects, it would cause itself to  survive and would then continue to increase indefinitely. Can there  really be such an environment? This is essentially the question that I  asked at the end of the last chapter –  can this creativity continue  indefinitely?  – and it is the question to which the Spaceship Earth  metaphor assumes a negative answer.  The issue comes down to this: if such an environment can exist, what  are the minimal physical features that it must have? Access to  matter  is  one. For example, the trick of extracting oxygen from moon rocks  depends on having compounds of oxygen available. With more advanced  technology, one could manufacture oxygen by transmutation; but, no  matter how advanced one’s technology is, one still needs raw materials  of some sort. And, although mass can be recycled, creating an open-ended  stream of knowledge depends on having an ongoing supply of it, both  to make up for inevitable inefficiencies and to make the additional  memory capacity to store new knowledge as it is created.  Also, many of the necessary transformations require  energy : some- thing must power conjectures and scientific experiments and all those  manufacturing processes; and, again, the laws of physics forbid the  creation of energy from nothing. So access to an energy supply is also  a necessity. To some extent, energy and mass can be transformed    into each other. For instance, transmuting hydrogen into any other  element releases energy through nuclear fusion. Energy can also be  converted into mass by various subatomic processes (but I cannot  imagine naturally occurring circumstances in which those would be  the best way of obtaining matter).  In addition to matter and energy, there is one other essential require- ment, namely  evidence : the information needed to test scientific theories.  The Earth’s surface is rich======================================================== success. A pessimistic civil- ization considers it immoral to behave in ways that have not been tried  many times before, because it is blind to the possibility that the benefits  of doing so might offset the risks. So it is intolerant and conformist.  But Athens took the opposite view. Pericles also contrasted his city’s  openness to foreign visitors with the closed, defensive attitude of rival  cities: again, he expected that Athens would benefit from contact with  new, unforeseeable ideas, even though, as he acknowledged, this policy  gave enemy spies access to the city too. He even seems to have regarded  the lenient treatment of children as a source of military strength: In education, where our rivals from their very cradles by a painful  discipline seek after manliness, in Athens we live exactly as we please,  and yet are just as ready to encounter every legitimate danger. 218 the beginning of infinity A pessimistic civilization prides itself on its children’s conformity to  the proper patterns of behaviour, and bemoans every real or imagined  novelty. Sparta was, in all the above respects, the opposite of Athens. The  epitome of a pessimistic civilization, it was notorious for its citizens’  austere ‘spartan’ lifestyle, for the harshness of its educational system,  and for the total militarization of its society. Every male citizen was a  full-time soldier, owing absolute obedience to his superiors, who were  themselves obliged to follow religious tradition. All other work was  done by slaves: Sparta had reduced an entire neighbouring society,    the Messenians, to the status of helots (a kind of serf or slave). It    had no philosophers, historians, artists, architects, writers – or other  knowledge-creating people of any kind apart from the occasional  talented general. Thus almost the entire effort of the society was  devoted to preserving itself in its existing state – in other words, to  preventing improvement. In 404 bce, twenty-seven years after Pericles’  funeral oration, Sparta decisively defeated Athens in war and imposed  an authoritarian form of government on it. Although, through the  vagaries of international politics, Athens became independent and  democratic again soon afterwards, and continued for several gener- ations to produce art, literature and philosophy, it was never again  host to rapid, open-ended progress. It became unexceptional. Why? I  guess that its optimism was gone. Another short-lived enlightenment happened in the Italian city-state  of Florence in the fourteenth century. This was the time of the early  Renaissance, a cultural movement that revived the literature, art and  science of ancient Greece and Rome after more than a millennium of  intellectual stagnation in Europe. It became an  enlightenment  when  the Florentines began to believe that they could improve upon that  ancient knowledge. This era of dazzling innovation, known as the  Golden Age of Florence, was deliberately fostered by the Medici family,  who were in effect the city’s rulers – especially Lorenzo de’ Medici,  known as ‘the Magnificent’, who was in charge from 1469 to 1492.  Unlike Pericles, the Medici were not devotees of democracy: Florence’s  enlightenment began not in politics but in art, and then philosophy,  science and technology, and in those fields it involved the same openness  to criticism and desire for innovation both in ideas and in action.  219 Optimism Artists, instead of being restricted to traditional themes and styles,  became free to depict what they considered beautiful, and to invent  new styles. Encouraged by the Medici, the wealthy of Florence competed  with each other in the innovativeness of the artists and scholars    whom they sponsored – such as Leonardo da Vinci, Michelangelo and  Botticelli. Another denizen of Florence at this time was Niccolò  Machiavelli, the first secular political philosopher since antiquity.  The Medici were soon promoting the new philosophy of ‘humanism’,  which valued knowledge above dogma, and virtues such as intellectual  independence, curiosity, good taste and friendship over piety and  humility. They sent agents all over the known world to obtain copies  of ancient books, many of which had not been seen in the West since  the fall of the Western Roman Empire. The Medici library made copies  which it supplied to scholars in Florence and elsewhere. Florence  became a powerhouse of newly revived ideas, new interpretations of  ideas, and brand-new ideas. But that rapid progress lasted for only a generation or so. A  charismatic monk, Girolamo Savonarola, began to preach apocalyptic  sermons against humanism and every other aspect of the Florentine  enlightenment. Urging a return to medieval conformism and self-denial,  he proclaimed prophecies of doom if Florence continued on its path.  Many citizens were persuaded, and in 1494 Savonarola managed    to seize power. He reimposed all the traditional restrictions on art,  literature, thought and======================================================== found in the current user’s input. Weizenbaum was shocked that many people using  Eliza  were fooled  by it. So it had passed the Turing test – at least, in its most naive version.  Moreover, even after people had been told that it was not a genuine  AI, they would sometimes continue to have long conversations with it  about their personal problems, exactly as though they believed that it  understood them. Weizenbaum wrote a book,  Computer Power and  Human Reason  (1976), warning of the dangers of anthropomorphism  when computers seem to exhibit human-like functionality. However, anthropomorphism is not the main type of overconfidence  that has beset the field of AI. For example, in 1983 Douglas Hofstadter  was subjected to a friendly hoax by some graduate students. They  convinced him that they had obtained access to a government-run AI  program, and invited him to apply the Turing test to it. In reality, one  of the students was at the other end of the line, imitating an  Eliza  program. As Hofstadter relates in his book  Metamagical Themas   (1985), the student was from the outset displaying an implausible  degree of understanding of Hofstadter’s questions. For example, an  early exchange was: 150 the beginning of infinity hofstadter : What are ears? student : Ears are auditory organs found on animals. That is not a dictionary definition. So  something  must have processed  the meaning of the word ‘ears’ in a way that distinguished it from most  other nouns. Any one such exchange is easily explained as being due  to luck: the question must have matched one of the templates that the  programmer had provided, including customized information about  ears. But after half a dozen exchanges on different subjects, phrased  in different ways, such luck becomes a very bad explanation and the  game should have been up. But it was not. So the student became ever  bolder in his replies, until eventually he was making jokes directed  specifically at Hofstadter – which gave him away. As Hofstadter remarked, ‘In retrospect, I am quite amazed at how  much genuine intelligence I was willing to accept as somehow having  been implanted in the program . . . It is clear that I was willing to accept  a huge amount of fluidity as achievable in this day and age simply by  putting together a large bag of isolated tricks, kludges and hacks.’ The  fact was (and this alone should have alerted Hofstadter) that, nineteen  years after  Eliza , not one of the  Eliza -like programs of the day resembled  a person even slightly more than the original had. Although they were  able to parse sentences better, and had more pre-programmed templates  for questions and answers, that is almost no help in an extended  conversation on diverse subjects. The probability that the outputs of  such templates will continue to resemble the products of human  thought diminishes exponentially with the number of utterances. So  Hofstadter should have been able to pronounce quite soon that the  candidate had passed the Turing test – and that, because it nevertheless  sounded rather like  Eliza , it must be a person pretending to be a  computer program. Programs written today – a further twenty-six years later – are still  no better at the task of seeming to think than  Eliza  was. They are now  known as ‘chatbots’, and their main application is still amusement, both  directly and in computer games. They have also been used to pro            vide  friendly seeming interfaces to lists of ‘frequently asked questions’ about  subjects like how to operate computers. But I think that users find them  no more helpful than a searchable list of the questions and answers. In 1990 the inventor Hugh Loebner endowed a prize for passing the  151 Artificial Creativity Turing test, to be judged at an annual competition. Until the test is  passed, a lesser prize is awarded each year for the entry judged to be  closest to passing. The test is harder to implement than it may seem at  first. One issue is that requiring the program to  pretend  to be human  is both biased and not very relevant to whether it can think .  Yet, if it  does not pretend to be human, it will be easy to identify as a computer  regardless of its ability to think. A related difficulty is that the human  participant in the test might intentionally imitate a chatbot – as in the  Hofstadter hoax – and so spoil the test, which is based on comparing  the two. Should the rules nevertheless allow the human to do this, in  order to mitigate the previous problem?  Unfortunately, such subtleties are not relevant at the current state  of the art. This is well illustrated by the following excerpts from the  conversation with which the program  Elbot  won the (lesser) Loebner  prize in 2008: judge :   do you understand the point of a turing test? elbot :   There are some people who would not pass the Turing  test themselves. Why must they inflict it on  computers? judge :  I spose it is a little harsh elbot :   If we======================================================== robots ever had marriages they would be  eternal: ‘Till rust do us part’. In that passage,  Elbot ’s first utterance is not a reply to the question but  presumably a stock response triggered by the keywords ‘Turing test’.  In the following line, the judge uses the word ‘spose’, which in that  context can only mean ‘suppose’ (either as slang or as a typographical  error). But  Elbot  presumably interprets it as ‘spouse’, and responds  with a stock joke about marriage. Hence, even from this exchange  alone, it is clear that  Elbot  was not processing the  meanings  of the  judge’s sentences.  judge:   so what do you do when you’re not chatting to me  then? elbot:   I have the same trouble when I shop for oil. Should  I buy the extra oily, the super oily, or the ultra  oily. There’s no way to tell. judge:   how about your career? does that involve oil? 152 the beginning of infinity elbot:   Well what about humans and occupation? Where do  they stand on this? When the judge helpfully took up  Elbot ’s randomly introduced theme  of oil,  Elbot  ignored it. Instead, having detected the keyword ‘career’,  it converted it to the synonym ‘occupation’ and inserted it into a stock  sentence pattern. This is how much success the quest for ‘machines that think’ had  achieved in the  fifty-eight   years  following Turing’s paper: nil. Yet,  in every other respect, computer science and technology had made  astounding progress during that period. The dwindling group of op    - ponents of the very possibility of AI are no doubt unsurprised by this  failure – for the wrong reason: they do not appreciate the significance  of universality. But the most passionate  enthusiasts  for the imminence  of AI do not appreciate the significance of the failure. Some claim that  the above criticism is unfair: modern AI research is not focused on  passing the Turing test, and great progress has been made in what is  now called ‘AI’ in many specialized applications. However, none of  those applications look like ‘machines that think’.* Others maintain  that the criticism is premature, because, during most of the history of  the field, computers had absurdly little speed and memory capacity  compared with today’s. Hence they continue to expect the breakthrough  in the next few years.  This will not do either. It is not as though someone has written a  chatbot that could pass the Turing test but would currently take a year  to compute each reply. People would gladly wait. And in any case, if  anyone knew how to write such a program, there would be no need  to wait – for reasons that I shall get to shortly. In his 1950 paper, Turing estimated that, to pass his test, an AI  program together with all its data would require no more than about  100 megabytes of memory, that the computer would need to be no  faster than computers were at the time (about ten thousand operations  per second), and that by the year 2000 ‘one will be able to speak of  machines thinking without expecting to be contradicted.’ Well, the  year 2000 has come and gone, the laptop computer on which I am  writing this book has over a thousand times as much memory as Turing  * Hence what I am calling ‘AI’ is sometimes called ‘AGI’: Artificial  General  Intelligence. 153 Artificial Creativity specified (counting hard-drive space), and about a million times the  speed (though it is not clear from his paper what account he was taking  of the brain’s parallel processing). But it can no more think than  Turing’s slide rule could. I am just as sure as Turing was that it  could  be programmed to think; and this might indeed require as few re-  sources as Turing estimated, even though orders of magnitude more  are available today. But with what program? And why is there no sign  of such a program? Intelligence in the general-purpose sense that Turing meant is one of  a constellation of attributes of the human mind that have been puzzling  philosophers for millennia; others include consciousness, free will, and  meaning. A typical such puzzle is that of  qualia  (singular  quale , which  rhymes with ‘baa-lay’) – meaning the subjective aspect of sensations.  So for instance the sensation of seeing the colour blue is a quale.  Consider the following thought experiment. You are a biochemist with  the misfortune to have been born with a genetic defect that disables  the blue receptors in your retinas. Consequently you have a form of  colour blindness in which you are able to see only red and green, and  mixtures of the two such as yellow, but anything purely blue also looks  to you like one of those mixtures. Then you discover a cure that will  cause your blue receptors to start working. Before administering the  cure to yourself, you can confidently make certain predictions about  what will happen if it works. One of them is that, when you hold up  a blue card as a test, you will see a colour that you have never seen  before. You can predict that you will call it ‘blue’, because you======================================================== analogue of a species, or of an organism, or a cell, or of sexual or  asexual reproduction. Genes and memes are about as different as can  be at the level of mechanisms, and of outcomes; they are similar only  at the lowest level of explanation, where they are both  replicators  that  embody  knowledge  and are therefore conditioned by the same funda- mental principles that determine the conditions under which knowledge  can or cannot be preserved, can or cannot improve.  Meme evolution In the classic 1956 science-fiction story ‘Jokester’, by Isaac Asimov, the  main character is a scientist studying jokes. He finds that, although most  people do sometimes make witty remarks that are original, they never  invent what he considers to be a fully fledged joke: a story with a plot  and a punchline that causes listeners to laugh. Whenever they tell such  a joke, they are merely repeating one that they have heard from someone  else. So, where do jokes come from originally? Who creates them? The  fictional answer given in ‘Jokester’ is far-fetched and need not concern  us here. But the premise of the story is not so absurd: it really is plausible  that some jokes were not created by anyone – that they evolved.  People tell each other amusing stories – some fictional, some factual.  They are not jokes, but some become memes: they are interesting  enough for the listeners to retell them to other people, and some of  those people retell them in turn. But they rarely recite them word for  word; nor do they preserve every detail of the content. Hence an often- retold story will come to exist in different versions. Some of those  versions will be retold more often than others – in some cases because  people find them amusing. When that is the main reason for retelling  them, successive versions that remain in circulation will tend to be    ever more amusing. So the conditions are there for evolution: repeated  cycles of imperfect copying of information, alternating with selection.  Eventually the story becomes amusing enough to make people laugh,  and a fully fledged joke has evolved.  373 The Evolution of Culture It is conceivable that a joke could evolve through variations that  were not intended to improve upon the funniness. For example, people  who hear a story can mishear or misunderstand aspects of it, or change  it for pragmatic reasons, and in a small proportion of cases, by sheer  luck, that will produce a funnier version of the story, which will then  propagate better. If a joke has evolved in that way from a non-joke, it  truly has no author. Another possibility is that most of the people who  altered the amusing story on its way to becoming a joke  designed  their  contributions, using creativity to make it funnier intentionally. In such  cases, although the joke was indeed created by variation and selection,  its funniness was the result of human creativity. In that case it would  be misleading to say that ‘no one created it.’ It had many co-authors,  each of whom contributed creative thought to the outcome. But it may  still be that literally no one understands why the joke is as funny as it  is, and hence that no one could create another joke of similar quality  at will. Although we do not know exactly how creativity works, we do  know that it is itself an evolutionary process within individual brains.  For it depends on conjecture (which is variation) and criticism (for the  purpose of selecting ideas). So, somewhere inside brains, blind vari    - ations and selections are adding up to creative thought at a higher level  of emergence. The idea of memes has come in for a great deal of radical, and in  my view mistaken, criticism to the effect that it is vague and pointless,  or else tendentious. For example, when the ancient Greek religion was  suppressed, but the stories of its gods continued to be told, though  now only as fiction, were those stories still the same memes despite  now causing new behaviours? When Newton’s laws were translated  into English from the original Latin, they caused different words to be  spoken and written. Were they the same memes? But in fact such  questions cast no doubt on the existence of memes, nor on the useful- ness of the concept. It is like the controversy about which objects in  the solar system should be called ‘planets’. Is Pluto a ‘real’ planet even  though it is smaller than some of the moons in our solar system? Is  Jupiter really not a planet but an un-ignited star? It is not important.  What is important is what is really there. And memes are really there,  regardless of what we call them or how we classify them. Just as the  374 the beginning of infinity basic theory of genes was developed long before the discovery of DNA,  so today, without knowing  how  ideas are stored in brains, we do know  that some ideas can be passed from one person to another and affect  people’s behaviour. Memes are those ideas.  Another line of criticism is that memes, unlike======================================================== what it would have taken for scientists to forecast, say,  carbon-dioxide emissions for the twentieth century. On the (shaky)  assumption that energy use would continue to increase by roughly  the same ex      ponential factor as before, they could have estimated the  resulting increase in emissions. But that estimate would not have  included the effects of nuclear power. It could not have, because  radioactivity itself had only just been discovered, and would not be  harnessed for power until the middle of the century. But suppose that  somehow they had been able to foresee that. Then they might have  modified their carbon-dioxide forecast, and concluded that emissions  could easily be restored to below the 1902 level by the end of the  century. But, again, that would only be because they could not possibly  foresee the campaign against nuclear power, which would put a stop  to its expansion (iron  ically, on environmental grounds) before it ever  became a significant factor in reducing emissions. And so on. Time  and again, the un      predictable factor of new human ideas, both good  and bad, would make the scientific prediction useless. The same is  bound to be true – even more so – of forecasts today for the coming  century. Which brings me to my third observation about the current  controversy. It is not yet accurately known how sensitive the atmosphere’s  tem    pera    ture is to the concentration of carbon dioxide – that is, how  much a given increase in concentration increases the temperature.  This number is important politically, because it affects how urgent  the problem is: high sensitivity means high urgency; low sensitivity  means the opposite. Unfortunately, this has led to the political debate  being dominated by the side issue of how ‘anthropogenic’ (human- caused) the increase in temperature to date has been. It is as if people  were arguing about how best to prepare for the next hurricane while  all agreeing that the only hurricanes one should prepare for are  human-induced ones. All sides seem to assume that if it turns out  that a  random  fluctuation in the temperature is about to raise sea  440 the beginning of infinity levels, disrupt agriculture, wipe out species and so on, our best plan  would be simply to grin and bear it. Or if two-thirds of the increase  is anthropogenic, we should not mitigate the effects of the other  third. Trying to predict what our net effect on the environment will be for  the next century and then subordinating all policy decisions to optim- izing that prediction cannot work. We cannot know how much to  reduce emissions by, nor how much effect that will have, because we  cannot know the future discoveries that will make some of our present  actions seem wise, some counter-productive and some irrelevant, nor  how much our efforts are going to be assisted or impeded by sheer  luck. Tactics to delay the onset of foreseeable problems may help. But  they cannot replace, and must be subordinate to, increasing our ability  to intervene  after  events turn out as we did not foresee. If that does  not happen in regard to carbon-dioxide-induced warming, it will  happen with something else. Indeed, we did not foresee the global-warming disaster. I call it a  disaster because the prevailing theory is that our best option is to  prevent carbon-dioxide emissions by spending vast sums and enforcing  severe worldwide restrictions on behaviour, and that is already a  disaster by any reasonable measure. I call it unforeseen because we  now realize that it was already under way even in 1971, when I attended  that lecture. Ehrlich did tell us that agriculture was soon going to be  devastated by rapid climate change. But the change in question was  going to be global  cooling , caused by smog and the condensation trails  of supersonic aircraft. The possibility of warming caused by gas emis- sions had already been mooted by some scientists, but Ehrlich did not  consider it worth mentioning. He told us that the evidence was that a  general cooling trend had already begun, and that it would continue  with catastrophic effects, though it would be reversed in the very long  term because of ‘heat pollution’ from industry (an effect that is currently  at least a hundred times smaller than the global warming that pre  - occupies us). There is a saying that an ounce of prevention equals a pound of cure.  But that is only when one knows what to prevent. No precautions can  avoid problems that we do not yet foresee. To prepare for those, there  is nothing we can do but increase our ability to put things right if they  441 Unsustainable go wrong. Trying to rely on the sheer good luck of avoiding bad  outcomes indefinitely would simply guarantee that we would eventually  fail without the means of recovering. The world is currently buzzing with plans to force reductions in gas  emissions at almost any cost. But it ought to be buzzing much more  with plans to reduce the temperature, or======================================================== for how to thrive at a higher  temperature. And not at all costs, but efficiently and cheaply. Some  such plans exist – for instance to remove carbon dioxide from the  atmosphere by a variety of methods; and to generate clouds over the  oceans to reflect sunlight; and to encourage aquatic organisms to  absorb more carbon dioxide. But at the moment these are very minor  research efforts. Neither supercomputers nor international treaties nor  vast sums are devoted to them. They are not central to the human  effort to face this problem, or problems like it.  This is dangerous. There is as yet no serious sign of retreat into a  sustainable lifestyle (which would really mean achieving only the  semblance  of sustainability), but even the aspiration is dangerous.  For what would we be aspiring to? To forcing the future world into  our image, endlessly reproducing our lifestyle, our misconceptions  and our mistakes. But if we choose instead to embark on an open- ended journey of creation and exploration whose every step is un  -  sustainable until it is redeemed by the next – if this becomes the  prevailing ethic and aspiration of our society – then the ascent of  man, the beginning of infinity, will have become, if not secure, then  at least sustainable.  terminology The ascent of man  The beginning of infinity. Moreover, Jacob  Bronowski’s  The Ascent of Man  was one of the inspirations for this  book. Sustain   The term has two almost opposite, but often confused,  meanings: to provide someone with what they need, and to prevent  things from changing. 442 the beginning of infinity meanings of ‘the beginning of infinity’  encountered in this chapter – Rejecting (the semblance of) sustainability as an aspiration or a  constraint on planning. summary Static societies eventually fail because their characteristic inability to  create knowledge rapidly must eventually turn some problem into a  catastrophe. Analogies between such societies and the technological  civilization of the West today are therefore fallacies. Marx, Engels and  Diamond’s ‘ultimate explanation’ of the different histories of different  societies is false: history is the history of ideas, not of the mechanical  effects of biogeography. Strategies to prevent foreseeable disasters are  bound to fail eventually, and cannot even address the unforeseeable.  To prepare for those, we need rapid progress in science and technology  and as much wealth as possible. 443 18 The Beginning ‘This is Earth. Not the eternal and only home of mankind, but  only a starting point of an infinite adventure. All you need do  is make the decision [to end your static society]. It is yours  to make.’ [With that decision] came the end, the final end of Eternity.  – And the beginning of Infinity. Isaac Asimov,  The End of Eternity  (1955) The first person to measure the circumference of the Earth was the  astronomer Eratosthenes of Cyrene, in the third century  bce.  His result  was fairly close to the actual value, which is about 40,000 kilometres.  For most of history this was considered an enormous distance, but with  the Enlightenment that conception gradually changed, and nowadays  we think of the Earth as small. That was brought about mainly by two  things: first, by the science of astronomy, which discovered titanic  entities compared with which our planet is indeed unimaginably tiny;  and, second, by technologies that have made worldwide travel and  communication commonplace. So the Earth has become smaller both  relative to the universe and relative to the scale of human action.  Thus, in regard to the  geography  of the universe and to our place in  it, the prevailing world view has rid itself of some parochial mis  - conceptions. We know that we have explored almost the whole surface  of that formerly enormous sphere; but we also know that there are far  more places left to explore in the universe (and beneath the surface of  the Earth’s land and oceans) than anyone imagined while we still had  those misconceptions.  444 the beginning of infinity In regard to theoretical knowledge, however, the prevailing world  view has not yet caught up with Enlightenment values. Thanks to the  fallacy and bias of prophecy, a persistent assumption remains that our  existing theories are at or fairly close to the limit of what it is knowable  – that we are  nearly there ,   or perhaps halfway there. As the economist  David Friedman has remarked, most people believe that an income of  about twice their own should be sufficient to satisfy any reasonable  person, and that no genuine benefit can be derived from amounts above  that. As with wealth, so with scientific knowledge: it is hard to imagine  what it would be like to know twice as much as we do, and so if we  try to prophesy it we find ourselves just picturing the next few decimal  places of what we already know. Even Feynman made an uncharacter- istic mistake in this regard when he wrote: I think there will certainly not be======================================================== for how to thrive at a higher  temperature. And not at all costs, but efficiently and cheaply. Some  such plans exist – for instance to remove carbon dioxide from the  atmosphere by a variety of methods; and to generate clouds over the  oceans to reflect sunlight; and to encourage aquatic organisms to  absorb more carbon dioxide. But at the moment these are very minor  research efforts. Neither supercomputers nor international treaties nor  vast sums are devoted to them. They are not central to the human  effort to face this problem, or problems like it.  This is dangerous. There is as yet no serious sign of retreat into a  sustainable lifestyle (which would really mean achieving only the  semblance  of sustainability), but even the aspiration is dangerous.  For what would we be aspiring to? To forcing the future world into  our image, endlessly reproducing our lifestyle, our misconceptions  and our mistakes. But if we choose instead to embark on an open- ended journey of creation and exploration whose every step is un  -  sustainable until it is redeemed by the next – if this becomes the  prevailing ethic and aspiration of our society – then the ascent of  man, the beginning of infinity, will have become, if not secure, then  at least sustainable.  terminology The ascent of man  The beginning of infinity. Moreover, Jacob  Bronowski’s  The Ascent of Man  was one of the inspirations for this  book. Sustain   The term has two almost opposite, but often confused,  meanings: to provide someone with what they need, and to prevent  things from changing. 442 the beginning of infinity meanings of ‘the beginning of infinity’  encountered in this chapter – Rejecting (the semblance of) sustainability as an aspiration or a  constraint on planning. summary Static societies eventually fail because their characteristic inability to  create knowledge rapidly must eventually turn some problem into a  catastrophe. Analogies between such societies and the technological  civilization of the West today are therefore fallacies. Marx, Engels and  Diamond’s ‘ultimate explanation’ of the different histories of different  societies is false: history is the history of ideas, not of the mechanical  effects of biogeography. Strategies to prevent foreseeable disasters are  bound to fail eventually, and cannot even address the unforeseeable.  To prepare for those, we need rapid progress in science and technology  and as much wealth as possible. 443 18 The Beginning ‘This is Earth. Not the eternal and only home of mankind, but  only a starting point of an infinite adventure. All you need do  is make the decision [to end your static society]. It is yours  to make.’ [With that decision] came the end, the final end of Eternity.  – And the beginning of Infinity. Isaac Asimov,  The End of Eternity  (1955) The first person to measure the circumference of the Earth was the  astronomer Eratosthenes of Cyrene, in the third century  bce.  His result  was fairly close to the actual value, which is about 40,000 kilometres.  For most of history this was considered an enormous distance, but with  the Enlightenment that conception gradually changed, and nowadays  we think of the Earth as small. That was brought about mainly by two  things: first, by the science of astronomy, which discovered titanic  entities compared with which our planet is indeed unimaginably tiny;  and, second, by technologies that have made worldwide travel and  communication commonplace. So the Earth has become smaller both  relative to the universe and relative to the scale of human action.  Thus, in regard to the  geography  of the universe and to our place in  it, the prevailing world view has rid itself of some parochial mis  - conceptions. We know that we have explored almost the whole surface  of that formerly enormous sphere; but we also know that there are far  more places left to explore in the universe (and beneath the surface of  the Earth’s land and oceans) than anyone imagined while we still had  those misconceptions.  444 the beginning of infinity In regard to theoretical knowledge, however, the prevailing world  view has not yet caught up with Enlightenment values. Thanks to the  fallacy and bias of prophecy, a persistent assumption remains that our  existing theories are at or fairly close to the limit of what it is knowable  – that we are  nearly there ,   or perhaps halfway there. As the economist  David Friedman has remarked, most people believe that an income of  about twice their own should be sufficient to satisfy any reasonable  person, and that no genuine benefit can be derived from amounts above  that. As with wealth, so with scientific knowledge: it is hard to imagine  what it would be like to know twice as much as we do, and so if we  try to prophesy it we find ourselves just picturing the next few decimal  places of what we already know. Even Feynman made an uncharacter- istic mistake in this regard when he wrote: I think there will certainly not be======================================================== present and future – is as good as it could possibly be. The term  was first used to describe an argument of Leibniz (1646–1716) that  God, being ‘perfect’, would have created nothing less than ‘the best of  all possible worlds’. Leibniz believed that this idea solved the ‘problem  of evil’, which I mentioned in Chapter 4: he proposed that all apparent  evils in the world are outweighed by good consequences that are too  remote to be known. Similarly, all apparently good events that  fail  to  200 the beginning of infinity happen – including all improvements that humans are unsuccessful in  achieving – fail because they would have had bad consequences that  would have outweighed the good. Since consequences are determined by the laws of physics, the larger  part of Leibniz’s claim must be that the laws of physics are the best  possible too. Alternative laws that made scientific progress easier, or  made disease an impossible phenomenon, or made even one disease  slightly less unpleasant – in short, any alternative that would  seem   to be an improvement upon our actual history with all its plagues,  tortures, tyrannies and natural disasters – would in fact have been even  worse on balance, according to Leibniz. That theory is a spectacularly bad explanation. Not only can  any   observed sequence of events be explained as ‘best’ by that method, an  alternative Leibniz could equally well have claimed that we live in the  worst  of all possible worlds, and that every good event is necessary in  order to prevent something even better from happening. Indeed, some  philosophers, such as Arthur Schopenhauer, have claimed just that.  Their stance is called philosophical ‘pessimism’. Or one could claim  that the world is exactly halfway between the best possible and the  worst possible – and so on. Notice that, despite their superficial differ- ences, all those theories have something important in common: if any  of them were true, rational thought would have almost no power to  discover true explanations. For, since we can always imagine states of  affairs that seem better than what we observe, we would always be  mistaken that they  were  better,  no matter how good our explanations  were . So, in such a world, the true explanations of events are never  even imaginable. For instance, in Leibniz’s ‘optimistic’ world, whenever  we try to solve a problem and fail, it is because we have been thwarted  by an unimaginably vast intelligence that determined that it was best  for us to fail. And, still worse, whenever someone rejects reason and  decides instead to rely on bad explanations or logical fallacies – or, for  that matter, on pure malevolence – they still achieve, in every case, a  better outcome on balance than the most rational and benevolent  thought possibly could have. This does not describe an explicable  world. And that would be very bad news for us, its inhabitants. Both  the original ‘optimism’ and the original ‘pessimism’ are close to pure  pessimism as I shall define it. 201 Optimism In everyday usage, a common saying is that ‘an optimist calls a glass  half full while a pessimist calls it half empty’. But those attitudes are  not what I am referring to either: they are matters not of philosophy  but of psychology – more ‘spin’ than substance. The terms can also  refer to moods, such as cheerfulness or depression, but, again, moods  do not necessitate any particular stance about the future: the statesman  Winston Churchill suffered from intense depression, yet his outlook  on the future of civilization, and his specific expectations as wartime  leader, were unusually positive. Conversely the economist Thomas  Malthus, a notorious prophet of doom (of whom more below), is said  to have been a serene and happy fellow, who often had his companions  at the dinner table in gales of laughter.  Blind  optimism  is  a stance towards the future. It consists of proceed- ing as if one knows that the bad outcomes will not happen. The  opposite approach, blind pessimism, often called the  precautionary  principle , seeks to ward off disaster by avoiding everything not known  to be safe. No one seriously advocates either of these two as a universal  policy, but their assumptions and their arguments are common, and  often creep into people’s planning. Blind optimism is also known as ‘overconfidence’ or ‘recklessness’.  An often cited example, perhaps unfairly, is the judgement of the builders  of the ocean liner  Titanic  that it was ‘practically unsinkable’. The largest  ship of its day, it sank on its maiden voyage in 1912. Designed to survive  every foreseeable disaster, it collided with an iceberg in a manner that  had not been foreseen. A blind pessimist argues that there is an inherent  asymmetry between good and bad consequences: a successful maiden  voyage cannot possibly do as much good as a disastrous one can do  harm. As Rees points out, a single catastrophic consequence of an  otherwise beneficial======================================================== phenomena remote from our  everyday experience, the longer those chains of interpretation become,  and every additional link necessitates more theory. A single unexpected  39 Closer to Reality or misunderstood phenomenon anywhere in the chain can, and often  does, render the resulting sensory experience arbitrarily misleading.  Yet, over time, the conclusions that science has drawn have become  ever truer to reality. Its quest for good explanations corrects the errors,  allows for the biases and misleading perspectives, and fills in the gaps.  This is what we can achieve when, as Feynman said, we keep learning  more about how not to fool ourselves. Telescopes contain automatic tracking mechanisms that continuously  realign them so as to compensate for the effect of the Earth’s motion;  in some, computers continuously change the shape of the mirror so as  to compensate for the shimmering of the Earth’s atmosphere. And so,  observed through such a telescope, stars do not appear to twinkle or  to move across the sky as they did to generations of observers in the  past. Those things are only appearance – parochial error. They have  nothing to do with the reality of stars. The primary function of the  telescope’s optics is to reduce the illusion that the stars are few, faint,  twinkling and moving. The same is true of every feature of the telescope,  and of all other scientific instruments: each layer of indirectness,  through its associated theory, corrects errors, illusions, misleading  perspectives and gaps. Perhaps it is the mistaken empiricist ideal of  ‘pure’, theory-free observation that makes it seem odd that truly  accurate observation is always so hugely indirect. But the fact is that  progress requires the application of ever more knowledge  in advance   of our observations. So I was indeed looking at galaxies. Observing a galaxy via specks  of silver is no different in that regard from observing a garden via  images on a retina. In all cases, to say that we have genuinely observed  any given thing is to say that we have accurately attributed our evidence  (ultimately always evidence inside our own brains) to that thing.  Scientific truth consists of such correspondence between theories and  physical reality.  Scientists operating giant particle accelerators likewise look at pixels  and ink, numbers and graphs, and thereby observe the microscopic  reality of subatomic particles like nuclei and quarks. Others operate  electron microscopes and fire the beam at cells that are as dead as  dodos, having been stained, quick-frozen by liquid nitrogen, and  mounted in a vacuum – but they thereby learn what  living  cells are  40 the beginning of infinity like. It is a marvellous fact that objects can exist which, when we  observe them, accurately take on the appearance and other attributes  of other objects that are elsewhere and very differently constituted.  Our sensory systems are such objects too, for it is only they that are  directly affecting our brains when we perceive anything. Such instruments are rare and fragile configurations of matter.    Press one wrong button on the telescope’s control panel, or code one  wrong instruction into its computer, and the whole immensely complex  artefact may well revert to revealing nothing other than itself. The same  would be true if, instead of making that scientific instrument, you were  to assemble those raw materials into almost any other configuration:  stare at them, and you would see nothing other than them. Explanatory theories tell us how to build and operate instruments  in exactly the right way to work this miracle. Like conjuring tricks in  reverse, such instruments fool our senses into seeing what is really  there. Our minds, through the methodological criterion that I mentioned  in Chapter 1, conclude that a particular thing is real if and only if it  figures in our best explanation of something. Physically, all that has  happened is that human beings, on Earth, have dug up raw materials  such as iron ore and sand, and have rearranged them – still on Earth  – into complex objects such as radio telescopes, computers and display  screens, and now, instead of looking at the sky, they look at those  objects. They are focusing their  eyes  on human artefacts that are close  enough to touch. But their  minds  are focused on alien entities and  processes, light years away.  Sometimes they are still looking at glowing dots just as their ancestors  did – but on computer monitors instead of the sky. Sometimes they  are looking at numbers or graphs. But in all cases they are inspecting  local phenomena: pixels on a screen, ink on paper, and so on. These  things are physically very unlike stars: they are much smaller; they are  not dominated by nuclear forces and gravity; they are not capable of  transmuting elements or creating life; they have not been there for  billions of years. But when astronomers look at them, they see stars. 41 Closer to Reality summary======================================================== long as it does not lead you to conclude that there is  something worthwhile about the Persephone myth, or the prophet’s  apocalyptic theory or the gambler’s delusion, just because is it testable.  Nor is a person capable of making progress merely by virtue of being  willing to drop a theory when it is refuted: one must also be seeking  a better explanation of the relevant phenomena. That is the scientific  frame of mind. As the physicist Richard Feynman said, ‘Science is what we have  learned about how to keep from fooling ourselves.’ By adopting easily  variable explanations, the gambler and prophet are ensuring that they  will be able to continue fooling themselves no matter what happens.  Just as thoroughly as if they had adopted untestable theories, they are  insulating themselves from facing evidence that they are mistaken  about what is really there in the physical world. The quest for good explanations is, I believe, the basic regulating  principle not only of science, but of the Enlightenment generally. It is  the feature that distinguishes those approaches to knowledge from all  others, and it implies all those other conditions for scientific progress  I have discussed: It trivially implies that prediction alone is insufficient.  23 The Reach of Explanations Somewhat less trivially, it leads to the rejection of authority, because  if we adopt a theory on authority, that means that we would also have  accepted a range of different theories on authority. And hence it also  implies the need for a tradition of criticism. It also implies a meth- odological rule – a  criterion for reality  – namely that we should conclude  that a particular thing is real if and only if it figures in our best  explanation of something. Although the pioneers of the Enlightenment and of the scientific  revolution did not put it this way, seeking good explanations was (and  remains) the spirit of the age. This is how they began to think. It is  what they began to do, systematically for the first time. It is what made  that momentous difference to the rate of progress of all kinds. Long before the Enlightenment, there were individuals who sought  good explanations. Indeed, my discussion here suggests that all progress  then, as now, was due to such people. But in most ages they lacked  contact with a tradition of criticism in which others could carry on their  ideas, and so created little that left any trace for us to detect. We do  know of sporadic traditions of good-explanation-seeking in narrowly  defined fields, such as geometry, and even short-lived traditions of  criticism – mini-enlightenments – which were tragically snuffed out, as  I shall describe in Chapter 9. But the sea change in the values and  patterns of thinking of a whole community of thinkers, which brought  about a sustained and accelerating creation of knowledge, happened  only once in history, with  the  Enlightenment and its scientific revolution.  An entire political, moral, economic and intellectual culture – roughly  what is now called ‘the West’ – grew around the values entailed by the  quest for good explanations, such as tolerance of dissent, openness to  change, distrust of dogmatism and authority, and the aspiration to  progress both by individuals and for the culture as a whole. And the  progress made by that multifaceted culture, in turn, promoted those  values – though, as I shall explain in Chapter 15, they are nowhere close  to being fully implemented. Now consider the true explanation of seasons. It is that the Earth’s  axis of rotation is tilted relative to the plane of its orbit around the  sun. Hence for half of each year the northern hemisphere is tilted  towards the sun while the southern hemisphere is tilted away, and for  the other half it is the other way around. Whenever the sun’s rays are  24 the beginning of infinity falling vertically in one hemisphere (thus providing more heat per    unit area of the surface) they are falling obliquely in the other (thus  providing less).  The true explanation of seasons (not to scale!) That is a good explanation – hard to vary, because all its details play  a functional role. For instance, we know – and can test independently  of our experience of seasons – that surfaces tilted away from radiant  heat are heated less than when they are facing it, and that a spinning  sphere in space points in a constant direction. And we can explain why,  in terms of theories of geometry, heat and mechanics. Also, the same  tilt appears in our explanation of where the sun appears relative to the  horizon at different times of year. In the Persephone myth, in contrast,  the coldness of the world is caused by Demeter’s sadness – but people  do not generally cool their surroundings when they are sad, and we  have no way of knowing that Demeter  is  sad, or that she ever cools  the world, other than the onset of winter itself. One could not substitute  the moon for the sun in the axis-tilt story, because the======================================================== so the only constraint on the  imaginary laws of physics is that they be consistent. It is  because  of  the requirement that they be consistent that they are counter-intuitive:  intuitions about infinity are often illogical. It is a bit awkward to have to keep changing rooms – though they  are all identical and are freshly made up every time a guest moves in.  But guests love staying at Infinity Hotel. That is because it is cheap –  only a dollar a night – yet extraordinarily luxurious. How is that  possible? Every day, when the management receive all the room rents  of one dollar per room, they spend the income as follows. With the  dollars they received from the rooms numbered 1 to 1000, they buy  complimentary champagne, strawberries, housekeeping services and  all the other overheads,  just for room 1 . With the dollars they received  from the rooms numbered 1001 to 2000, they do the same for room  2, and so on. In this way, each room receives several hundred dollars’  worth of goods and services every day, and the management make a  profit as well, all from their income of one dollar per room. Word gets around, and one day an infinitely long train pulls up at  the local station, containing infinitely many people wanting to stay at  the hotel. Making infinitely many public-address announcements would  take too long (and, anyway, the hotel rules say that each guest can be  asked to perform only a finite number of actions per day), but no  matter. The management merely announce, ‘Will all guests please move  immediately to the room whose number is double that of their current  room.’ Obviously they can all do that, and afterwards the only occupied  rooms are the even numbered ones, leaving the odd-numbered ones  free for the new arrivals. That is exactly enough to receive the infinitely  many new guests, because there are exactly as many odd numbers as  there are natural numbers, as illustrated overleaf: 170 the beginning of infinity There are exactly as many odd numbers as there are natural numbers. So the first new arrival goes to room 1, the second to room 3, and so  on. Then, one day, an  infinite number  of infinitely long trains arrive at  the station, all full of guests for the hotel. But the managers are still  unperturbed. They just make a slightly more complicated announce- ment, which readers who are familiar with mathematical terminology  can see in this footnote.* The upshot is: everyone is accommodated. However, it  is  mathematically possible to overwhelm the capacity  of Infinity Hotel. In a remarkable series of discoveries in the 1870s,  Cantor proved, among other things, that not all infinities are equal. In  particular, the infinity of the continuum – the number of points in a  finite line (which is the same as the number of points in the whole of  space or spacetime) – is much larger than the infinity of the natural  numbers. Cantor proved this by proving that there can be no one-to- one correspondence between the natural numbers and the points in a  line: that set of points has a higher order of infinity than the set of  natural numbers. Here is a version of his proof – known as the  diagonal argument.  Imagine a one-centimetre-thick pack of cards, each one so thin that  there is one of them for every ‘real number’ of centimetres between 0  and 1. Real numbers can be defined as the decimal numbers between  those limits, such as 0.7071. . ., where the ellipsis again denotes a  continuation that may be infinitely long. It is impossible to deal out  *First, they announce to the existing guests, ‘For each natural number  N , will the guest  in room number  N  please move immediately to room number  N ( N  +   1)/2.’ Then they  announce, ‘For all natural numbers  N  and  M , will the  N th passenger from the  M th  train please go to room number [( N  +  M ) 2   +  N  –  M ]/2.’ 171 A Window on Infinity one of these cards to each room of Infinity Hotel. For suppose that the  cards  were  so distributed. We can prove that this entails a contradiction.  It would mean that cards had been assigned to rooms in something  like the manner of the table below. (The particular numbers illustrated  are not significant: we are going to prove that real numbers cannot be  assigned in  any  order.) Cantor’s diagonal argument Look at the infinite sequence of digits highlighted in bold – namely  ‘  . . .’. Then consider a decimal number constructed as follows: it  starts with zero followed by a decimal point, and continues arbitrarily,  except that each of its digits must differ from the corresponding digit  in the infinite sequence ‘  . . .’. For instance, we could choose a  number such as ‘0.5885. . .’. The card with the number thus constructed  cannot have been assigned to any room. For it differs in its first digit  from that of the card assigned to room 1, and in its second digit from  that of the card assigned to room 2, and so on. Thus it differs from all  the cards that have been assigned======================================================== socrates: I do? hermes: Of  course. Have you yourself not often been misunderstood,  even by people trying hard to understand you? socrates: Yes. hermes:  Have you, in turn, not often misunderstood what someone  means, even when he is trying to tell you as clearly as he can? socrates:  Indeed I have. Not least during this conversation!  hermes: W ell, this is not an attribute of philosophical ideas only, but  of all ideas. Remember when you all got lost on your way here from  the ship? And why? socrates: It  was because – as we realized with hindsight – we  completely misunderstood the directions given to us by the captain. hermes: So,  when you got the wrong idea of what he meant, despite  having listened attentively to every word he said,  where did that  wrong idea come from ? Not from him, presumably . . . socrates: I  see. It must come from within ourselves. It must be a  guess. Though, until this moment, it had never even remotely occurred  to me that I had been guessing. hermes: So  why would you expect that anything different happens  when you do understand someone correctly? socrates: I  see. When we hear something being said, we  guess  what  it means, without realizing what we are doing. That is beginning to  make sense to me.      Except – guesswork isn’t knowledge!  hermes:  Indeed, most guesses are not new knowledge. Although  guesswork is the  origin  of all knowledge, it is also a source of error,  and therefore what happens to an idea  after  it has been guessed is  crucial. socrates: So –  let me combine that insight with what I know of  240 the beginning of infinity criticism. A guess might come from a dream, or it might just be a  wild speculation or random combination of ideas, or anything. But  then we do not just accept it blindly or because we imagine it is  ‘authorized’, or because we  want  it to be true. Instead we criticize  it and try to discover its flaws. hermes: Yes.  That is what you  should  do, at any rate. socrates:  Then we try to remedy those flaws by altering the idea,  or dropping it in favour of others – and the alterations and other  ideas are themselves guesses. And are themselves criticized. Only  when we fail in these attempts either to reject or to improve an idea  do we provisionally accept it. hermes:  That can work. Unfortunately, people do not always do  what can work. socrates: Thank you, Hermes. It is exciting to learn of this single  process through which all knowledge originates, whether it is our  knowledge of a sea captain’s directions to Delphi, or knowledge of  right and wrong that we have carefully refined for years, or theorems  of arithmetic or geometry – or epistemology revealed to us by a    god – hermes: It  all comes from within, from conjecture and criticism. socrates: W ait! It comes from within,  even if revealed by a god ? hermes:  And is just as fallible as ever. Yes. Your argument covers that  case just like any other. socrates:  Marvellous! But now – what about objects that we just  experience  in the natural world. We reach out and touch an object,  and hence experience it  out there.  Surely that is a different kind of  knowledge, a kind which – fallible or not – really does come from  without, at least in the sense that our own experience is out there,  at the location of the object.* hermes: You  loved the idea that all those other different kinds of  knowledge originate in the same way, and are improved in the same  way. Why is ‘direct’ sensory experience an exception? What if it just  seems  radically different?  *The ancient Greeks were not very clear about where sensory experiences are located.  Even in the case of vision, many in Socrates’ time believed that the eye  emits  some- thing like light, and that the sensation of seeing an object consists of some sort of  interaction between the object and that light. 241 A Dream of Socrates socrates:  But surely you are now asking me to believe in a sort of  all-encompassing conjuring trick, resembling the fanciful notion that  the whole of life is really a dream. For it would mean that the  sensation of touching an object does not happen where we experience  it happening, namely in the hand that touches, but in the mind –  which I believe is located somewhere in the brain. So all my sen  - sations of touch are located inside my skull, where in reality nothing  can touch while I still live. And whenever I think I am seeing a vast,  brilliantly illuminated landscape, all that I am really experiencing    is likewise located entirely inside my skull, where in reality it is  constantly dark! hermes: Is  that so absurd? Where do you think all the sights and  sounds of  this   dream  are located? socrates: I  accept that  they  are indeed in my mind. But that is my  point: most dreams portray things that are simply not there in the  external reality. To portray things that  are  there is surely impossible  without some input that does not come from the mind but from  those things======================================================== it misses and the rest strikes everywhere on  the exposed surface. Remember, this is just a single particle, which may  consist of fungible instances. The next thing that happens is that they  cease to be fungible, splitting through their interaction with atoms at  their points of arrival into a finite but huge number of instances, each  of which is the origin of a separate history. 294 the beginning of infinity In each such history, there is an autonomous instance of the cosmic- ray particle, which will dissipate its energy in creating a ‘cosmic-ray  shower’ of electrically charged particles. Thus, in different histories,  such a shower will occur at different locations. In some, that shower  will provide a conducting path down which a lightning bolt will travel.  Every atom on the surface of the Earth will be struck by such lightning  in  some  history. In other histories, one of those cosmic-ray particles  will strike a human cell, damaging some already damaged DNA in  such a way as to make the cell cancerous. Some non-negligible pro  - portion of all cancers are caused in this way. As a result, there exist  histories in which any given person, alive in our history at any time,  is killed soon afterwards by cancer. There exist other histories in which  the course of a battle, or a war, is changed by such an event, or by a  lightning bolt at exactly the right place and time, or by any of countless  other unlikely, ‘random’ events. This makes it highly plausible that  there exist histories in which events have played out more or less as  in alternative-history stories such as  Fatherland  and  Roma Eterna  – or  in which events in your own life played out very differently, for better  or worse. A great deal of fiction is therefore close to a fact somewhere in the  multiverse. But not all fiction. For instance, there are no histories in  which my stories of the transporter malfunction are true, because they  require different laws of physics. Nor are there histories in which the  fundamental constants of nature such as the speed of light or the charge  on an electron are different. There is, however, a sense in which different  laws of physics  appear  to be true for a period in some histories, because  of a sequence of ‘unlikely accidents’. (There may also be universes in  which there are different laws of physics, as required in anthropic  explanations of fine-tuning. But as yet there is no viable theory of such  a multiverse.) Imagine a single photon from a starship’s communication laser,  heading towards Earth. Like the cosmic ray, it arrives all over the  surface, in different histories. In each history, only one atom will absorb  the photon and the rest will initially be completely unaffected. A receiver  for such communications would then detect the relatively large, discrete  change undergone by such an atom. An important consequence for the  construction of measuring devices (including eyes) is that no matter  295 The Multiverse how far away the source is, the kick given to an atom by an arriving  photon is always the same: it is just that the weaker the signal is, the  fewer kicks there are. If this were not so – for instance, if classical physics  were true – weak signals would be much more easily swamped by  random local noise. This is the same as the advantage of digital over  analogue information processing that I discussed in Chapter 6. Some of my own research in physics has been concerned with the  theory of  quantum computers . These are computers in which the  information-carrying variables have been protected by a variety of  means from becoming entangled with their surroundings. This allows  a new mode of computation in which the flow of information is not  confined to a single history. In one type of quantum computation,  enormous numbers of different computations, taking place simul- taneously, can affect each other and hence contribute to the output of  a computation. This is known as  quantum parallelism . In a typical quantum computation, individual bits of information are  represented in physical objects known as ‘qubits’ – quantum bits – of  which there is a large variety of physical implementations but always  with two essential features. First, each qubit has a variable that can take  one of two discrete values, and, second, special measures are taken to  protect the qubits from entanglement – such as cooling them to  temperatures close to absolute zero. A typical algorithm using quantum  parallelism begins by causing the information-carrying variables in some  of the qubits to acquire both their values simultaneously. Con    sequently,  regarding those qubits as a register representing (say) a number, the  number of separate instances of the register as a whole is exponentially  large: two to the power of the number of qubits. Then, for a period,  classical computations are performed, during which waves of  differentiation spread to some of the other qubits – but no further,======================================================== 406–7, 408–9,  410   see also  imitation Parthenon  217, 250n particles, elementary  3, 11, 43, 67, 108,  118, 288, 293, 450 accelerators  39, 197 as configurations  267 cosmic rays  68, 293–4 identity loss  287–9 interaction between charged particles   96, 290–91 and interference  287–8;  see also   interference, quantum speed and  289–90 and waves/fields  291, 307, 319 see also  atoms; electron(s), photons,  quantum theory Pasteur, Louis  82 peacock’s tail  91–2, 361, 401 people vii,  42 , 43, 44,  45 , 56, 59, 60, 64,  65,  75 , 76–7, 85, 157, 354, 416 as abstractions  123, 454 and atoms  306 cosmic significance of  72– 7 4, 458,  459 as a disease or cure  435 ultimate reach of  66, 69–71, 146 as universal explainers  146, 164, 416,  429    see   also  humans; extraterrestrials;  artificial intelligence people, the  209, 217, 326, 329, 335–8,  344, 350, 352 perception   see  sensory experience;  interpretation perfection  66, 80, 102, 119, 142, 189,  199, 232, 238, 248, 333, 343–4 perfectibility  65, 366, 445 perfectly identical  see  fungible Pericles  217–8 Persephone myth  19–21, 22, 24, 25,   60 perspiration phase of research   see  inspiration/perspiration pessimism  166–7, 217–18, 316, 350,  421, 431–5, 445–6, 449 blind (precautionary principle)  201–4,  208, 210, 216,  221 , end of  216, 221;  see also  Enlightenment pessimistic bias of prophecy  198, 206,  320, 444 philosophical  200 phantom-zone stories  259, 261, 263–4,  283 philosophy  viii, 4–5, 9, 12, 14, 18, 35,  64, 70, 153, 163, 192–3, 201, 209,  218, 226, 235, 239, 251–2, 255,  359, 366, 369, 370, 398, 405, 423,  456 Athenian  83, 216–18 bad, preventing knowledge growth   26, 110, 166, 305–23,  324 , 325,  436, 448–9; counteracted by  progress  324; quantum theory and   305–6, 307–11 good  311, 312, 324–5 and good explanations  26, 119–20 history of ideas  43, 65–6, 153, 209,  216, 311–12, 255, 256, 390–91,  428, 442 linguistic  313, 325 reductionism in  122, 425 role of evidence in  209 of science  5, 15, 120, 403 of the unknowable  see  optimism see also   specific philosophers and  philosophies Phoenicians  127 phosphors, red  433–4 photographs aesthetics and  357 astronomy and  34–8 photons  266, 267, 273–4, 275, 294–5,  306, 309, 452 see also  light; Mach–Zehnder  interferometers 480 index physics astrophysics  see  astronomy;  astrophysicists; astrophysics atomic  312 and the complexity of everyday events   107 infinity in  see  infinity: physics and;  singularities; Zeno’s mistake connection between computation and   138, 142, 187, 189–92, 195, 295–6 constants of  62, 97–104, 105–6, 177,  179, 180, 199, 283, 294, 446, 452– 3; fine-tuning  see  fine-tuning of the  universe/laws of physics counter-intuitive theories of  27, 107,  195, 199, 265–7, 279, 304, 306–7 elementary particle physics  see  particles, elementary and infinity  164, 177–81, 182–3;  see  also  singularities laws of  3, 6, 43, 54, 61, 65, 67, 69,  70, 71–2, 83, 87, 104, 110, 137,  186–91, 364, 425, 434, 437, 454,  458, 459; as abstractions  122–3,  458; conservation of energy  61,  109; deterministic nature of  136,  200, 263, 265, 275, 304, 358–9;  are not evils  123, 193, 213; fine- tuning  see  fine-tuning of the  universe/laws of physics; and the  mind–body problem  117–22, 130;  second law of thermodynamics   110, 111; determine simplicity and  complexity  187; need to be specific   79; our window on abstractions   185–8;  see also  nature: laws of and proof  183, 185, 187–8, 195 quantum  see  quantum theory pictograms  125–7, 130, 134 Pitcairn Island  418–19, 430 planets  2, 28, 35–6, 43, 44–6, 63, 68,  71, 73, 96, 97, 101, 112–13, 216,  273, 290, 292, 373, 411 plasma  46, 69 Plato  119, 187, 216, 223n, 253–5 and ‘a dream of Socrates’  243–7,  249–53 plurality (first-past-the-post) voting  system  346–50, 352 political philosophy  12, 209–12, 217– 18, 342  Popper’s criterion of ridding ourselves  of bad governments without  violence  see under  Popper, Karl rulers  209–12, 251–2, 344  society-wide planning and decision- making  335–51 see also  voting; representative  government Polynesians  419, 421, 427 Popper, Karl  4, 10, 14, 17–18, 66, 104– 5, 114,, 210, 211, 215, 230n, 312,  403–4, 406, 409, 447, 460–61 criterion of demarcation for science   14  see also  testability criterion of ridding ourselves of bad  governments without violence   209–12, 344–51,  352 , 396, 423 on our infinite ignorance  447 on instruction  411–12 on ‘sources of knowledge’ 209 theory of knowledge in ‘a dream of  Socrates’  223–54 letting theories die in our place  114,  124 and optimism  196, 212, 215 on prediction and prophecy  198 on ‘who should rule’  209 ‘Population, Resources, Environment’  (lecture by Ehrlich)  431–2, 440 populations  48–9, 50, 55, 58, 418, 421,  422, 428, 437 and evolution  89–92, 93, 106, 378–9,  383–4, 401 Malthus on resources and  205–6, 214 paradox  330–31, 334, 337, 339, 346 in the US Constitution  326–30, 338,  349, 350, 351 Porter, Roy  66, 457, 461======================================================== policy is bad, and to remove them without violence if they are. Just as  the institutions of science are structured so as to avoid entrenching  theories, but instead to expose them to criticism and testing, so political  institutions should not make it hard to oppose rulers and policies,  non-violently, and should embody traditions of peaceful, critical dis-  cussion of them and of the institutions themselves and everything else.  Thus, systems of government are to be judged not for their prophetic  ability to choose and install good leaders and policies, but for their  ability to remove bad ones that are already there.  That entire stance is fallibilism in action. It  assumes  that rulers and  policies are always going to be flawed – that problems are inevitable.  But it also assumes that improving upon them is possible: problems  are soluble. The ideal towards which this is working is not that nothing  212 the beginning of infinity unexpected will go wrong, but that when it does it will be an opportun- ity for further progress. Why would anyone want to make the leaders and policies that they  themselves favour more vulnerable to removal? Indeed, let me first  ask:  why would anyone want to replace bad leaders and policies at  all?  That question may seem absurd, but perhaps it is absurd only from  the perspective of a civilization that takes progress for granted. If we  did not expect progress, why should we expect the new leader or policy,  chosen by whatever method, to be any better than the old? On the  contrary, we should then expect any changes on average to do as much  harm as good. And then the precautionary principle advises, ‘Better  the devil you know than the devil you don’t.’ There is a closed loop of  ideas here: on the assumption that knowledge is not going to grow,  the precautionary principle is true; and on the assumption that the  precautionary principle is true, we cannot afford to allow knowledge  to grow. Unless a society is expecting its own future choices to be better  than its present ones, it will strive to make its present policies and  institutions as immutable as possible. Therefore Popper’s criterion can  be met only by societies that expect their knowledge to grow – and to  grow unpredictably. And, further, they are expecting that if it did grow,  that would help .  This expectation is what I call optimism, and I can state it, in its  most general form, thus: The Principle of Optimism All evils are caused by insufficient knowledge. Optimism is, in the first instance, a way of explaining failure, not  prophesying success. It says that there is no fundamental barrier, no  law of nature or supernatural decree, preventing progress. Whenever  we try to improve things and fail, it is not because the spiteful (or  unfathomably benevolent) gods are thwarting us or punishing us for  trying, or because we have reached a limit on the capacity of reason  to make improvements, or because it is best that we fail, but always  because we did not know enough, in time. But optimism is also a stance  towards the future, because nearly all failures, and nearly all successes,  are yet to come. 213 Optimism Optimism follows from the explicability of the physical world, as I  explained in Chapter 3. If something is permitted by the laws of physics,  then the only thing that can prevent it from being technologically  possible is not knowing how. Optimism also assumes that none of the  prohibitions  imposed by the laws of physics are necessarily  evils . So,  for instance, the lack of the impossible knowledge of prophecy is not  an insuperable obstacle to progress. Nor are insoluble mathematical  problems, as I explained in Chapter 8.  That means that in the long run there are no insuperable evils, and  in the short run the only insuperable evils are parochial ones. There  can be no such thing as a disease for which it is impossible to discover  a cure, other than certain types of brain damage – those that have  dissipated the knowledge that constitutes the patient’s personality. For  a sick person is a physical object, and the task of transforming this  object into the same person in good health is one that no law of physics  rules out. Hence there is a way of achieving such a transformation –  that is to say, a cure. It is only a matter of knowing how. If we do not,  for the moment, know how to eliminate a particular evil, or we know  in theory but do not yet have enough time or resources (i.e. wealth),  then, even so, it is universally true that  either  the laws of physics forbid  eliminating it in a given time with the available resources  or  there is a  way of eliminating it in the time and with those resources. The same must hold, equally trivially, for the evil of death – that is  to say, the deaths of human beings from disease or old age. This problem  has a tremendous resonance in every culture – in its literature, its values,  its objectives great and small. It also has an almost======================================================== society replicate as reliably as the  most successful memes of either a very static society or an (as yet  hypothetical) fully dynamic society. This causes a number of phenomena  that are peculiar to our transitional era. One of them is that some anti-rational memes evolve against the  grain, towards rationality. An example is the transition from an auto- cratic monarchy to a ‘constitutional monarchy’, which has played a  positive role in some democratic systems. Given the instability that I  have described, it is not surprising that such transitions often fail. Another is the formation within the dynamic society of anti-rational  subcultures. Recall that anti-rational memes suppress criticism selectively  and cause only finely tuned damage. This makes it possible for the  members of an anti-rational subculture to function normally in other  respects. So such subcultures can survive for a long time, until they are  destabilized by the haphazard effects of reach from other fields. For  example, racism and other forms of bigotry exist nowadays almost  entirely in subcultures that suppress criticism. Bigotry exists not because  it benefits the bigots, but despite the harm they do to themselves by  using fixed, non-functional criteria to determine their choices in life.  Present-day methods of education still have a lot in common with  their static-society predecessors. Despite modern talk of encouraging  critical thinking, it remains the case that teaching by rote and inculcating  standard patterns of behaviour through psychological pressure are  integral parts of education, even though they are now wholly or partly  renounced in explicit theory. Moreover, in regard to academic know- ledge, it is still taken for granted, in practice, that the main purpose of  education is to transmit a standard curriculum faithfully. One con  - sequence is that people are acquiring scientific knowledge in an anaemic  and instrumental way. Without a critical, discriminating approach to  what they are learning, most of them are not effectively replicating the  memes of science and reason into their minds. And so we live in a  society in which people can spend their days conscientiously using  laser technology to count cells in blood samples, and their evenings    sitting cross-legged and chanting to draw supernatural energy out of  the Earth. 394 the beginning of infinity Living with memes Existing accounts of memes have neglected the all-important distinction  between the rational and anti-rational modes of replication. Con  - sequently they end up missing most of what is happening, and why.  Moreover, since the most obvious examples of memes are long-lived  anti-rational memes and short-lived arbitrary fads, the tenor of such  accounts is usually anti-meme, even when these accounts formally  accept that the best and most valuable knowledge also consists    of memes.  For example, the psychologist Susan Blackmore, in her book  The  Meme Machine , attempts to provide a fundamental explanation of the  human condition in terms of meme evolution. Now, memes are indeed  integral to the explanation for the existence of our species – though, as  I shall explain in the next chapter, I believe that the specific mechanism  she proposes would not have been possible. But, crucially, Blackmore  downplays the element of creativity both in the replication of memes  and in their origin. This leads her, for example, to doubt that techno- logical progress is best explained as being due to individuals as the  conventional narrative would have it. She regards it instead as meme  evolution. She cites the historian George Basalla, whose book  The  Evolution of Technology  denies ‘the myth of the heroic inventor’. But that distinction between ‘evolution’ and ‘heroic inventors’ as  being the agents of discovery makes sense only in a static society. There,  most change is indeed brought about in the way that I guessed jokes  might evolve, with no great creativity being exercised by any individual  participant. But in a dynamic society, scientific and technological  innovations are generally made creatively. That is to say, they emerge  from individual minds as novel ideas, having acquired significant  adaptations inside those minds. Of course, in both cases, ideas are built  from previous ideas by a process of variation and selection, which  constitutes evolution. But when evolution takes place largely within  an individual mind, it is not meme evolution. It is creativity by a heroic  inventor.  Worse, in regard to progress, Blackmore denies that there has been  ‘progress towards anything in particular’ – that is to say, no progress  towards anything objectively better. She recognizes only increasing  395 The Evolution of Culture complexity. Why? Because  biological  evolution does not have a ‘better’  or ‘worse’. This despite her own warning that memes and genes evolve  differently. Again, her claim is largely true of static societies, but not  of======================================================== 406–7, 408–9,  410   see also  imitation Parthenon  217, 250n particles, elementary  3, 11, 43, 67, 108,  118, 288, 293, 450 accelerators  39, 197 as configurations  267 cosmic rays  68, 293–4 identity loss  287–9 interaction between charged particles   96, 290–91 and interference  287–8;  see also   interference, quantum speed and  289–90 and waves/fields  291, 307, 319 see also  atoms; electron(s), photons,  quantum theory Pasteur, Louis  82 peacock’s tail  91–2, 361, 401 people vii,  42 , 43, 44,  45 , 56, 59, 60, 64,  65,  75 , 76–7, 85, 157, 354, 416 as abstractions  123, 454 and atoms  306 cosmic significance of  72– 7 4, 458,  459 as a disease or cure  435 ultimate reach of  66, 69–71, 146 as universal explainers  146, 164, 416,  429    see   also  humans; extraterrestrials;  artificial intelligence people, the  209, 217, 326, 329, 335–8,  344, 350, 352 perception   see  sensory experience;  interpretation perfection  66, 80, 102, 119, 142, 189,  199, 232, 238, 248, 333, 343–4 perfectibility  65, 366, 445 perfectly identical  see  fungible Pericles  217–8 Persephone myth  19–21, 22, 24, 25,   60 perspiration phase of research   see  inspiration/perspiration pessimism  166–7, 217–18, 316, 350,  421, 431–5, 445–6, 449 blind (precautionary principle)  201–4,  208, 210, 216,  221 , end of  216, 221;  see also  Enlightenment pessimistic bias of prophecy  198, 206,  320, 444 philosophical  200 phantom-zone stories  259, 261, 263–4,  283 philosophy  viii, 4–5, 9, 12, 14, 18, 35,  64, 70, 153, 163, 192–3, 201, 209,  218, 226, 235, 239, 251–2, 255,  359, 366, 369, 370, 398, 405, 423,  456 Athenian  83, 216–18 bad, preventing knowledge growth   26, 110, 166, 305–23,  324 , 325,  436, 448–9; counteracted by  progress  324; quantum theory and   305–6, 307–11 good  311, 312, 324–5 and good explanations  26, 119–20 history of ideas  43, 65–6, 153, 209,  216, 311–12, 255, 256, 390–91,  428, 442 linguistic  313, 325 reductionism in  122, 425 role of evidence in  209 of science  5, 15, 120, 403 of the unknowable  see  optimism see also   specific philosophers and  philosophies Phoenicians  127 phosphors, red  433–4 photographs aesthetics and  357 astronomy and  34–8 photons  266, 267, 273–4, 275, 294–5,  306, 309, 452 see also  light; Mach–Zehnder  interferometers 480 index physics astrophysics  see  astronomy;  astrophysicists; astrophysics atomic  312 and the complexity of everyday events   107 infinity in  see  infinity: physics and;  singularities; Zeno’s mistake connection between computation and   138, 142, 187, 189–92, 195, 295–6 constants of  62, 97–104, 105–6, 177,  179, 180, 199, 283, 294, 446, 452– 3; fine-tuning  see  fine-tuning of the  universe/laws of physics counter-intuitive theories of  27, 107,  195, 199, 265–7, 279, 304, 306–7 elementary particle physics  see  particles, elementary and infinity  164, 177–81, 182–3;  see  also  singularities laws of  3, 6, 43, 54, 61, 65, 67, 69,  70, 71–2, 83, 87, 104, 110, 137,  186–91, 364, 425, 434, 437, 454,  458, 459; as abstractions  122–3,  458; conservation of energy  61,  109; deterministic nature of  136,  200, 263, 265, 275, 304, 358–9;  are not evils  123, 193, 213; fine- tuning  see  fine-tuning of the  universe/laws of physics; and the  mind–body problem  117–22, 130;  second law of thermodynamics   110, 111; determine simplicity and  complexity  187; need to be specific   79; our window on abstractions   185–8;  see also  nature: laws of and proof  183, 185, 187–8, 195 quantum  see  quantum theory pictograms  125–7, 130, 134 Pitcairn Island  418–19, 430 planets  2, 28, 35–6, 43, 44–6, 63, 68,  71, 73, 96, 97, 101, 112–13, 216,  273, 290, 292, 373, 411 plasma  46, 69 Plato  119, 187, 216, 223n, 253–5 and ‘a dream of Socrates’  243–7,  249–53 plurality (first-past-the-post) voting  system  346–50, 352 political philosophy  12, 209–12, 217– 18, 342  Popper’s criterion of ridding ourselves  of bad governments without  violence  see under  Popper, Karl rulers  209–12, 251–2, 344  society-wide planning and decision- making  335–51 see also  voting; representative  government Polynesians  419, 421, 427 Popper, Karl  4, 10, 14, 17–18, 66, 104– 5, 114,, 210, 211, 215, 230n, 312,  403–4, 406, 409, 447, 460–61 criterion of demarcation for science   14  see also  testability criterion of ridding ourselves of bad  governments without violence   209–12, 344–51,  352 , 396, 423 on our infinite ignorance  447 on instruction  411–12 on ‘sources of knowledge’ 209 theory of knowledge in ‘a dream of  Socrates’  223–54 letting theories die in our place  114,  124 and optimism  196, 212, 215 on prediction and prophecy  198 on ‘who should rule’  209 ‘Population, Resources, Environment’  (lecture by Ehrlich)  431–2, 440 populations  48–9, 50, 55, 58, 418, 421,  422, 428, 437 and evolution  89–92, 93, 106, 378–9,  383–4, 401 Malthus on resources and  205–6, 214 paradox  330–31, 334, 337, 339, 346 in the US Constitution  326–30, 338,  349, 350, 351 Porter, Roy  66, 457, 461======================================================== often  do this  by imparting useful functionality to their organism, and in those cases  *This terminology differs slightly from that of Dawkins. Anything that is copied,    for whatever reason, he calls a replicator. What I call a replicator he calls an ‘active    replicator’. 94 the beginning of infinity their knowledge incidentally includes knowledge about that functionality.  Functionality, in turn, is achieved by encoding, into genes, regularities  in the environment and sometimes even rule-of-thumb approximations  to laws of nature, in which case the genes are incidentally encoding that  knowledge too. But the core of the explanation for the presence of a  gene is always that it got itself replicated more than its rival genes. Non-explanatory human knowledge can also evolve in an analogous  way: rules of thumb are not passed on perfectly to the next generation  of users, and the ones that survive in the long run are not necessarily  the ones that optimize the ostensible function. For instance, a rule that  is expressed in an elegant rhyme may be remembered, and repeated,  better than one that is more accurate but expressed in ungainly prose.  Also, no human knowledge is entirely non-explanatory. There is always  at least a background of assumptions about reality against which the  meaning of a rule of thumb is understood, and that background can  make some false rules of thumb seem plausible. Explanatory theories evolve through a more complicated mechanism.  Accidental errors in transmission and memory still play a role, but a  much smaller one. That is because good explanations are hard to vary  even without being tested, and hence random errors in the transmission  of a good explanation are easier for the receiver to detect and correct.  The most important source of variation in explanatory theories is  creativity. For instance, when people are trying to understand an idea  that they hear from others, they typically understand it to mean what  makes most sense to them, or what they are most expecting to hear,  or what they fear to hear, and so on. Those meanings are conjectured  by the listener or reader, and may differ from what the speaker or  writer intended. In addition, people often try to improve explanations  even when they have received them accurately: they make creative  amendments, spurred by their own criticism. If they then pass the  explanation on to others, they usually try to pass on what they consider  to be the improved version. Unlike genes, many memes take different physical forms every time  they are replicated. People rarely express ideas in exactly the same  words in which they heard them. They also translate from one language  to another, and between spoken and written language, and so on. Yet  we rightly call what is transmitted the  same  idea – the same meme –  95 Creation throughout. Thus, in the case of most memes, the real replicator is  abstract: it is the knowledge itself. This is in principle true of genes as  well: biotechnology routinely transcribes genes into the memories of  computers, where they are stored in a different physical form. Those  records could be translated back into DNA strands and implanted in  different animals. The only reason this is not yet a common practice  is that it is easier to copy the original gene. But one day the genes of a  rare species could survive its extinction by causing themselves to be  stored on a computer and then implanted into a cell of a different  species. I say ‘causing themselves to be stored’ because the biotech- nologists would not be recording information indiscriminately, but  only information that met a criterion such as ‘gene of an endangered  species’. The ability to interest biotechnologists in this way would then  be part of the reach of the knowledge in those genes.  So, both human knowledge and biological adaptations are abstract  replicators: forms of information which, once they are embodied in a  suitable physical system, tend to remain so while most variants of them  do not. The fact that the principles of neo-Darwinist theory are, from a  certain perspective, self-evident has itself been used as a criticism of  the theory. For instance, if the theory  must  be true, how can it be  testable? One reply, often attributed to Haldane, is that the whole  theory would be refuted by the discovery of a single fossilized rabbit  in a stratum of Cambrian rock. However, that is misleading. The import  of such an observation would depend on what explanations were  available under the given circumstances. For instance, misidentifications  of fossils, and of strata, have sometimes been made and would have  to be ruled out by good explanations before one could call the discovery  ‘a fossilized rabbit in Cambrian rock’.  Even given such explanations, what would have been ruled out by  the rabbit would be not the theory of evolution itself, but only the  prevailing theory of the history of life and geological processes======================================================== 378–9, 387 and static societies  380, 383–6, 414  subcultures  393 cultural relativism  314, 356 culture   397   see also  cultural evolution cures  11, 153, 213, 272, 422, 437, 455 curvature of spacetime  107, 112, 183–4,  312, 450 dark energy  451 dark matter  36, 46, 67 Darwin, Charles  80, 82, 87, 91 Darwin, Erasmus  87, 88 Darwinian theory  80, 89 Marx on  371 neo-Darwinism  89–96, 103, 104–5 refutation possibilities  95–6 data  15, 18, 210, 315, 323 Dawkins, Juliet  353, 362 Dawkins, Richard  52–3, 56–7, 92, 93,  279 argument from personal incredulity   164 Haldane–Dawkins ‘queerer-than-we- can-suppose’ argument  53, 56,  59, 81 death  48, 63, 69, 436, 453, 459 elimination of  63, 213,  455 evil of  213 fear of  84 decision-making  335 conventional model of  341 democratic  344–5;  see also  voting and Popper’s criterion of ridding  ourselves of bad governments  without violence  344–51,  352 and problem solving  341–2 social-choice theory and  335, 337–8,  342–3, 345 society-wide planning and  335–51 by weighing  340–42 decoherence  285,  303 deconstructionism  314 deduction  5 deep space  47–8, 66–9, 71–2, 293 deforestation  418, 420–21, 422 Demeter  19–21, 24, 26 democracy  217, 250, 333, 335 democratic decision-making in  elections  344–5 see also  voting; plurality voting   346–50 Dennett, Daniel  117, 154 design  44, 125, 131, 139, 144, 155,  159–162, 201, 357, 367 appearance of  44, 50,  84–6 , 87,  97, 98, 106, 357, 363–4; Paley’s  criterion for  85–7 argument from  83–7 creationism and designers  43, 49, 51,  73, 79–81, 97 in the laws of physics  96–103 determinism  277, 287, 371 deterministic laws  263, 265, 267,  268, 270, 275, 276, 279, 305 Deutsch, David,  The Fabric of Reality    109–10, 450, 460 diagonal argument  170–71, 172 Diamond, Jared  425–9, 430, 442 dictatorship  see  tyranny meaning of ‘dictator’ in Arrow’s  theorem  343 no-dictator axiom  336 Difference Engine  135–6 Difference Engine, The  (Gibson and  Sterling) 137 differentiation calculus  164 of histories in a multiverse  273–5,  276–9, 287–8; decoherence and   285; interference and  283–7, 291,  293; rate of growth of distinct  469 index histories  287;  see also  waves of  differentiation digital technology  139–42 dinosaurs  162, 315 disasters, natural  42, 49, 63, 200, 202,  206–7 discrete variables  128, 140, 142, 274,  305, 450 discrete/continuous dichotomy  140,  142, 274, 298, 450 disease  59, 63, 196, 200, 213, 294, 385,  437 Black Death  208, 385, 437 cholera  207 cures  11, 153, 213, 272, 422, 437,  455 pandemics/epidemics  196, 208, 418,  436;  see also  Black Death  above DNA  56–7, 62, 67, 78, 95, 162, 375,  376 computer  145 damage  294 and the genetic code’s jump to  universality  143–6, 162–3 in pollen  360 dogmas/dogmatism  13, 23, 26, 66, 122,  445, 447 domino computer (Hofstadter)  115–17,  118, 185, 358 doomsday argument  455–6 doppelgangers  258, 263–4, 265, 270–72 Doyle, Arthur Conan  10 Dragon’s Egg  (Forward)  97 dream hallucination  301 Popperian epistemology taught in a  ‘dream of Socrates’  223–54 reality and experience as a waking  dream  241–2, 252–3 drugs  317–18 Easter Island  418–24, 430–31 economic forecasts  371, 437, 439 ecosystems artificial/virtual  68 see   also  biosphere Eden, Garden of  52, 63 Edison, Thomas  36, 41, 158, 341 see also  inspiration/perspiration education  123, 203–4, 210, 217–18,  230–31, 244, 247, 252,  254, 311,  377–8, 382, 389, 391, 392, 393,  400, 409, 431, 435 academic knowledge  4, 255, 369,  393, 446 because I say so  311, 391–2, 395 moral  230–31 university  34–6, 158, 255, 308, 309,  403, 406, 409, 433, 446 see also  fun; Popper on instruction Ehrlich, Paul  431–2, 440 Einstein, Albert  60, 104, 113, 255, 256,  307, 310, 312, 446–7, 451 curved space and time  183–4 explanation of planetary motion  112,  113 general theory of relativity  29, 61,  107, 312; and the problem of  quantum gravity  449–50 special theory of relativity  199 Elbot  program  151, 156 electoral systems  338–40 and democratic decision-making   344–5 plurality voting system  346–50 see also  proportional representation electron(s)  70, 108, 289–91, 293, 294,  298, 324, 454 field  291 microscope  39 elegance  3, 25, 32, 42, 94, 199, 355,  367 , 387 elementary particles  see  particles,  elementary elements ancient theory of  14 formation of  1, 2, 40, 50, 61–2, 96 Eliza  program  148–9, 161 see also  chatbots emergence  104,  108 –11, 118–19, 123,  156, 292, 302–3, 305, 395 causation as emergent  118 Hofstadter’s ‘I’ and  115–18 levels of emergence and of explanation   114, 116, 118,  123 , 124, 130, 141,  293, 373, 444, 459 and reductionism  109–10 emotions  154, 356, 384, 389 empiricism   4 –29, 32, 119, 122, 155,  165, 311–12, 358, 361, 411 and the deceptiveness of the senses  8,  14, 301 failed to eliminate authority  8–10;  see  also  justificationism 470 index empiricism ( cont .) the falseness of  7–8, 32, 39, 120,  209–10, 403 and the history of ideas  311–12,  314–16, 325, 345,======================================================== the early twenty-first  century, it would have killed at least a substantial proportion of all  humans. In that respect, as in many others, we live in an era of un    - precedented  safety : the twenty-first century is the first ever moment  when we have known how to defend ourselves from such impacts,  which occur once every 250,000 years or so. This may sound too rare  to care about, but it is random .  A probability of one in 250,000 of  such an impact in any given year means that a typical person on Earth  would have a far larger chance of dying of an asteroid impact than in  an aeroplane crash. And the next such object to strike us is already out  there at this moment, speeding towards us with nothing to stop it  except human knowledge. Civilization is vulnerable to several other  known types of disaster with similar levels of risk. For instance, ice  208 the beginning of infinity ages occur more frequently than that, and ‘mini ice ages’ much more  frequently – and some climatologists believe that they can happen with  only a few years’ warning. A ‘super-volcano’ such as the one lurking  under Yellowstone National Park could blot out the sun for years at  a time. If it happened tomorrow our species could survive, by growing  food using artificial light, and civilization could recover. But many  would die, and the suffering would be so tremendous that such events  should merit almost as much preventative effort as an extinction. We  do not know the probability of a spontaneously occurring incurable  plague, but we may guess that it is unacceptably high, since pandemics  such as the Black Death in the fourteenth century have already shown  us the sort of thing that can happen on a timescale of centuries. Should  any of those catastrophes loom, we now have at least a chance of  creating the knowledge required to survive, in time. We have such a chance because we are able to solve problems.  Problems are inevitable. We shall always be faced with the problem of  how to plan for an unknowable future. We shall never be able to afford  to sit back and hope for the best. Even if our civilization moves out  into space in order to hedge its bets, as Rees and Hawking both rightly  advise, a gamma-ray burst in our galactic vicinity would still wipe us  all out. Such an event is thousands of times rarer than an asteroid  collision, but when it does finally happen we shall have no defence  against it without a great deal more scientific knowledge and an  enormous increase in our wealth.  But first we shall have to survive the next ice age; and, before that,  other dangerous climate change (both spontaneous and human-caused),  and weapons of mass destruction and pandemics and all the countless  unforeseen dangers that are going to beset us. Our political institutions,  ways of life, personal aspirations and morality are all forms or embodi- ments of knowledge, and all will have to be improved if civilization –  and the Enlightenment in particular – is to survive every one of the risks  that Rees describes and presumably many others of which we have    no inkling.  So – how? How can we formulate  policies  for the unknown? If we  cannot derive them from our best existing knowledge, or from dog  - matic rules of thumb like blind optimism or pessimism, where  can  we  derive them from? Like scientific theories, policies cannot be  derived   209 Optimism from anything. They are conjectures .  And we should choose between  them not on the basis of their origin, but according to how good they  are as explanations: how hard to vary. Like the rejection of empiricism, and of the idea that knowledge is  ‘justified, true belief’, understanding that political policies are conjectures  entails the rejection of a previously unquestioned philosophical as    - sumption. Again, Popper was a key advocate of this rejection. He wrote: The question about the sources of our knowledge . . . has always been  asked in the spirit of: ‘What are the best sources of our knowledge – the  most reliable ones, those which will not lead us into error, and those to  which we can and must turn, in case of doubt, as the last court of appeal?’  I propose to assume, instead, that no such ideal sources exist – no more  than ideal rulers – and that all ‘sources’ are liable to lead us into error at  times. And I propose to replace, therefore, the question of the sources of  our knowledge by the entirely different question: ‘How can we hope to  detect and eliminate error?’  ‘Knowledge without Authority’ (1960) The question ‘How can we hope to detect and eliminate error?’ is  echoed by Feynman’s remark that ‘science is what we have learned  about how to keep from fooling ourselves’. And the answer is basically  the same for human decision-making as it is for science: it requires a  tradition of criticism, in which good explanations are sought – for  example, explanations of what has gone wrong, what would be better,  what effect various policies have had in the======================================================== success. A pessimistic civil- ization considers it immoral to behave in ways that have not been tried  many times before, because it is blind to the possibility that the benefits  of doing so might offset the risks. So it is intolerant and conformist.  But Athens took the opposite view. Pericles also contrasted his city’s  openness to foreign visitors with the closed, defensive attitude of rival  cities: again, he expected that Athens would benefit from contact with  new, unforeseeable ideas, even though, as he acknowledged, this policy  gave enemy spies access to the city too. He even seems to have regarded  the lenient treatment of children as a source of military strength: In education, where our rivals from their very cradles by a painful  discipline seek after manliness, in Athens we live exactly as we please,  and yet are just as ready to encounter every legitimate danger. 218 the beginning of infinity A pessimistic civilization prides itself on its children’s conformity to  the proper patterns of behaviour, and bemoans every real or imagined  novelty. Sparta was, in all the above respects, the opposite of Athens. The  epitome of a pessimistic civilization, it was notorious for its citizens’  austere ‘spartan’ lifestyle, for the harshness of its educational system,  and for the total militarization of its society. Every male citizen was a  full-time soldier, owing absolute obedience to his superiors, who were  themselves obliged to follow religious tradition. All other work was  done by slaves: Sparta had reduced an entire neighbouring society,    the Messenians, to the status of helots (a kind of serf or slave). It    had no philosophers, historians, artists, architects, writers – or other  knowledge-creating people of any kind apart from the occasional  talented general. Thus almost the entire effort of the society was  devoted to preserving itself in its existing state – in other words, to  preventing improvement. In 404 bce, twenty-seven years after Pericles’  funeral oration, Sparta decisively defeated Athens in war and imposed  an authoritarian form of government on it. Although, through the  vagaries of international politics, Athens became independent and  democratic again soon afterwards, and continued for several gener- ations to produce art, literature and philosophy, it was never again  host to rapid, open-ended progress. It became unexceptional. Why? I  guess that its optimism was gone. Another short-lived enlightenment happened in the Italian city-state  of Florence in the fourteenth century. This was the time of the early  Renaissance, a cultural movement that revived the literature, art and  science of ancient Greece and Rome after more than a millennium of  intellectual stagnation in Europe. It became an  enlightenment  when  the Florentines began to believe that they could improve upon that  ancient knowledge. This era of dazzling innovation, known as the  Golden Age of Florence, was deliberately fostered by the Medici family,  who were in effect the city’s rulers – especially Lorenzo de’ Medici,  known as ‘the Magnificent’, who was in charge from 1469 to 1492.  Unlike Pericles, the Medici were not devotees of democracy: Florence’s  enlightenment began not in politics but in art, and then philosophy,  science and technology, and in those fields it involved the same openness  to criticism and desire for innovation both in ideas and in action.  219 Optimism Artists, instead of being restricted to traditional themes and styles,  became free to depict what they considered beautiful, and to invent  new styles. Encouraged by the Medici, the wealthy of Florence competed  with each other in the innovativeness of the artists and scholars    whom they sponsored – such as Leonardo da Vinci, Michelangelo and  Botticelli. Another denizen of Florence at this time was Niccolò  Machiavelli, the first secular political philosopher since antiquity.  The Medici were soon promoting the new philosophy of ‘humanism’,  which valued knowledge above dogma, and virtues such as intellectual  independence, curiosity, good taste and friendship over piety and  humility. They sent agents all over the known world to obtain copies  of ancient books, many of which had not been seen in the West since  the fall of the Western Roman Empire. The Medici library made copies  which it supplied to scholars in Florence and elsewhere. Florence  became a powerhouse of newly revived ideas, new interpretations of  ideas, and brand-new ideas. But that rapid progress lasted for only a generation or so. A  charismatic monk, Girolamo Savonarola, began to preach apocalyptic  sermons against humanism and every other aspect of the Florentine  enlightenment. Urging a return to medieval conformism and self-denial,  he proclaimed prophecies of doom if Florence continued on its path.  Many citizens were persuaded, and in 1494 Savonarola managed    to seize power. He reimposed all the traditional restrictions on art,  literature, thought and======================================================== simulation argument  455 and the Singularity  456–7 Turing test  148, 149–50, 151, 152–3,  154–6, 158, 161, 320 The Ascent of Man   419, 440– 441 , 460 Asimov, Isaac ‘Jokester’  372 The End of Eternity   443 asteroids  207 astrology  42 astronomy  34–7, 58, 68, 443 and astrology  42 and scientific instruments bringing us  closer to reality  34–41 astrophysicists  60, 72 as representative of people  98–103,  177–80, 183, 452–3;  see also  anthropic reasoning astrophysics  1–3, 6, 46–7, 70–71, 101,  275, 450–51 see  also  cosmology Athena  217, 238, 246 Athens  83, 119, 216–18, 220–21, 427,  449 and ‘a dream of Socrates’  224–5,  229–35, 244–51 Golden Age of  216–17, 254, 386 atomic bomb  see  nuclear weapons atomic lasers  266, 290 atomic physics  312 atoms  43, 67, 70, 109–10, 258, 266,  288–91, 298, 301, 302, 312, 324 affected by waves of differentiation   274–5, 298 atomic configurations  109–10 and people  306 of a stratum  293 structure of  445 see  also  particles, elementary Attenborough, David  419, 421 attraction  357–60 and evolution  360–65 audiences  14, 17, 19, 259, 279, 357,  369, 403, 409–10 Augustine of Hippo  82 Australia  19, 432 authority the Enlightenment’s rebellion against   12–13, 22–3, 32–3, 65 and knowledge  4, 8–13, 22–3, 123,  209, 227, 310, 311, 314, 356, 391,  395 see also  justificationism automation  36, 39, 57–8, 62,  76 , 135–6,  141, 158, 160, 320, 438, 456 axis-tilt theory  23–5, 26–8, 44, 68,   458 465 index Babbage, Charles  135, 136, 137, 139,  148 Babylonian numerals  131 background knowledge  16 Bacon, Roger  220 bacteria  82, 145, 162, 436 Balinski, Michel  334 Balinski and Young’s theorem  334,  339 Basalla, George  394 ‘bat, what is it like to be a’ (Nagel)  367 Bateson, Patrick  320, 321 Bear, Greg  202–3 beauty and attraction  357–9, 360–65 and elegance  355 objectivity of  122, 353–68 truth and  355 two kinds of  364, 365 ‘because I say so’  311, 391–2, 395 see also  memes, anti-rational;  quantum theory: shut-up-and- calculate interpretation Beethoven, Ludwig van  355, 356 beginning of infinity, introductory  explanation of concept  vii–viii;   see also   443 behaviour parsing  407–9 behaviourism  157–8,  163 , 316–20 Bell, Jocelyn  38 Big Bang  3, 6, 11, 96, 175, 197,   450–51 afterglow (microwave radiation)  46,  47, 68 in a parallel universe  263 Big Crunch  450–51 biogeography  426–42 biological weapons  196, 204, 205 biosphere  44–5, 48–51, 69–70 automated environmental  transformation  57–9 environmental control and the human  reach  57–63 environments and knowledge  74–5 evolution and the biosphere–culture  analogy  371–2 and fine-tuning of the laws of physics   97 global warming and climate change   437–41 and the problem of suffering/evil  80 see also  ecosystems biotechnology  95, 196 see also  biological weapons birds and music  356 nesting  89–91, 145 reach and evolution of adaptations   54–5 see also  parrots bits (information)  187 Black Death  208, 385, 437 black holes  2, 3, 173, 178, 203 Blackmore, Susan  394–5, 402, 404, 415 blind spot  80 Bohm, David  310 Bohr, Neils  308 Boltzmann, Ludwig  255, 312 Book of Nature  4 Bostrom, Nick  453 Botticelli, Sandro  219 Bradshaw, Elizabeth  320 brains  78, 379, 415 adaptation, and knowledge in human  brains  78–9, 95, 105–6 add-ons  456, 457 and the doomsday argument  455–6 encoding of knowledge in  50, 375–7 evolutionary process of creativity in   373 the human brain and scientific  knowledge  72, 189 and the understanding of abstractions   119 British Enlightenment  see  Enlightenment:  British Bronowski, Jacob  121, 355, 419–20,  423, 441, 460 Byrne, Richard  407, 460 Caesar, Julius  423 calculus  164, 194 calendars  7 cancer  294, 437 Cantor, Georg  166, 170–71, 181, 182,  195 carbon-dioxide emissions  437–41 Carroll, Lewis:  Through the Looking  Glass   282 Carter, Brandon  96 catalysts  143 cathode-ray tubes  433–5 causation  118, 300–301, 428 celestial sphere theory  8, 10, 112, 133 466 index cells  39–40, 58, 95, 294, 372, 376, 384,  393 single- and multicellular organisms   144 certainty  see  fallibility Chaerephon, and ‘a dream of Socrates’   243–9, 251, 252, 253 chains  of interpretation  38–9  of proxies  72, 317 of instantiations of abstractions   114–15, 256 of universes  179 chatbots  150, 152, 158, 160 chemistry  13, 43, 46, 57–8, 61–2, 67,  73, 96–7, 142–3, 261, 301–2, 359,  362, 425 humans as chemical scum  44–8, 51,  72, 73 chess  36, 114, 118, 136, 157 choice  326–52 apportionment paradoxes  326–33 decision-making and social choice  see   decision-making devising an electoral system  338–40 social-choice theory  335, 337–8,  342–3, 345,  352 ; applied to an  individual mind  340–41 voters’  342 cholera  207 Churchill, Winston  201, 333 cimenti   14 civilization Athenian  216–18, 224–5, 229–33,  244–51, 246 of Easter Island  418, 419–23,   430–31 extra-terrestrial civilizations  202–4 Florentine  218–20 optimism and  208–22 pessimism and  196–203 Polynesian  419, 421, 427 present and======================================================== nation merely has one more legislator to feed than planned.  The real problem is that this apportionment is no longer representative:  85 per cent of eleven is not 8.5 but 9.35. So the large state, with only  eight seats, is in fact short of its quota by well over one seat. My rule  under-represents 85 per cent of the population. Because we  intended   to allocate ten seats, the exact quotas necessarily add up to ten; but  the rounded ones add up to eleven. And if there are going to be eleven  seats in the House, the principle of representative government – and  the Constitution – requires each state to receive its fair share of those,  not of the ten that we merely intended.  Again, many ‘why don’t they just . . . ?’ ideas spring to mind. Why  don’t they just create three additional seats and give them to the large  state, thus bringing the allocation within the quota? (Curious readers  328 the beginning of infinity may check that no fewer than three additional seats are needed to  achieve this.) Alternatively, why don’t they just transfer a seat from  one of the small states to the large state? Perhaps it should be from the  state with the smallest population, so as to disadvantage as few people  as possible. That would not only bring all the allocations within the  quota, but also restore the number of seats to the originally intended  ten. Such strategies are known as  reallocation schemes . They are indeed  capable of staying within the quota. So, what is wrong with them? In  the jargon of the subject, the answer is  apportionment paradoxes  – or,  in ordinary language,  unfairness  and  irrationality .  For example, the last reallocation scheme that I described is unfair  by being biased against the inhabitants of the least populous state.  They bear the whole cost of correcting the rounding errors. On this  occasion their representation has been rounded down to zero. Yet, in  the sense of minimizing the deviation from the quotas, the apportion- ment is almost perfectly fair: previously, 85 per cent of the population  were well outside the quota, and now all are within it and 95 per cent  are at the closest whole numbers to their quotas. It is true that 5 per  cent now have no representatives – so they will not be able to vote in  congressional elections at all – but that still leaves them within the  quota, and indeed only slightly further from their exact quota than  they were. (The numbers zero and one are almost equidistant from the  quota of just over one half.) Nevertheless, because those 5 per cent  have been completely disenfranchised, most advocates of representative  government would regard this outcome as much less representative  than it was before.  That must mean that the ‘minimum total deviation from quota’ is  not the right measure of representativeness. But what is the right  measure? What is the right trade-off between being slightly unfair to  many people and very unfair to a few people? The Founding Fathers  were aware that different conceptions of fairness, or representativeness,  could conflict. For example, one of their justifications for democracy  was that govern  ment was not legitimate unless everyone who was  subject to the law had a representative, of equal power, among the  lawmakers. This was expressed in their slogan ‘No taxation without  representation’. Another of their aspirations was to abolish  privilege :  329 Choices they wanted the system of government to have no built-in bias. Hence  the requirement of proportional allocation. Since these two aspirations  can conflict, the Constitution contains a clause that explicitly adjudicates  between them: ‘Each State shall have at least one Representative.’ This  favours the principle of representative government in the no-taxation- without-representation sense over the same principle in the abolish- privilege sense. Another concept that frequently appeared in the Founding Fathers’  arguments for representative government was ‘the will of the people’.  Governments are supposed to enact it. But that is a source of further  inconsistencies. For in elections, only the will of  voters  counts, and not  all of ‘the people’ are voters. At the time, voters were a fairly small  minority: only free male citizens over the age of twenty-one. To address  this point, the ‘Numbers’ referred to in the Constitution constituted  the whole population of a state, including non-voters such as women,  children, immigrants and slaves. In this way the Constitution attempted  to treat the  population  equally by treating  voters  unequally. So voters in states with a higher proportion of non-voters were  allocated more representatives per capita.  This had the perverse effect  that in the states where the voters were already the most privileged  within  the state (i.e. where they were an exceptionally small minority),  they now received an additional privilege relative to voters in other  states: they were allocated more representation in======================================================== theories about the behaviour of invisible entities  such as forces and momentum that they began to understand what  was needed in order to go there.  This increasingly intimate connection between  explaining  the world  and  controlling  it is no accident, but is part of the deep structure of  the world. Consider the set of all conceivable transformations of  physical objects. Some of those (like faster-than-light communication)  56 the beginning of infinity never happen because they are forbidden by laws of nature; some (like  the formation of stars out of primordial hydrogen) happen spontan- eously; and some (such as converting air and water into trees, or  converting raw materials into a radio telescope) are possible, but  happen only when the requisite knowledge is present – for instance,  embodied in genes or brains. But those are the only possibilities. That  is to say, every putative physical transformation, to be performed in a  given time with given resources or under any other conditions, is either – impossible because it is forbidden by the laws of nature; or – achievable, given the right knowledge.  That momentous dichotomy exists because if there were transform- ations that technology could never achieve regardless of what know- ledge was brought to bear, then this fact would itself be a testable  regularity in nature. But all regularities in nature have explanations,  so the explanation of that regularity would itself be a law of nature,  or a consequence of one. And so, again, everything that is not forbidden  by laws of nature is achievable, given the right knowledge.  This fundamental connection between explanatory knowledge and  technology is why the Haldane–Dawkins queerer-than-we-can-suppose  argument is mistaken – why the reach of human adaptations does have  a different character from that of all the other adaptations in the  biosphere. The ability to create and use explanatory knowledge gives  people  a power to transform nature which is ultimately not limited by  parochial factors, as all other adaptations are, but only by universal  laws. This is the cosmic significance of explanatory knowledge – and  hence of people, whom I shall henceforward define as entities that can  create explanatory knowledge.  For every other species on Earth, we can determine its reach simply  by making a list of all the resources and environmental conditions on  which its adaptations depend. In principle one could determine those  from a study of its DNA molecules – because that is where all its genetic  information is encoded (in the form of sequences of small constituent  molecules called ‘bases’). As Dawkins has pointed out: A gene pool is carved and whittled through generations of ancestral  natural selection to fit [a particular] environment. In theory a knowledge- able zoologist, presented with the complete transcript of a genome [the  57 The Spark set of all the genes of an organism], should be able to reconstruct the  environmental circumstances that did the carving. In this sense the DNA  is a coded description of ancestral environments. In Art Wolfe,  The Living Wild , ed. Michelle A. Gilders (2000) To be precise, the ‘knowledgeable zoologist’ would be able to reconstruct  only those aspects of the organism’s ancestral environment that exerted  selection pressure – such as the types of prey that existed there, what  behaviours would catch them, what chemicals would digest them and  so on. Those are all regularities in the environment. A genome contains  coded descriptions of them, and hence implicitly specifies the environ- ments in which the organism can survive. For example, all primates  require vitamin C. Without it, they fall ill and die of the disease scurvy,  but their genes do not contain the knowledge of how to synthesize it.  So, whenever any non-human primate is in an environment that does  not supply vitamin C for an extended period, it dies. Any account that  overlooks this fact will overestimate the reach of those species. Humans  are primates, yet  their  reach has nothing to do with which environments  supply vitamin C. Humans can create and apply new knowledge of how  to cause it to be synthesized from a wide range of raw materials, by  agriculture or in chemical factories. And, just as essentially, humans can  discover for themselves that, in most environments, they  need  to do that  in order to survive. Similarly, whether humans could live entirely outside the biosphere  – say, on the moon – does not depend on the quirks of human bio  - chemistry. Just as humans currently cause over a tonne of vitamin C  to appear in Oxfordshire every week (from their farms and factories),  so they could do the same on the moon – and the same goes for  breathable air, water, a comfortable temperature and all their other  parochial needs. Those needs can all be met, given the right knowledge,  by transforming other resources. Even with present-day technology, it  would be possible to build a======================================================== be able to harness physical phenomena of which  we are unaware. Also, that teleportation to or from another location  would be mistaken for ‘destruction’ (without trace) and ‘creation’ (out  of thin air) in your experiment and that therefore this cannot be ruled  out as a possible cause of the anomalies. When headlines appear of the form ‘Teleportation Possibly  Observed in City Museum, Say Scientists’ and ‘Scientists Prove Alien  323 A Physicist’s History of Bad Philosophy Abduction is Real,’ protest mildly that you have claimed no such  thing, that your results are not conclusive, merely suggestive, and  that more studies are needed to determine the mechanism of this  perplexing phenomenon. You have made no false claim. Data can become ‘inconsistent with  conventional physics’ by the mundane means of containing errors, just  as genes can ‘cause happiness’ by countless mundane means such as  affecting your appearance. The fact that your paper does not point this  out does not make it false. Moreover, as I said, the crucial step consists  of a definition, and definitions, provided only that they are consistent,  cannot be false. You have  defined  an observation of more people entering  than leaving as a ‘destruction’ of people. Although, in everyday language,  that phrase has a connotation of people disappearing in puffs of smoke,  that is not what it means in this study. For all you know, they  could  be  disappearing in puffs of smoke, or in invisible spaceships: that would  be consistent with your data. But your paper takes no position on that.  It is entirely about the outcomes of your observations.  So you had better not name your research paper ‘Errors Made When  Counting People Incompetently’. Aside from being a public-relations  blunder, that title might even be considered unscientific, according to  explanationless science. For it would be taking a position on the  ‘interpretation’ of the observed data, about which it provides no  evidence.  In my view this is a scientific experiment in form only. The substance  of scientific theories is explanation, and explanation  of   errors  constitutes  most of the content of the design of any non-trivial scientific experiment. As the above example illustrates, a generic feature of experimentation  is that the bigger the errors you make, either in the numbers or in your  naming and interpretation of the measured quantities, the more exciting  the results are,  if true . So, without powerful techniques of error-detection  and -correction – which depend on explanatory theories – this gives  rise to an instability where false results drown out the true. In the ‘hard  sciences’ – which usually do good science – false results due to all sorts  of errors are nevertheless common. But they are corrected when    their explanations are criticized and tested. That cannot happen in  explanationless science. Consequently, as soon as scientists allow themselves to stop demand- 324 the beginning of infinity ing good explanations and consider only whether a prediction is  accurate or inaccurate, they are liable to make fools of themselves. This  is the means by which a succession of eminent physicists over the  decades have been fooled by conjurers into believing that various  conjuring tricks have been done by ‘paranormal’ means. Bad philosophy cannot easily be countered by good philosophy –  argument and explanation – because it holds itself immune. But it can  be countered by  progress . People want to understand the world, no  matter how loudly they may deny that. And progress makes bad  philosophy harder to believe. That is not a matter of refutation by logic  or experience, but of explanation. If Mach were alive today I expect  he would have accepted the existence of atoms once he saw them  through a microscope, behaving according to atomic theory. As a matter  of logic, it would still be open to him to say, ‘I’m not seeing atoms, I’m  only seeing a video monitor. And I’m only seeing that theory’s predict- ions  about me , not about atoms, come true.’ But the fact that that is a  general-purpose bad explanation would be borne in upon him. It would  also be open to him to say, ‘Very well, atoms do exist, but electrons do  not.’ But he might well tire of that game if a better one seems to be  available – that is to say, if rapid progress is made. And then he would  soon realize that it is not a game. Bad philosophy is philosophy that denies the possibility, desirability  or existence of progress. And progress is the only effective way of  opposing bad philosophy. If progress cannot continue indefinitely, bad  philosophy will inevitably come again into the ascendancy – for it will  be true. terminology Bad philosophy   Philosophy that actively prevents the growth of  knowledge. Interpretation   The explanatory part of a scientific theory, supposedly  distinct from its predictive or instrumental part. Copenhagen interpretation   Niels Bohr’s combination of instrument-======================================================== preferences? One reason  is that, when females mated with prominent-tailed males, their male  offspring, having more prominent tails, found more mates. Another  may be that an individual able to grow a large, colourful tail is more  92 the beginning of infinity likely to be healthy. In any case, the net effect of all the selection  pressures was to spread genes for large, colourful tails, and genes for  preferring such tails, through the population. The species and the  individuals just had to suffer the consequences. If the best-spreading genes impose sufficiently large disadvantages  on the species, the species becomes extinct. Nothing in biological  evolution prevents that. It has presumably happened many times in  the history of life on Earth, to species less lucky than the peacock.  Dawkins named his tour-de-force account of neo-Darwinism  The  Selfish Gene  because he wanted to stress that evolution does not  especially promote the ‘welfare’ of species or individual organisms.  But, as he also explained, it does not promote the ‘welfare’ of genes  either: it adapts them not for survival in larger numbers, nor indeed  for survival at all, but only for spreading through the population at  the expense of rival genes, particularly slight variants of themselves. Is it sheer luck, then, that most genes do usually confer some, albeit  less than optimal, functional benefits on their species, and on their  individual holders? No. Organisms are the slaves, or tools, that genes  use to achieve their ‘purpose’ of spreading themselves through the  population. (That is the ‘purpose’ that Paley and even Darwin never  guessed.) Genes gain advantages over each other in part by keeping  their slaves alive and healthy, just as human slave owners did. Slave  owners were not working for the benefit of their workforces, nor for  the benefit of individual slaves: it was solely to achieve their own  objectives that they fed and housed their slaves, and indeed forced  them to reproduce. Genes do much the same thing.  In addition, there is the phenomenon of reach: when the knowledge  in a gene happens to have reach, it will help the individual to help itself  in a wider range of circumstances, and by more, than the spreading of  the gene strictly requires. That is why mules stay alive even though they  are sterile. So it is not surprising that genes usually confer  some  benefits  on their species and its members, and do often succeed in increasing  their own absolute numbers. Nor should it be surprising that they  sometimes do the opposite. But what genes are adapted to – what they  do better than almost any variant of themselves – has nothing to do  with the species or the individuals or even their own survival in the  long run. It is getting themselves replicated more than rival genes. 93 Creation Neo-Darwinism and knowledge Neo-Darwinism does not refer, at its fundamental level, to anything  biological. It is based on the idea of a  replicator  (anything that contributes  causally to its own copying).* For instance, a gene conferring the ability  to digest a certain type of food  causes  the organism to remain healthy  in some situations where it would otherwise weaken or die. Hence it  increases the organism’s chances of having offspring in the future, and  those offspring would inherit, and spread,  copies  of the gene. Ideas can be replicators too. For example, a good joke is a replicator:  when lodged in a person’s mind, it has a tendency to cause that person  to tell it to other people, thus copying it into  their  minds. Dawkins  coined the term  memes  (rhymes with ‘dreams’) for ideas that are  replicators. Most ideas are not replicators: they do not cause us to  convey them to other people. Nearly all long-lasting ideas, however,  such as languages, scientific theories and religious beliefs, and the  ineffable states of mind that constitute cultures such as being British,  or the skill of performing classical music, are memes (or ‘memeplexes’  – collections of interacting memes). I shall say more about memes in  Chapter 15. The most general way of stating the central assertion of the neo-  Darwinian theory of evolution is that a population of replicators subject  to variation (for instance by imperfect copying) will be taken over by  those variants that are better than their rivals at causing themselves to  be replicated. This is a surprisingly deep truth which is commonly  criticized either for being too obvious to be worth stating or for being  false. The reason, I think, is that, although it is self-evidently true, it is  not self-evidently the explanation of specific adaptations. Our intuition  prefers explanations in terms of function or purpose: what does a gene  do for its holder, or for its species? But we have just seen that the genes  generally do not optimize such functionality.  So the knowledge embodied in genes is knowledge of how to get  themselves replicated at the expense of their rivals. Genes======================================================== because of the special measures that prevent this. Hence, information  is processed separately in each of that vast number of autonomous  histories. Finally, an interference process involving all the affected qubits  combines the information in those histories into a single history. Because  of the intervening computation, which has processed the information,  the final state is not the same as the initial one, as in the simple inter- ference experiment I discussed above, namely        ,   but is some  function of it, like this: 296 the beginning of infinity A typical quantum computation.  Y 1  . . .  Y many  are intermediate results that  depend on the input  X . All of them are needed to compute the output  f  ( X ) efficiently. Just as the starship crew members could achieve the effect of large  amounts of computation by sharing information with their doppel- gängers computing the same function on different inputs, so an  algorithm that makes use of quantum parallelism does the same. But,  while the fictional effect is limited only by starship regulations that we  may invent to suit the plot, quantum computers are limited by the laws  of physics that govern quantum interference. Only certain types of  parallel computation can be performed with the help of the multiverse  in this way. They are the ones for which the mathematics of quantum  interference happens to be just right for combining into a single history  the information that is needed for the final result. In such computations, a quantum computer with only a few hundred  qubits could perform far more computations in parallel than there are  atoms in the visible universe. At the time of writing, quantum computers  with about ten qubits have been constructed. ‘Scaling’ the technology  to larger numbers is a tremendous challenge for quantum technology,  but it is gradually being met. I mentioned above that, when a large object is affected by a small  influence, the usual outcome is that the large object is strictly unaffected.  I can now explain why. For example, in the Mach–Zehnder interfero- meter, shown earlier, two instances of a single photon travel on two  different paths. On the way, they strike two different mirrors. Interference  will happen only if the photon does not become entangled with the  mirrors – but it  will  become entangled if either mirror retains the slightest  record that it has been struck (for that would be a differential effect of  the instances on the two different paths). Even a single quantum of  change in the amplitude of the mirror’s vibration on its supports, for  Y 1 f(X) X … Y 2 Y (many) splitting interference යය 297 The Multiverse instance, would be enough to prevent the interference (the subsequent  merging of the photon’s two instances).  When one of the instances of the photon bounces off either mirror,  its momentum changes, and hence by the principle of the conservation  of momentum (which holds universally in quantum physics, just as in  classical physics), the mirror’s momentum must change by an equal  and opposite amount. Hence it seems that, in each history, one mirror  but not the other must be left vibrating with slightly more or less energy  after the photon has struck it. That energy change would be a record  of which path the photon took, and hence the mirrors would be  entangled with the photon. Fortunately, that is not what happens. Remember that, at a sufficiently  fine level of detail, what we crudely see as a single history of the mirror,  resting passively or vibrating gently on its supports, is actually a vast  number of histories with instances of all its atoms continually splitting  and rejoining. In particular, the total energy of the mirror takes a vast  number of possible values around the average, ‘classical’ one. Now,  what happens when a photon strikes the mirror, changing that total  energy by one quantum?  Oversimplifying for a moment, imagine just five of those countless  instances of the mirror, with each instance having a different vibrational  energy ranging from two quanta below the average to two quanta  above it. Each instance of the photon strikes one instance of the mirror  and imparts one additional quantum of energy to it. So, after that  impact, the average energy of the instances of the mirror will have  increased by one quantum, and there will now be instances with  energies ranging from one quantum below the old average to three  above. But since, at this fine level of detail, there is no autonomous  history associated with any of those values of the energy, it is not  meaningful to ask whether an instance of the mirror with a particular  energy after the impact is  the same  one that previously had that energy.  The objective physical fact is only that, of the five instances of the  mirror, four have energies that were present before, and one does not.  Hence, only that one – whose energy is three quanta higher than the  previous average – carries any record of the======================================================== each  other for replication. The process of copying a genome is called a living  organism. Thus the genetic code is also a language for specifying  organisms. At some point, the system switched to replicators made of  DNA, which is more stable than RNA and therefore more suitable for  storing large amounts of information.  The familiarity of what happened next can obscure how remarkable  and mysterious it is. Initially, the genetic code and the mechanism that  interpreted it were both evolving along with everything else in the  organisms. But there came a moment when the code stopped evolving  yet the organisms continued to do so. At that moment the system was  coding for nothing more complex than primitive, single-celled creatures.  Yet virtually all subsequent organisms on Earth, to this day, have not  only been based on DNA replicators but have used exactly the same  alphabet of bases, grouped into three-base ‘words’, with only small  variations in the meanings of those ‘words’. That means that, considered as a language for specifying organisms,  the genetic code has displayed phenomenal reach. It evolved only to  specify organisms with no nervous systems, no ability to move or exert  forces, no internal organs and no sense organs, whose lifestyle consisted  of little more than synthesizing their own structural constituents and  then dividing in two. And yet the same language today specifies the  hardware and software for countless multicellular behaviours that    had no close analogue in those organisms, such as running and flying  and breathing and mating and recognizing predators and prey. It also  specifies engineering structures such as wings and teeth, and nano- technology such as immune systems, and even a brain that is capable  of explaining quasars, designing other organisms from scratch, and  wondering why it exists.  During the entire evolution of the genetic code, it was displaying far  less reach. It may be that each successive variant of it was used to  specify only a few species that were very similar to each other. At any  rate, it must have been a frequent occurrence that a species embodying  145 The Jump to Universality new knowledge was specified in a new variant of the genetic code. But  then the evolution stopped, at a point when it had already attained  enormous reach. Why? It looks like a jump to some sort of universality,  does it not?  What happened next followed the same sad pattern that I have  described in other stories of universality: for well over a billion years  after the system had reached universality and stopped evolving, it was  still  only being used to make bacteria. That means that the reach that  we can now see that the system had was to remain unused for longer  than the system itself had taken to evolve from non-living precursors.  If intelligent extraterrestrials had visited Earth at any time during those  billion years they would have seen no evidence that the genetic code  could specify anything significantly different from the organisms that  it had specified when it first appeared. Reach always has an explanation. But this time, to the best of my  knowledge, the explanation is not yet known. If the reason for the  jump in reach was that it was a jump to universality, what was the  universality? The genetic code is presumably not universal  for specify- ing life forms , since it relies on specific types of chemicals, such as  proteins. Could it be a universal constructor? Perhaps. It does manage  to build with inorganic materials sometimes, such as the calcium  phosphate in bones, or the magnetite in the navigation system inside  a pigeon’s brain. Biotechnologists are already using it to manufacture  hydrogen and to extract uranium from seawater. It can also program  organisms to perform constructions outside their bodies: birds build  nests; beavers build dams. Perhaps it would it be possible to specify,  in the genetic code, an organism whose life cycle includes building a  nuclear-powered spaceship. Or perhaps not. I guess it has some lesser,  and not yet understood, universality.  In 1994 the computer scientist and molecular biologist Leonard  Adleman designed and built a computer composed of DNA together  with some simple enzymes, and demonstrated that it was capable of  performing some sophisticated computations. At the time, Adleman’s  DNA computer was arguably the fastest computer in the world. Further,  it was clear that a  universal  classical computer could be made in a  similar way. Hence we know that, whatever that other universality of  the DNA system was, the universality of computation had also been  146 the beginning of infinity inherent in it for billions of years, without ever being used – until  Adleman used it. The mysterious universality of DNA as a constructor may have been  the first universality to exist. But, of all the different forms of univer- sality, the most significant physically is the characteristic universality  of people,======================================================== other particles) are ‘particles and waves at the same  time’. There is a field (or ‘waves’) in the multiverse for every individual  particle that we observe in a particular universe. 292 the beginning of infinity Although quantum theory is expressed in mathematical language, I  have now given an account in English of the main features of the reality  that it describes. So at this point the fictional multiverse that I have  been describing is more or less the real one. But there is one thing left  to tidy up. My ‘succession of speculations’ was based on universes, and  on instances of objects, and then on corrections to those ideas in order  to describe the multiverse. But the real multiverse is not ‘based on’  anything, nor is it a correction to anything. Universes, histories, particles  and their instances are not referred to by quantum theory at all – any  more than are planets, and human beings and their lives and loves.  Those are all approximate, emergent phenomena in the multiverse.  A history is part of the multiverse in the same sense that a geological  stratum is part of the Earth’s crust. One history is distinguished from  the others by the values of physical variables, just as a stratum is  distinguished from others by its chemical composition and by the types  of fossils found in it and so on. A stratum and a history are both  channels of information flow. They preserve information because,  although their contents change over time, they are approximately  autonomous  – that is to say, the changes in a particular stratum or  history depend almost entirely on conditions inside it and not else- where. It is because of that autonomy that a fossil found today can be  used as evidence of what was present when that stratum was formed.  Similarly, it is why, within a history, using classical physics, one can  successfully predict some aspects of the future of that history from    its past.  A stratum, like a history, has no separate existence over and above  the objects in it: it  consists  of them. Nor does a stratum have well- defined edges. Also, there are regions of the Earth – for instance, near  volcanoes – where strata have merged (though I think there are no  geological processes that split and remerge strata in the way that  histories split and remerge). There are regions of the Earth – such as  the core – where there have never been strata. And there are regions  – such as the atmosphere – where strata do form but their contents  interact and mix on much shorter timescales than in the crust. Similarly,  there are regions of the multiverse that contain short-lived histories,  and others that do not even approximately contain histories. However, there is one big difference between the ways in which  293 The Multiverse strata and histories emerge from their respective underlying phenomena.  Although not every atom in the Earth’s crust can be unambiguously  assigned to a particular stratum, most of the atoms that form a stratum  can. In contrast, every atom in an everyday object is a multiversal  object, not partitioned into nearly autonomous instances and nearly  autonomous histories, yet everyday objects such as starships and  betrothed couples, which are made of such particles, are partitioned  very accurately into nearly autonomous histories with exactly one  instance, one position, one speed of each object in each history.  That is because of the suppression of interference by entanglement.  As I explained, interference almost always happens either very soon  after splitting or not at all. That is why the larger and more complex  an object or process is, the less its gross behaviour is affected by  interference. At that ‘coarse-grained’ level of emergence, events in the  multiverse consist of autonomous histories, with each coarse-grained  history consisting of a swathe of many histories differing only in  microscopic details but affecting each other through interference.  Spheres of differentiation tend to grow at nearly the speed of light, so,  on the scale of everyday life and above, those coarse-grained histories  can justly be called ‘universes’ in the ordinary sense of the word. Each  of them somewhat resembles the universe of classical physics. And they  can usefully be called ‘parallel’ because they are nearly autonomous.  To the inhabitants, each looks very like a single-universe world. Microscopic events which are accidentally amplified to that coarse- grained level (like the voltage surge in our story) are rare in any one  coarse-grained history, but common in the multiverse as a whole. For  example, consider a single cosmic-ray particle travelling in the direction  of Earth from deep space. That particle must be travelling in a range  of slightly different directions, because the uncertainty principle implies  that in the multiverse it must spread sideways like an ink blot as it  travels. By the time it arrives, this ink blot may well be wider than the  whole Earth – so most of======================================================== meme generation. (Meme ‘generations’ are  simply successive instances of copying to another individual.) Tech- nology can add further stages to a meme’s life cycle. For instance, the  behaviour may be to write something down – thus embodying the  meme in a third physical form, which may later cause a person who  reads it to enact other behaviour, which then causes the meme to    appear in someone’s brain. But all memes must have at least two  physical forms. In contrast, for genes the replicator exists in only one physical form  – the DNA strand (of a germ cell). Even though it may be copied to  other locations in the organism, translated into RNA, and expressed  as behaviour, none of those forms is a replicator. The idea that the  behaviour might be a replicator is a form of Lamarckism, since it  implies that behaviours that had been modified by circumstances would  be inherited.  377 The Evolution of Culture A gene exists in only one physical form, which is copied. Because of the alternating physical forms of a meme, it has to survive  two different, and potentially unrelated, mechanisms of selection in  every generation. The brain-memory form has to cause the holder to  enact the behaviour; and the behaviour form has to cause the new  recipient to remember it – and to enact it. So, for example, although religions prescribe behaviours such as  educating one’s children to adopt the religion, the mere intention to  transmit a meme to one’s children or anyone else is quite insufficient  to make that happen. That is why the overwhelming majority of  attempts to start a new religion fail, even if the founder members try  hard to propagate it. In such cases, what has happened is that an idea  that people have adopted has succeeded in causing them to enact  various behaviours including ones intended to cause their children and  others to do the same – but the behaviour has failed to cause the same  idea to be stored in the minds of those recipients.  The existence of long-lived religions is sometimes explained from  the premise that ‘children are gullible’, or that they are ‘easily frightened’  by tales of the supernatural. But that is not the explanation. The  overwhelming majority of ideas simply do not have what it takes to  persuade (or frighten or cajole or otherwise cause) children or anyone  else into doing the same to other people. If establishing a faithfully  replicating meme were that easy, the whole adult population in our  society would be proficient at algebra, thanks to the efforts made to  378 the beginning of infinity teach it to them when they were children. To be exact, they would all  be proficient algebra  teachers . To be a meme, an idea has to contain quite sophisticated knowledge  of how to cause humans to do at least two independent things: assimi- late the meme faithfully, and enact it. That some memes can replicate  themselves with great fidelity for many generations is a token of how  much knowledge they contain.  The selfish meme If a gene is in a genome at all, then, when suitable circumstances arise,  it will definitely be expressed as an enzyme, as I described in Chapter  6, and will then cause its characteristic effects. Nor can it be left behind  if the rest of its genome is successfully replicated. But merely being  present in a mind does not automatically get a meme expressed as  behaviour: the meme has to compete for that privilege with other ideas  – memes and non-memes, about all sorts of subjects – in the same mind.  And merely being expressed as behaviour does not automatically get  the meme copied into a recipient along with other memes: it has to  compete for the recipients’ attention and acceptance with all sorts of  behaviours by other people, and with the recipient’s own ideas. All that  is in addition to the analogue of the type of selection that genes face,  each meme competing with rival versions of itself across the population,  perhaps by containing the knowledge for some useful function. Memes are subject to all sorts of random and intentional variation  in addition to all that selection, and so they evolve. So to this extent  the same logic holds as for genes: memes are ‘selfish’. They do not  necessarily evolve to benefit their holders, or their society – or, again,  even themselves, except in the sense of replicating better than other  memes. (Though now  most  other memes are their rivals, not just  variants of themselves.) The successful meme variant is the one that  changes the behaviour of its holders in such a way as to make itself  best at displacing other memes from the population. This variant may  well benefit its holders, or their culture, or the species as a whole. But  if it harms them, or destroys them, it will spread anyway. Memes that  harm society are a familiar phenomenon. You need only consider the  harm done by adherents of political views, or religions, that you  379 The Evolution of Culture especially abhor. Societies have been destroyed======================================================== writings, as well as human  authorities such as priests and academics, and belief in traditional lore,  rules of thumb and hearsay. Empiricism also contradicted the opposing  and surprisingly persistent idea that the senses are little more than  sources of error to be ignored. And it was optimistic, being all about  Sensory experiences Theories / knowledge of reality ‘Derivation’ (such as ‘Extrapolation’, ‘Generalization’ or ‘Induction’) 5 The Reach of Explanations obtaining new knowledge, in contrast with the medieval fatalism that  had expected everything important to be known already. Thus, despite  being quite wrong about where scientific knowledge comes from,  empiricism was a great step forward in both the philosophy and the  history of science. Nevertheless, the question that sceptics (friendly and  unfriendly) raised from the outset always remained: how can knowledge  of what has  not  been experienced possibly be ‘derived’ from what  has ?  What sort of thinking could possibly constitute a valid derivation of  the one from the other? No one would expect to deduce the  geography   of Mars from a map of Earth, so why should we expect to be able    to learn about  physics  on Mars from experiments done on Earth?  Evidently, logical deduction alone would not do, because there is a  logical gap: no amount of deduction applied to statements describing  a set of experiences can reach a conclusion about anything other than  those experiences.  The conventional wisdom was that the key is  repetition : if one  repeatedly has similar experiences under similar circumstances, then  one is supposed to ‘extrapolate’ or ‘generalize’ that pattern and predict  that it will continue. For instance, why do we expect the sun to rise  tomorrow morning? Because in the past (so the argument goes) we  have seen it do so whenever we have looked at the morning sky. From  this we supposedly ‘derive’ the theory that under similar circumstances  we shall always have that experience, or that we probably shall. On  each occasion when that prediction comes true, and provided that it  never fails, the probability that it will always come true is supposed to  increase. Thus one supposedly obtains ever more reliable knowledge  of the future from the past, and of the general from the particular. That  alleged process was called ‘inductive inference’ or ‘induction’, and the  doctrine that scientific theories are obtained in that way is called  inductivism . To bridge the logical gap, some inductivists imagine that  there is a principle of nature – the ‘principle of induction’ – that makes  inductive inferences likely to be true. ‘The future will resemble the past’  is one popular version of this, and one could add ‘the distant resembles  the near,’ ‘the unseen resembles the seen’ and so on. But no one has ever managed to formulate a ‘principle of induction’  that is usable in practice for obtaining scientific theories from ex    - periences. Historically, criticism of inductivism has focused on that  6 the beginning of infinity failure, and on the logical gap that cannot be bridged. But that lets  inductivism off far too lightly. For it concedes inductivism’s two most  serious misconceptions. First, inductivism purports to explain how science obtains  predictions  about experiences . But most of our theoretical knowledge simply does  not take that form. Scientific explanations are about reality, most of  which does not consist of anyone’s experiences. Astrophysics is not  primarily about  us  (what we shall see if we look at the sky), but about  what stars are: their composition and what makes them shine, and  how they formed, and the universal laws of physics under which    that happened. Most of that has never been observed: no one has  experienced a billion years, or a light year; no one could have been  present at the Big Bang; no one will ever touch a law of physics –  except in their minds, through theory. All our predictions of how  things will  look  are deduced from such explanations of how things  are . So inductivism fails even to address how we can know about stars  and the universe, as distinct from just dots in the sky. The second fundamental misconception in inductivism is that  scientific theories predict that ‘the future will resemble the past’, and  that ‘the unseen resembles the seen’ and so on. (Or that it ‘probably’  will.) But in reality the future is unlike the past, the unseen very different  from the seen. Science often predicts – and brings about – phenomena  spectacularly different from anything that has been experienced before.  For millennia people dreamed about flying, but they experienced only  falling. Then they discovered good explanatory theories about flying,  and then they flew – in that order. Before 1945, no human being had  ever observed a nuclear-fission (atomic-bomb) explosion; there may  never have been one in the history of the universe. Yet the first such  explosion, and the conditions under======================================================== counter-intuitive properties, some of which are illustrated by  Hilbert’s thought experiment of Infinity Hotel. One of them is that, if  195 A Window on Infinity unlimited progress really is going to happen, not only are we now at  almost the very beginning of it, we always shall be. Cantor proved, with  his diagonal argument, that there are infinitely many levels of infinity,  of which physics uses at most the first one or two: the infinity of the  natural numbers and the infinity of the continuum. Where there are  infinitely many identical copies of an observer (for instance in multiple  universes), probability and proportions do not make sense unless the  collection as a whole has a structure subject to laws of physics that give  them meaning. A mere infinite sequence of universes, like the rooms in    In  finity Hotel, does not have such structure, which means that anthropic  reasoning by itself is insufficient to explain the apparent ‘fine-tuning’  of the constants of physics. Proof is a physical process: whether a  mathematical proposition is provable or unprovable, de    cidable or  undecidable, depends on the laws of physics, which determine which  abstract entities and relationships are modelled by physical objects.  Similarly, whether a task or pattern is simple or complex depends on  what the laws of physics are. 196 9 Optimism The possibilities that lie in the future are infinite. When I say  ‘It is our duty to remain optimists,’ this includes not only the  openness of the future but also that which all of us contribute  to it by everything we do: we are all responsible for what the  future holds in store. Thus it is our duty, not to prophesy evil  but, rather, to fight for a better world. Karl Popper,  The Myth of the Framework  (1994) Martin Rees suspects that civilization was lucky to survive the twentieth  century. For throughout the Cold War there was always a possibility  that another world war would break out, this time fought with hydrogen  bombs, and that civilization would be destroyed. That danger seems to  have receded, but in Rees’s book  Our Final Century , published in 2003,  he came to the worrying conclusion that civilization now had only a  50 per cent chance of surviving the twenty-first century.  Again this was because of the danger that newly created knowledge  would have catastrophic consequences. For example, Rees thought it  likely that civilization-destroying weapons, particularly biological ones,  would soon become so easy to make that terrorist organizations, or  even malevolent individuals, could not be prevented from acquiring  them. He also feared accidental catastrophes, such as the escape of  genetically modified micro-organisms from a laboratory, resulting in  a pandemic of an incurable disease. Intelligent robots, and nano- technology (engineering on the atomic scale), ‘could in the long run be  even more threatening’, he wrote. And ‘it is not inconceivable that  physics could be dangerous too.’ For instance, it has been suggested  197 Optimism that elementary-particle accelerators that briefly create conditions that  are in some respects more extreme than any since the Big Bang might  destabilize the very vacuum of space and destroy our entire universe.  Rees pointed out that, for his conclusion to hold, it is not necessary  for any one of those catastrophes to be at all probable, because we  need be unlucky only once, and we incur the risk afresh every time  progress is made in a variety of fields. He compared this with playing  Russian roulette.  But there is a crucial difference between the human condition and  Russian roulette: the probability of winning at Russian roulette is  unaffected by anything that the player may think or do. Within its  rules, it is a game of pure chance. In contrast, the future of civilization  depends entirely on what we think and do. If civilization falls, that will  not be something that just happens to us: it will be the outcome of  choices that people make. If civilization survives, that will be because  people succeed in solving the problems of survival, and that too will  not have happened by chance.  Both the future of civilization and the outcome of a game of Russian  roulette are unpredictable, but in different senses and for entirely  unrelated reasons. Russian roulette is merely  random . Although we  cannot predict the outcome, we do know what the possible outcomes  are, and the probability of each, provided that the rules of the game  are obeyed. The future of civilization is  unknowable , because the  knowledge that is going to affect it has yet to be created. Hence the  possible outcomes are not yet known, let alone their probabilities. The growth of knowledge cannot change that fact. On the contrary,  it contributes strongly to it: the ability of scientific theories to predict  the future depends on the reach of their explanations, but no explan- ation has enough reach to predict the content of its own successors –======================================================== what it would have taken for scientists to forecast, say,  carbon-dioxide emissions for the twentieth century. On the (shaky)  assumption that energy use would continue to increase by roughly  the same ex      ponential factor as before, they could have estimated the  resulting increase in emissions. But that estimate would not have  included the effects of nuclear power. It could not have, because  radioactivity itself had only just been discovered, and would not be  harnessed for power until the middle of the century. But suppose that  somehow they had been able to foresee that. Then they might have  modified their carbon-dioxide forecast, and concluded that emissions  could easily be restored to below the 1902 level by the end of the  century. But, again, that would only be because they could not possibly  foresee the campaign against nuclear power, which would put a stop  to its expansion (iron  ically, on environmental grounds) before it ever  became a significant factor in reducing emissions. And so on. Time  and again, the un      predictable factor of new human ideas, both good  and bad, would make the scientific prediction useless. The same is  bound to be true – even more so – of forecasts today for the coming  century. Which brings me to my third observation about the current  controversy. It is not yet accurately known how sensitive the atmosphere’s  tem    pera    ture is to the concentration of carbon dioxide – that is, how  much a given increase in concentration increases the temperature.  This number is important politically, because it affects how urgent  the problem is: high sensitivity means high urgency; low sensitivity  means the opposite. Unfortunately, this has led to the political debate  being dominated by the side issue of how ‘anthropogenic’ (human- caused) the increase in temperature to date has been. It is as if people  were arguing about how best to prepare for the next hurricane while  all agreeing that the only hurricanes one should prepare for are  human-induced ones. All sides seem to assume that if it turns out  that a  random  fluctuation in the temperature is about to raise sea  440 the beginning of infinity levels, disrupt agriculture, wipe out species and so on, our best plan  would be simply to grin and bear it. Or if two-thirds of the increase  is anthropogenic, we should not mitigate the effects of the other  third. Trying to predict what our net effect on the environment will be for  the next century and then subordinating all policy decisions to optim- izing that prediction cannot work. We cannot know how much to  reduce emissions by, nor how much effect that will have, because we  cannot know the future discoveries that will make some of our present  actions seem wise, some counter-productive and some irrelevant, nor  how much our efforts are going to be assisted or impeded by sheer  luck. Tactics to delay the onset of foreseeable problems may help. But  they cannot replace, and must be subordinate to, increasing our ability  to intervene  after  events turn out as we did not foresee. If that does  not happen in regard to carbon-dioxide-induced warming, it will  happen with something else. Indeed, we did not foresee the global-warming disaster. I call it a  disaster because the prevailing theory is that our best option is to  prevent carbon-dioxide emissions by spending vast sums and enforcing  severe worldwide restrictions on behaviour, and that is already a  disaster by any reasonable measure. I call it unforeseen because we  now realize that it was already under way even in 1971, when I attended  that lecture. Ehrlich did tell us that agriculture was soon going to be  devastated by rapid climate change. But the change in question was  going to be global  cooling , caused by smog and the condensation trails  of supersonic aircraft. The possibility of warming caused by gas emis- sions had already been mooted by some scientists, but Ehrlich did not  consider it worth mentioning. He told us that the evidence was that a  general cooling trend had already begun, and that it would continue  with catastrophic effects, though it would be reversed in the very long  term because of ‘heat pollution’ from industry (an effect that is currently  at least a hundred times smaller than the global warming that pre  - occupies us). There is a saying that an ounce of prevention equals a pound of cure.  But that is only when one knows what to prevent. No precautions can  avoid problems that we do not yet foresee. To prepare for those, there  is nothing we can do but increase our ability to put things right if they  441 Unsustainable go wrong. Trying to rely on the sheer good luck of avoiding bad  outcomes indefinitely would simply guarantee that we would eventually  fail without the means of recovering. The world is currently buzzing with plans to force reductions in gas  emissions at almost any cost. But it ought to be buzzing much more  with plans to reduce the temperature, or